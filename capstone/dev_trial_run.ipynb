{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from factory_func import plot_confusion_matrix\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, ENGLISH_STOP_WORDS\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, f1_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Embedding, Conv1D, Conv2D, Lambda, LSTM, ConvLSTM2D, TimeDistributed, Masking, Bidirectional\n",
    "from keras.layers import Reshape, Flatten, Dropout, Concatenate, Activation, MaxPooling1D, GlobalAveragePooling1D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Model, load_model, Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emotion Analysis  \n",
    "### Accuracy Records  \n",
    "SVM: 45.5172%  \n",
    "Dense NN: 45.1724%  \n",
    "CNN: 47.2414%  \n",
    "LSTM: tbc  \n",
    "  \n",
    "*(there might be a ceiling for how much you can improve the accuracy)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_raw = pd.read_csv(os.path.join(os.getcwd(), 'dev_sent_emo.csv'))\n",
    "train_raw = pd.read_csv(os.path.join(os.getcwd(), 'train_sent_emo.csv'))\n",
    "test_raw = pd.read_csv(os.path.join(os.getcwd(), 'test_sent_emo.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sr No.</th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Dialogue_ID</th>\n",
       "      <th>Utterance_ID</th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>StartTime</th>\n",
       "      <th>EndTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Oh my God, hes lost it. Hes totally lost it.</td>\n",
       "      <td>Phoebe</td>\n",
       "      <td>sadness</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>00:20:57,256</td>\n",
       "      <td>00:21:00,049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>What?</td>\n",
       "      <td>Monica</td>\n",
       "      <td>surprise</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>00:21:01,927</td>\n",
       "      <td>00:21:03,261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Or! Or, we could go to the bank, close our acc...</td>\n",
       "      <td>Ross</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>00:12:24,660</td>\n",
       "      <td>00:12:30,915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Youre a genius!</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>joy</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>00:12:32,334</td>\n",
       "      <td>00:12:33,960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Aww, man, now we wont be bank buddies!</td>\n",
       "      <td>Joey</td>\n",
       "      <td>sadness</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>00:12:34,211</td>\n",
       "      <td>00:12:37,505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sr No.                                          Utterance   Speaker  \\\n",
       "0       1     Oh my God, hes lost it. Hes totally lost it.    Phoebe   \n",
       "1       2                                              What?    Monica   \n",
       "2       3  Or! Or, we could go to the bank, close our acc...      Ross   \n",
       "3       4                                   Youre a genius!  Chandler   \n",
       "4       5            Aww, man, now we wont be bank buddies!      Joey   \n",
       "\n",
       "    Emotion Sentiment  Dialogue_ID  Utterance_ID  Season  Episode  \\\n",
       "0   sadness  negative            0             0       4        7   \n",
       "1  surprise  negative            0             1       4        7   \n",
       "2   neutral   neutral            1             0       4        4   \n",
       "3       joy  positive            1             1       4        4   \n",
       "4   sadness  negative            1             2       4        4   \n",
       "\n",
       "      StartTime       EndTime  \n",
       "0  00:20:57,256  00:21:00,049  \n",
       "1  00:21:01,927  00:21:03,261  \n",
       "2  00:12:24,660  00:12:30,915  \n",
       "3  00:12:32,334  00:12:33,960  \n",
       "4  00:12:34,211  00:12:37,505  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_raw.Utterance = dev_raw.Utterance.apply(lambda x: re.sub('\\\\x92', \"'\", x))\n",
    "train_raw.Utterance = train_raw.Utterance.apply(lambda x: re.sub('\\\\x92', \"'\", x))\n",
    "test_raw.Utterance = test_raw.Utterance.apply(lambda x: re.sub('\\\\x92', \"'\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dev = dev_raw.Utterance\n",
    "y_dev = dev_raw.Emotion\n",
    "x_train = train_raw.Utterance\n",
    "y_train = train_raw.Emotion\n",
    "x_test = test_raw.Utterance\n",
    "y_test = test_raw.Emotion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tfidf + SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(lowercase=True, stop_words='english', ngram_range=(1,3))\n",
    "tfidf.fit(x_train)\n",
    "x_dev_tf = tfidf.transform(x_dev)\n",
    "x_train_tf = tfidf.transform(x_train)\n",
    "x_test_tf = tfidf.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svd = TruncatedSVD(n_components=300)\n",
    "# x_dev_tr = svd.fit_transform(x_dev_tf)\n",
    "# x_train_tr = svd.fit_transform(x_train_tf)\n",
    "# x_test_tr = svd.fit_transform(x_test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(C=10, kernel='linear', probability=True)\n",
    "# param_grid = { \n",
    "#     'C': [1,10,100], 'kernel': ['linear', 'rbf']\n",
    "# }\n",
    "# clf = GridSearchCV(estimator=svm, param_grid=param_grid, cv=5)\n",
    "# clf.fit(x_train_tr, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Best model by GridSearchCV**  \n",
    "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,  \n",
    "decision_function_shape='ovr', degree=3, gamma='auto_deprecated',  \n",
    "kernel='linear', max_iter=-1, probability=True, random_state=None,  \n",
    "shrinking=True, tol=0.001, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.fit(X=x_train_tf, y=y_train)\n",
    "y_pred_svm = svm.predict(x_test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42923347861223476"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=y_pred_svm, y_true=y_test, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 45.5172%\n"
     ]
    }
   ],
   "source": [
    "svm_accuracy = 100*np.sum(y_pred_svm==y_test)/len(y_pred_svm)\n",
    "print('Test accuracy: %.4f%%' % svm_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras TF-IDF tokenizer + Neural nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural network won't accept sentences with different dimension(i.e. number of words) as input. By padding the inputs, we decide the maximum length of words in a sentence, then zero pads the rest, if the input length is shorter than the designated length. In the case where it exceeds the maximum length, then it will also truncate either from the beginning or from the end.  \n",
    "*Ref_1* https://keras.io/preprocessing/sequence/  \n",
    "*Ref_2* https://towardsdatascience.com/another-twitter-sentiment-analysis-with-python-part-11-cnn-word2vec-41f5e28eda74\n",
    "\n",
    "https://medium.com/@sabber/classifying-yelp-review-comments-using-lstm-and-word-embeddings-part-1-eb2275e4066b\n",
    "#### Dense Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dev = dev_raw.Utterance\n",
    "y_dev = dev_raw.Emotion\n",
    "x_train = train_raw.Utterance\n",
    "y_train = train_raw.Emotion\n",
    "x_test = test_raw.Utterance\n",
    "y_test = test_raw.Emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 7\n",
    "vocabulary_size = 20000\n",
    "tokenizer = Tokenizer(num_words= vocabulary_size)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "# sequences = tokenizer.texts_to_sequences(x_train)\n",
    "# data = pad_sequences(sequences, maxlen=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anger': 0,\n",
       " 'disgust': 1,\n",
       " 'fear': 2,\n",
       " 'joy': 3,\n",
       " 'neutral': 4,\n",
       " 'sadness': 5,\n",
       " 'surprise': 6}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.fit_on_texts(x_train)\n",
    "x_train = tokenizer.texts_to_matrix(x_train, mode='tfidf')\n",
    "x_test = tokenizer.texts_to_matrix(x_test, mode='tfidf')\n",
    "\n",
    "targets, uniques = pd.factorize(y_train, sort=True)\n",
    "y_train = to_categorical(targets, num_classes)\n",
    "\n",
    "label_map = dict(zip(list(uniques), range(num_classes)))\n",
    "label_map\n",
    "# len(y_true) == len(y_pred_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenizer.fit_on_sequences(x_dev)\n",
    "# tokenizer.texts_to_sequences(x_dev)\n",
    "# tokenizer.texts_to_matrix(x_dev, mode='tfidf')\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 1.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_transf = list(map(label_map.get, y_test))\n",
    "z_transf = list(map(sen_label_map.get, z_test))\n",
    "y_true = to_categorical(np.array(y_transf), num_classes)\n",
    "z_true = to_categorical(np.array(z_transf), num_polarities)\n",
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_checkpts = ModelCheckpoint(filepath=os.path.join(os.getcwd() + '/saved_models/dense.weights.best.hdf5'), \n",
    "                               verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 32)                640032    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 651,367\n",
      "Trainable params: 651,367\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_classes = 7\n",
    "\n",
    "dense = Sequential()\n",
    "dense.add(Dense(32, activation='relu', input_dim=20000))\n",
    "# model.add(Dropout(0.2))\n",
    "dense.add(Dense(64, activation='relu'))\n",
    "dense.add(Dense(128, activation='relu'))\n",
    "dense.add(Dense(num_classes, activation='softmax'))\n",
    "dense.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "dense.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conv1D is generally good for text, whereas Conv2D is good for audio and images where spatial matter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5993 samples, validate on 3996 samples\n",
      "Epoch 1/10\n",
      "5993/5993 [==============================] - 6s 1ms/step - loss: 1.5412 - acc: 0.4762 - val_loss: 1.4232 - val_acc: 0.5083\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.42323, saving model to C:\\Users\\syip\\Desktop\\DaSci\\Nanodegree\\ml_nanodegree\\capstone/saved_models/dense.weights.best.hdf5\n",
      "Epoch 2/10\n",
      "5993/5993 [==============================] - 4s 727us/step - loss: 1.1340 - acc: 0.5972 - val_loss: 1.5039 - val_acc: 0.5053\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.42323\n",
      "Epoch 3/10\n",
      "5993/5993 [==============================] - 4s 699us/step - loss: 0.7546 - acc: 0.7402 - val_loss: 1.7573 - val_acc: 0.4479\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.42323\n",
      "Epoch 4/10\n",
      "5993/5993 [==============================] - 4s 723us/step - loss: 0.5112 - acc: 0.8241 - val_loss: 2.0672 - val_acc: 0.4615\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.42323\n",
      "Epoch 5/10\n",
      "5993/5993 [==============================] - 4s 726us/step - loss: 0.3853 - acc: 0.8690 - val_loss: 2.3884 - val_acc: 0.4605\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.42323\n",
      "Epoch 6/10\n",
      "5993/5993 [==============================] - 5s 785us/step - loss: 0.3147 - acc: 0.8935 - val_loss: 2.5746 - val_acc: 0.4515\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.42323\n",
      "Epoch 7/10\n",
      "5993/5993 [==============================] - 4s 734us/step - loss: 0.2704 - acc: 0.9087 - val_loss: 2.8275 - val_acc: 0.4499\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.42323\n",
      "Epoch 8/10\n",
      "5993/5993 [==============================] - 4s 678us/step - loss: 0.2414 - acc: 0.9172 - val_loss: 3.0937 - val_acc: 0.4332\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.42323\n",
      "Epoch 9/10\n",
      "5993/5993 [==============================] - 5s 805us/step - loss: 0.2216 - acc: 0.9221 - val_loss: 3.2223 - val_acc: 0.4492\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.42323\n",
      "Epoch 10/10\n",
      "5993/5993 [==============================] - 6s 1ms/step - loss: 0.2096 - acc: 0.9261 - val_loss: 3.3708 - val_acc: 0.4532\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.42323\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1aa0c34d438>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense.fit(x_train, y_train, validation_split=0.4, epochs=10, callbacks=[dense_checkpts], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data = pad_sequences(tokenizer.texts_to_sequences(x_test), maxlen=50)\n",
    "y_pred_dense = dense.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({4: 1606, 3: 300, 0: 188, 5: 156, 6: 289, 1: 29, 2: 42})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_pred_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 45.1724%\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = 100*np.sum(y_pred_dense==y_true)/len(y_true)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['anger', 'disgust', 'fear', 'joy', 'neutral', 'sadness', 'surprise'], dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__About batch_size__  \n",
    "Advantages of using a batch size < number of all samples:\n",
    "\n",
    "- It requires less memory. Since you train the network using fewer samples, the overall training procedure requires less memory. That's especially important if you are not able to fit the whole dataset in your machine's memory.\n",
    "\n",
    "- Typically networks train faster with mini-batches. That's because we update the weights after each propagation. In our example we've propagated 11 batches (10 of them had 100 samples and 1 had 50 samples) and after each of them we've updated our network's parameters. If we used all samples during propagation we would make only 1 update for the network's parameter.\n",
    "\n",
    "Disadvantages of using a batch size < number of all samples:\n",
    "\n",
    "- The smaller the batch the less accurate the estimate of the gradient will be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolutional Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 7\n",
    "n_length = x_train.shape[0]\n",
    "n_features = x_train.shape[1]\n",
    "\n",
    "x_train_reshaped = x_train.reshape(n_length, n_features, 1)\n",
    "x_test_reshaped = x_test.reshape(x_test.shape[0], n_features, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_checkpts = ModelCheckpoint(filepath=os.path.join(os.getcwd() + '/saved_models/cnn.weights.best.hdf5'), \n",
    "                               verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 20000, 16)         48        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 10000, 16)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 10000, 32)         1056      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 5000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 5000, 64)          4160      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 2500, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 160000)            0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 128)               20480128  \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 20,486,295\n",
      "Trainable params: 20,486,295\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn = Sequential()\n",
    "cnn.add(Conv1D(filters=16, kernel_size=2, padding='same', activation='relu', input_shape=(n_features, 1)))\n",
    "cnn.add(MaxPooling1D(pool_size=2))\n",
    "cnn.add(Conv1D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "cnn.add(MaxPooling1D(pool_size=2))\n",
    "cnn.add(Conv1D(filters=64, kernel_size=2, padding='same', activation='relu'))\n",
    "cnn.add(MaxPooling1D(pool_size=2))\n",
    "# cnn.add(GlobalAveragePooling1D())\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(128, activation='relu'))\n",
    "cnn.add(Dense(num_classes, activation='softmax'))\n",
    "cnn.compile(optimizer='adam',\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5993 samples, validate on 3996 samples\n",
      "Epoch 1/5\n",
      "5993/5993 [==============================] - 152s 25ms/step - loss: 1.5315 - acc: 0.4721 - val_loss: 1.4881 - val_acc: 0.4817\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.48806, saving model to C:\\Users\\syip\\Desktop\\DaSci\\Nanodegree\\ml_nanodegree\\capstone/saved_models/cnn.weights.best.hdf5\n",
      "Epoch 2/5\n",
      "5993/5993 [==============================] - 151s 25ms/step - loss: 1.2260 - acc: 0.5493 - val_loss: 1.4904 - val_acc: 0.4652\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.48806\n",
      "Epoch 3/5\n",
      "5993/5993 [==============================] - 149s 25ms/step - loss: 0.8607 - acc: 0.6843 - val_loss: 1.7995 - val_acc: 0.4637\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.48806\n",
      "Epoch 4/5\n",
      "5993/5993 [==============================] - 148s 25ms/step - loss: 0.5945 - acc: 0.7829 - val_loss: 2.2183 - val_acc: 0.4695\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.48806\n",
      "Epoch 5/5\n",
      "5993/5993 [==============================] - 150s 25ms/step - loss: 0.4472 - acc: 0.8398 - val_loss: 2.6401 - val_acc: 0.4630\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.48806\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f2011e1cf8>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(x_train_reshaped, y_train, validation_split=0.4, epochs=5, callbacks=[cnn_checkpts], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 44.0613%\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({4: 1728, 0: 198, 3: 256, 5: 118, 1: 40, 6: 249, 2: 21})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_cnn = cnn.predict_classes(x_test_reshaped)\n",
    "# y_pred_cnn = [np.argmax(x) for x in cnn.predict(x_test_reshaped)]\n",
    "Counter(y_pred_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 47.2414%\n"
     ]
    }
   ],
   "source": [
    "cnn_accuracy = 100*np.sum(y_pred_cnn==y_true)/len(y_pred_cnn)\n",
    "print('Test accuracy: %.4f%%' % cnn_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn_score = cnn.evaluate(x_test_reshaped, y_pred_cnn, verbose=1)\n",
    "# print(\"%s: %.2f%%\" % (cnn.metrics_names[1], cnn_score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Serialise the model architecture to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(os.getcwd(), \"saved_models\", \"cnn.model.json\", \"w\") as json_file:\n",
    "    json_file.write(cnn.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json and create model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_cnn_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_cnn = model_from_json(loaded_cnn_json)\n",
    "# load weights into new model\n",
    "loaded_cnn.load_weights(\"cnn.weights.best.hdf5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENGLISH_STOP_WORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WordEnbedding + LSTM  \n",
    "- checkpoint: try a pre-trained embedding layer e.g. GloVe Embedding, Word2Vec  \n",
    "  \n",
    "Building the embedding from scratch instead of using pre-trained (*this can be a slower approach, but tailors the model to a specific training dataset*)  \n",
    "\n",
    "Ref_1: https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_checkpts = ModelCheckpoint(filepath=os.path.join(os.getcwd() + '/saved_models/lstm.weights.best.hdf5'), \n",
    "                               verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The shape of the input to \"Flatten\" is not fully defined (got (None, 128). Make sure to pass a complete \"input_shape\" or \"batch_input_shape\" argument to the first layer in your model.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-30e6ec7aeca9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mlstm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mlstm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecurrent_dropout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mlstm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mlstm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    179\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_source_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m             \u001b[0moutput_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    472\u001b[0m             if all([s is not None\n\u001b[0;32m    473\u001b[0m                     for s in to_list(input_shape)]):\n\u001b[1;32m--> 474\u001b[1;33m                 \u001b[0moutput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_output_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    475\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\layers\\core.py\u001b[0m in \u001b[0;36mcompute_output_shape\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    498\u001b[0m             raise ValueError('The shape of the input to \"Flatten\" '\n\u001b[0;32m    499\u001b[0m                              \u001b[1;34m'is not fully defined '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 500\u001b[1;33m                              \u001b[1;34m'(got '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    501\u001b[0m                              \u001b[1;34m'Make sure to pass a complete \"input_shape\" '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m                              \u001b[1;34m'or \"batch_input_shape\" argument to the first '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The shape of the input to \"Flatten\" is not fully defined (got (None, 128). Make sure to pass a complete \"input_shape\" or \"batch_input_shape\" argument to the first layer in your model."
     ]
    }
   ],
   "source": [
    "max_features=20000\n",
    "embedding_size=128\n",
    "lstm_output_size=32  #70\n",
    "num_classes=7\n",
    "\n",
    "lstm = Sequential()\n",
    "lstm.add(Embedding(max_features, 128))\n",
    "lstm.add(LSTM(units=128, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n",
    "lstm.add(Flatten())\n",
    "lstm.add(Dense(num_classes, activation='sigmoid'))\n",
    "          \n",
    "lstm.compile(loss='categorical_crossentropy',\n",
    "            optimizer='adam',\n",
    "            metrics=['accuracy'])\n",
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5993 samples, validate on 3996 samples\n",
      "Epoch 1/3\n",
      "5993/5993 [==============================] - 1072s 179ms/step - loss: 1.5608 - acc: 0.4726 - val_loss: 1.5449 - val_acc: 0.4670\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.54495, saving model to C:\\Users\\syip\\Desktop\\DaSci\\Nanodegree\\ml_nanodegree\\capstone/saved_models/lstm.weights.best.hdf5\n",
      "Epoch 2/3\n",
      "5993/5993 [==============================] - 1074s 179ms/step - loss: 1.5429 - acc: 0.4746 - val_loss: 1.5357 - val_acc: 0.4670\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.54495 to 1.53567, saving model to C:\\Users\\syip\\Desktop\\DaSci\\Nanodegree\\ml_nanodegree\\capstone/saved_models/lstm.weights.best.hdf5\n",
      "Epoch 3/3\n",
      "5993/5993 [==============================] - 1067s 178ms/step - loss: 1.5419 - acc: 0.4746 - val_loss: 1.5396 - val_acc: 0.4670\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.53567\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f206cfb550>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.fit(x_train, y_train, validation_split=0.4, epochs=1, callbacks=[lstm_checkpts], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({4: 2610})"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_lstm = lstm.predict_classes(x_test)\n",
    "Counter(y_pred_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_accuracy = 100*np.sum(y_pred_lstm==y_true)/len(y_pred_lstm)\n",
    "print('Test accuracy: %.4f%%' % lstm_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_lstm = load_model('./saved_models/lstm.weights.best.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 4, 4, 4, 4], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_lstm.predict_classes(x_test[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WordEmbedding + ConvLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, 20000, 128)        2560000   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 20000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 19996, 64)         41024     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 4999, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 4999, 32)          12416     \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 159968)            0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 7)                 1119783   \n",
      "=================================================================\n",
      "Total params: 3,733,223\n",
      "Trainable params: 3,733,223\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "max_features=20000\n",
    "embedding_size=128\n",
    "lstm_output_size=32  #70\n",
    "num_classes=7\n",
    "\n",
    "conv_lstm = Sequential()\n",
    "conv_lstm.add(Embedding(input_dim=max_features, output_dim=embedding_size, input_length=20000))\n",
    "conv_lstm.add(Dropout(0.25))\n",
    "conv_lstm.add(Conv1D(filters=64,\n",
    "                 kernel_size=5,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1))\n",
    "conv_lstm.add(MaxPooling1D(pool_size=4))\n",
    "conv_lstm.add(LSTM(units=lstm_output_size, return_sequences=True))\n",
    "conv_lstm.add(Flatten())\n",
    "conv_lstm.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "conv_lstm.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "conv_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_lstm_checkpts = ModelCheckpoint(filepath=os.path.join(os.getcwd() + '/saved_models/conv_lstm.weights.best.hdf5'), \n",
    "                               verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_lstm.fit(x_train, y_train, validation_split=0.4, callback=[conv_lstm_checkpts], epochs=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({4: 2610})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_conv_lstm = conv_lstm.predict_classes(x_test)\n",
    "Counter(y_pred_conv_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.0000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syip\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "conv_lstm_accuracy = 100*np.sum(y_pred_conv_lstm==y_true)/len(y_true)\n",
    "print('Test accuracy: %.4f%%' % conv_lstm_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec  \n",
    "Do transfer learning with pre-trained word embedding layers, such as Word2Vec & GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dev_tokens = [sentence.split() for sentence in x_dev]\n",
    "x_train_tokens = [sentence.split() for sentence in x_train]\n",
    "\n",
    "model = Word2Vec(\n",
    "    x_train_tokens,\n",
    "    size=150,\n",
    "    window=10,\n",
    "    min_count=2,\n",
    "    workers=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first parameter passed to gensim.models.Word2Vec is an iterable of sentences. Sentences themselves are a list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(x_train_tokens, total_examples=len(x_train), epochs=10)\n",
    "\n",
    "w = ['good']\n",
    "# w = filter(lambda x: x in model.vocab, x_train.tokens)\n",
    "model.wv.most_similar(positive=w,\n",
    "#                       topn=6\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GloVe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract word embeddings from the Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = dict()\n",
    "f = open('./saved_models/glove.6B.100d.txt', encoding=\"utf8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a weight matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size=20000\n",
    "\n",
    "embedding_matrix = np.zeros((vocabulary_size, 100))\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    if index > vocabulary_size - 1:\n",
    "        break\n",
    "    else:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[index] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create ConvLSTM model with GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\syip\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\syip\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 20000, 100)        2000000   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 20000, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 19996, 64)         32064     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 4999, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 2,131,783\n",
      "Trainable params: 131,783\n",
      "Non-trainable params: 2,000,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "glove = Sequential()\n",
    "glove.add(Embedding(vocabulary_size, 100, input_length=20000, weights=[embedding_matrix], trainable=False))\n",
    "glove.add(Dropout(0.2))\n",
    "glove.add(Conv1D(filters=64,\n",
    "                 kernel_size=5,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1))\n",
    "glove.add(MaxPooling1D(pool_size=4))\n",
    "glove.add(LSTM(units=128, return_sequences=True))\n",
    "glove.add(Flatten())\n",
    "glove.add(Dense(num_classes, activation='sigmoid'))\n",
    "glove.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "glove.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_checkpts = ModelCheckpoint(filepath=os.path.join(os.getcwd() + '/saved_models/glove.weights.best.hdf5'), \n",
    "                               verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\syip\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 5993 samples, validate on 3996 samples\n",
      "Epoch 1/1\n",
      "5993/5993 [==============================] - ETA: 3:19:05 - loss: 1.9459 - acc: 0.18 - ETA: 3:15:05 - loss: 1.9447 - acc: 0.34 - ETA: 3:07:14 - loss: 1.9431 - acc: 0.40 - ETA: 3:03:22 - loss: 1.9421 - acc: 0.41 - ETA: 3:02:30 - loss: 1.9413 - acc: 0.40 - ETA: 3:00:31 - loss: 1.9404 - acc: 0.39 - ETA: 2:58:45 - loss: 1.9382 - acc: 0.40 - ETA: 2:57:20 - loss: 1.9364 - acc: 0.39 - ETA: 2:55:46 - loss: 1.9335 - acc: 0.40 - ETA: 2:54:50 - loss: 1.9295 - acc: 0.40 - ETA: 2:53:49 - loss: 1.9201 - acc: 0.42 - ETA: 2:54:11 - loss: 1.9096 - acc: 0.43 - ETA: 2:53:43 - loss: 1.8961 - acc: 0.43 - ETA: 2:53:01 - loss: 1.8770 - acc: 0.44 - ETA: 2:52:27 - loss: 1.8598 - acc: 0.44 - ETA: 2:52:09 - loss: 1.8400 - acc: 0.45 - ETA: 2:51:38 - loss: 1.8327 - acc: 0.44 - ETA: 2:50:57 - loss: 1.8168 - acc: 0.45 - ETA: 2:48:58 - loss: 1.8044 - acc: 0.45 - ETA: 2:47:00 - loss: 1.7974 - acc: 0.45 - ETA: 2:45:22 - loss: 1.7902 - acc: 0.44 - ETA: 2:43:51 - loss: 1.7789 - acc: 0.45 - ETA: 2:42:04 - loss: 1.7771 - acc: 0.44 - ETA: 2:40:17 - loss: 1.7629 - acc: 0.45 - ETA: 2:38:46 - loss: 1.7547 - acc: 0.45 - ETA: 2:37:13 - loss: 1.7510 - acc: 0.44 - ETA: 2:35:50 - loss: 1.7481 - acc: 0.44 - ETA: 2:34:29 - loss: 1.7336 - acc: 0.45 - ETA: 2:33:05 - loss: 1.7284 - acc: 0.45 - ETA: 2:31:39 - loss: 1.7176 - acc: 0.45 - ETA: 2:30:17 - loss: 1.7083 - acc: 0.45 - ETA: 2:28:55 - loss: 1.6981 - acc: 0.46 - ETA: 2:27:44 - loss: 1.7018 - acc: 0.45 - ETA: 2:26:24 - loss: 1.6922 - acc: 0.46 - ETA: 2:25:18 - loss: 1.6919 - acc: 0.46 - ETA: 2:24:01 - loss: 1.6939 - acc: 0.45 - ETA: 2:22:50 - loss: 1.6869 - acc: 0.46 - ETA: 2:21:42 - loss: 1.6811 - acc: 0.46 - ETA: 2:20:35 - loss: 1.6769 - acc: 0.46 - ETA: 2:19:22 - loss: 1.6750 - acc: 0.46 - ETA: 2:18:13 - loss: 1.6700 - acc: 0.46 - ETA: 2:17:11 - loss: 1.6684 - acc: 0.46 - ETA: 2:16:04 - loss: 1.6689 - acc: 0.46 - ETA: 2:14:52 - loss: 1.6689 - acc: 0.46 - ETA: 2:13:51 - loss: 1.6672 - acc: 0.46 - ETA: 2:12:47 - loss: 1.6672 - acc: 0.46 - ETA: 2:11:47 - loss: 1.6636 - acc: 0.46 - ETA: 2:10:43 - loss: 1.6578 - acc: 0.46 - ETA: 2:09:40 - loss: 1.6550 - acc: 0.46 - ETA: 2:08:33 - loss: 1.6498 - acc: 0.46 - ETA: 2:07:29 - loss: 1.6477 - acc: 0.46 - ETA: 2:06:24 - loss: 1.6438 - acc: 0.46 - ETA: 2:05:24 - loss: 1.6384 - acc: 0.46 - ETA: 2:04:30 - loss: 1.6362 - acc: 0.47 - ETA: 2:03:33 - loss: 1.6353 - acc: 0.47 - ETA: 2:02:33 - loss: 1.6338 - acc: 0.46 - ETA: 2:01:40 - loss: 1.6345 - acc: 0.46 - ETA: 2:00:51 - loss: 1.6276 - acc: 0.47 - ETA: 1:59:53 - loss: 1.6276 - acc: 0.47 - ETA: 1:58:57 - loss: 1.6298 - acc: 0.47 - ETA: 1:58:01 - loss: 1.6247 - acc: 0.47 - ETA: 1:57:04 - loss: 1.6240 - acc: 0.47 - ETA: 1:56:04 - loss: 1.6213 - acc: 0.47 - ETA: 1:55:06 - loss: 1.6191 - acc: 0.47 - ETA: 1:54:11 - loss: 1.6210 - acc: 0.47 - ETA: 1:53:15 - loss: 1.6213 - acc: 0.46 - ETA: 1:52:17 - loss: 1.6211 - acc: 0.46 - ETA: 1:51:20 - loss: 1.6228 - acc: 0.46 - ETA: 1:50:22 - loss: 1.6224 - acc: 0.46 - ETA: 1:49:25 - loss: 1.6219 - acc: 0.46 - ETA: 1:48:30 - loss: 1.6226 - acc: 0.46 - ETA: 1:47:30 - loss: 1.6222 - acc: 0.46 - ETA: 1:46:47 - loss: 1.6163 - acc: 0.46 - ETA: 1:45:48 - loss: 1.6201 - acc: 0.46 - ETA: 1:44:48 - loss: 1.6179 - acc: 0.46 - ETA: 1:43:49 - loss: 1.6160 - acc: 0.46 - ETA: 1:42:50 - loss: 1.6164 - acc: 0.46 - ETA: 1:41:51 - loss: 1.6178 - acc: 0.46 - ETA: 1:40:52 - loss: 1.6181 - acc: 0.46 - ETA: 1:39:54 - loss: 1.6197 - acc: 0.46 - ETA: 1:38:55 - loss: 1.6176 - acc: 0.46 - ETA: 1:37:58 - loss: 1.6154 - acc: 0.46 - ETA: 1:36:58 - loss: 1.6141 - acc: 0.46 - ETA: 1:35:59 - loss: 1.6137 - acc: 0.46 - ETA: 1:35:01 - loss: 1.6131 - acc: 0.46 - ETA: 1:34:03 - loss: 1.6147 - acc: 0.46 - ETA: 1:33:09 - loss: 1.6132 - acc: 0.46 - ETA: 1:32:13 - loss: 1.6111 - acc: 0.46 - ETA: 1:31:14 - loss: 1.6094 - acc: 0.46 - ETA: 1:30:19 - loss: 1.6089 - acc: 0.46 - ETA: 1:29:20 - loss: 1.6078 - acc: 0.46 - ETA: 1:28:20 - loss: 1.6051 - acc: 0.46 - ETA: 1:27:24 - loss: 1.6053 - acc: 0.46 - ETA: 1:26:28 - loss: 1.6023 - acc: 0.47 - ETA: 1:25:31 - loss: 1.5996 - acc: 0.47 - ETA: 1:24:33 - loss: 1.5990 - acc: 0.47 - ETA: 1:23:39 - loss: 1.5978 - acc: 0.47 - ETA: 1:22:40 - loss: 1.5995 - acc: 0.47 - ETA: 1:21:45 - loss: 1.6008 - acc: 0.47 - ETA: 1:20:49 - loss: 1.6009 - acc: 0.47 - ETA: 1:19:50 - loss: 1.5998 - acc: 0.47 - ETA: 1:18:53 - loss: 1.6025 - acc: 0.47 - ETA: 1:17:58 - loss: 1.6042 - acc: 0.46 - ETA: 1:17:02 - loss: 1.6031 - acc: 0.46 - ETA: 1:16:06 - loss: 1.6015 - acc: 0.46 - ETA: 1:15:09 - loss: 1.5991 - acc: 0.47 - ETA: 1:14:12 - loss: 1.5992 - acc: 0.47 - ETA: 1:13:15 - loss: 1.5978 - acc: 0.47 - ETA: 1:12:18 - loss: 1.5999 - acc: 0.46 - ETA: 1:11:23 - loss: 1.5962 - acc: 0.47 - ETA: 1:10:28 - loss: 1.5956 - acc: 0.47 - ETA: 1:09:32 - loss: 1.5949 - acc: 0.47 - ETA: 1:08:36 - loss: 1.5939 - acc: 0.47 - ETA: 1:07:40 - loss: 1.5928 - acc: 0.47 - ETA: 1:06:43 - loss: 1.5913 - acc: 0.47 - ETA: 1:05:47 - loss: 1.5898 - acc: 0.47 - ETA: 1:04:50 - loss: 1.5894 - acc: 0.47 - ETA: 1:03:54 - loss: 1.5876 - acc: 0.47 - ETA: 1:02:57 - loss: 1.5863 - acc: 0.47 - ETA: 1:02:00 - loss: 1.5870 - acc: 0.47 - ETA: 1:01:04 - loss: 1.5880 - acc: 0.47 - ETA: 1:00:08 - loss: 1.5889 - acc: 0.47 - ETA: 59:12 - loss: 1.5866 - acc: 0.4756 - ETA: 58:16 - loss: 1.5846 - acc: 0.47 - ETA: 57:21 - loss: 1.5832 - acc: 0.47 - ETA: 56:26 - loss: 1.5804 - acc: 0.47 - ETA: 55:31 - loss: 1.5780 - acc: 0.47 - ETA: 54:36 - loss: 1.5772 - acc: 0.47 - ETA: 53:40 - loss: 1.5784 - acc: 0.47 - ETA: 52:44 - loss: 1.5783 - acc: 0.47 - ETA: 51:48 - loss: 1.5792 - acc: 0.47 - ETA: 50:52 - loss: 1.5810 - acc: 0.47 - ETA: 49:58 - loss: 1.5813 - acc: 0.47 - ETA: 49:04 - loss: 1.5822 - acc: 0.47 - ETA: 48:08 - loss: 1.5826 - acc: 0.47 - ETA: 47:12 - loss: 1.5838 - acc: 0.47 - ETA: 46:18 - loss: 1.5830 - acc: 0.47 - ETA: 45:22 - loss: 1.5825 - acc: 0.47 - ETA: 44:27 - loss: 1.5826 - acc: 0.47 - ETA: 43:30 - loss: 1.5823 - acc: 0.47 - ETA: 42:36 - loss: 1.5825 - acc: 0.47 - ETA: 41:39 - loss: 1.5819 - acc: 0.47 - ETA: 40:43 - loss: 1.5804 - acc: 0.47 - ETA: 39:47 - loss: 1.5811 - acc: 0.47 - ETA: 38:52 - loss: 1.5797 - acc: 0.47 - ETA: 37:56 - loss: 1.5798 - acc: 0.47 - ETA: 37:01 - loss: 1.5785 - acc: 0.47 - ETA: 36:06 - loss: 1.5772 - acc: 0.47 - ETA: 35:11 - loss: 1.5765 - acc: 0.47 - ETA: 34:15 - loss: 1.5769 - acc: 0.47 - ETA: 33:19 - loss: 1.5778 - acc: 0.47 - ETA: 32:25 - loss: 1.5777 - acc: 0.47 - ETA: 31:30 - loss: 1.5775 - acc: 0.47 - ETA: 30:35 - loss: 1.5746 - acc: 0.47 - ETA: 29:41 - loss: 1.5758 - acc: 0.47 - ETA: 28:46 - loss: 1.5746 - acc: 0.47 - ETA: 27:51 - loss: 1.5734 - acc: 0.47 - ETA: 26:56 - loss: 1.5738 - acc: 0.47 - ETA: 26:01 - loss: 1.5746 - acc: 0.47 - ETA: 25:06 - loss: 1.5740 - acc: 0.47 - ETA: 24:11 - loss: 1.5733 - acc: 0.47 - ETA: 23:16 - loss: 1.5729 - acc: 0.47 - ETA: 22:20 - loss: 1.5730 - acc: 0.47 - ETA: 21:25 - loss: 1.5733 - acc: 0.47 - ETA: 20:29 - loss: 1.5727 - acc: 0.47 - ETA: 19:34 - loss: 1.5720 - acc: 0.47 - ETA: 18:39 - loss: 1.5727 - acc: 0.47 - ETA: 17:43 - loss: 1.5726 - acc: 0.47 - ETA: 16:48 - loss: 1.5726 - acc: 0.47 - ETA: 15:53 - loss: 1.5717 - acc: 0.47 - ETA: 14:58 - loss: 1.5721 - acc: 0.47 - ETA: 14:02 - loss: 1.5722 - acc: 0.47 - ETA: 13:07 - loss: 1.5717 - acc: 0.47 - ETA: 12:12 - loss: 1.5724 - acc: 0.47 - ETA: 11:17 - loss: 1.5729 - acc: 0.47 - ETA: 10:22 - loss: 1.5736 - acc: 0.47 - ETA: 9:26 - loss: 1.5721 - acc: 0.4746 - ETA: 8:31 - loss: 1.5720 - acc: 0.474 - ETA: 7:36 - loss: 1.5720 - acc: 0.474 - ETA: 6:41 - loss: 1.5708 - acc: 0.475 - ETA: 5:46 - loss: 1.5715 - acc: 0.474 - ETA: 4:51 - loss: 1.5723 - acc: 0.473 - ETA: 3:56 - loss: 1.5725 - acc: 0.473 - ETA: 3:00 - loss: 1.5729 - acc: 0.473 - ETA: 2:05 - loss: 1.5734 - acc: 0.473 - ETA: 1:10 - loss: 1.5730 - acc: 0.473 - ETA: 15s - loss: 1.5733 - acc: 0.473 - 10518s 2s/step - loss: 1.5737 - acc: 0.4729 - val_loss: 1.5469 - val_acc: 0.4670\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00001: val_loss improved from inf to 1.54687, saving model to C:\\Users\\syip\\Desktop\\DaSci\\Nanodegree\\ml_nanodegree\\capstone/saved_models/glove.weights.best.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x250d08c6a20>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove.fit(x_train, y_train, validation_split=0.4, epochs=1, callbacks=[glove_checkpts], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({4: 2610})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_glove = glove.predict_classes(x_test)\n",
    "Counter(y_pred_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({4: 4710, 6: 1205, 2: 268, 5: 683, 3: 1743, 1: 271, 0: 1109})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis  \n",
    "__Predicting 3 classes: Positive, Negative & Neutral__  \n",
    "  \n",
    "**Model Available:**  \n",
    "- svm  \n",
    "- dense  \n",
    "- cnn  \n",
    "- lstm  \n",
    "- conv_lstm  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dev = dev_raw.Sentiment\n",
    "z_train = train_raw.Sentiment\n",
    "z_test = test_raw.Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'negative': 0, 'neutral': 1, 'positive': 2}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_polarities = 3\n",
    "\n",
    "sen_targets, sen_uniques = pd.factorize(z_train, sort=True)\n",
    "z_train = to_categorical(sen_targets, num_polarities)\n",
    "\n",
    "sen_label_map = dict(zip(list(sen_uniques), range(num_polarities)))\n",
    "sen_label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 4710, 2: 2334, 0: 2945})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(sen_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GloVe + LSTM  \n",
    "Note: To solve the problem of LSTM always predicting the same class even when trained with balanced data, the 'return_sequences' param in the LSTM layer needs to be set to True and add a Flatten layer. In addition, 'return_sequences=True' must be set when stacking LSTM layers so that the second LSTM layer has a three-dimensional sequence inpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 20000, 100)        2000000   \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 20000, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 19996, 64)         32064     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 4999, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 4999, 128)         98816     \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 639872)            0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 3)                 1919619   \n",
      "=================================================================\n",
      "Total params: 4,050,499\n",
      "Trainable params: 2,050,499\n",
      "Non-trainable params: 2,000,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sen_glove = Sequential()\n",
    "sen_glove.add(Embedding(vocabulary_size, 100, input_length=20000, weights=[embedding_matrix], trainable=False))\n",
    "sen_glove.add(Dropout(0.2))\n",
    "sen_glove.add(Conv1D(filters=64,\n",
    "                 kernel_size=5,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1))\n",
    "sen_glove.add(MaxPooling1D(pool_size=4))\n",
    "sen_glove.add(LSTM(units=128, return_sequences=True)) \n",
    "sen_glove.add(Flatten())\n",
    "sen_glove.add(Dense(num_polarities, activation='softmax'))\n",
    "sen_glove.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "sen_glove.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "100/100 [==============================] - ETA: 2:19 - loss: 1.0988 - acc: 0.281 - ETA: 1:12 - loss: 1.0878 - acc: 0.343 - ETA: 7s - loss: 1.1251 - acc: 0.3854  - 192s 2s/step - loss: 1.1457 - acc: 0.3800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x250d85bbe80>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen_glove.fit(x_train[100:200], z_train[100:200], epochs=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 2284, 2: 199, 1: 127})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_pred_glove = sen_glove.predict_classes(x_test)\n",
    "Counter(z_pred_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 41, 2: 24, 0: 35})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(sen_targets[100:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 32.2605%\n"
     ]
    }
   ],
   "source": [
    "glove_accuracy = 100*np.sum(z_pred_glove==z_transf)/len(z_true)\n",
    "print('Test accuracy: %.4f%%' % glove_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2610, 2610)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(z_pred_glove), len(z_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
