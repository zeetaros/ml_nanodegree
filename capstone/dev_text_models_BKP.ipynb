{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from factory_func import plot_confusion_matrix\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, ENGLISH_STOP_WORDS\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, f1_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Embedding, Conv1D, Conv2D, Lambda, LSTM, ConvLSTM2D, TimeDistributed, Masking, Bidirectional\n",
    "from keras.layers import Reshape, Flatten, Dropout, Concatenate, Activation, MaxPooling1D, GlobalAveragePooling1D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Model, load_model, Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. ETL & Cleansing  \n",
    "### 2. Rebalancing (Undersampling)  \n",
    "### 3. Feature Extraction  \n",
    "### 4. Model Selection & Evaluation  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emotion Analysis  \n",
    "### Accuracy Records  \n",
    "SVM: 45.5172%  \n",
    "Dense NN: 45.1724%  \n",
    "CNN: 47.2414%  \n",
    "LSTM: tbc  \n",
    "  \n",
    "*(there might be a ceiling for how much you can improve the accuracy)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_raw = pd.read_csv(os.path.join(os.getcwd(), 'dev_sent_emo.csv'))\n",
    "train_raw = pd.read_csv(os.path.join(os.getcwd(), 'train_sent_emo.csv'))\n",
    "test_raw = pd.read_csv(os.path.join(os.getcwd(), 'test_sent_emo.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sr No.</th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Dialogue_ID</th>\n",
       "      <th>Utterance_ID</th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>StartTime</th>\n",
       "      <th>EndTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Oh my God, hes lost it. Hes totally lost it.</td>\n",
       "      <td>Phoebe</td>\n",
       "      <td>sadness</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>00:20:57,256</td>\n",
       "      <td>00:21:00,049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>What?</td>\n",
       "      <td>Monica</td>\n",
       "      <td>surprise</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>00:21:01,927</td>\n",
       "      <td>00:21:03,261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Or! Or, we could go to the bank, close our acc...</td>\n",
       "      <td>Ross</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>00:12:24,660</td>\n",
       "      <td>00:12:30,915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Youre a genius!</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>joy</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>00:12:32,334</td>\n",
       "      <td>00:12:33,960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Aww, man, now we wont be bank buddies!</td>\n",
       "      <td>Joey</td>\n",
       "      <td>sadness</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>00:12:34,211</td>\n",
       "      <td>00:12:37,505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sr No.                                          Utterance   Speaker  \\\n",
       "0       1     Oh my God, hes lost it. Hes totally lost it.    Phoebe   \n",
       "1       2                                              What?    Monica   \n",
       "2       3  Or! Or, we could go to the bank, close our acc...      Ross   \n",
       "3       4                                   Youre a genius!  Chandler   \n",
       "4       5            Aww, man, now we wont be bank buddies!      Joey   \n",
       "\n",
       "    Emotion Sentiment  Dialogue_ID  Utterance_ID  Season  Episode  \\\n",
       "0   sadness  negative            0             0       4        7   \n",
       "1  surprise  negative            0             1       4        7   \n",
       "2   neutral   neutral            1             0       4        4   \n",
       "3       joy  positive            1             1       4        4   \n",
       "4   sadness  negative            1             2       4        4   \n",
       "\n",
       "      StartTime       EndTime  \n",
       "0  00:20:57,256  00:21:00,049  \n",
       "1  00:21:01,927  00:21:03,261  \n",
       "2  00:12:24,660  00:12:30,915  \n",
       "3  00:12:32,334  00:12:33,960  \n",
       "4  00:12:34,211  00:12:37,505  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_raw.Utterance = dev_raw.Utterance.apply(lambda x: re.sub('\\\\x92', \"'\", x))\n",
    "train_raw.Utterance = train_raw.Utterance.apply(lambda x: re.sub('\\\\x92', \"'\", x))\n",
    "test_raw.Utterance = test_raw.Utterance.apply(lambda x: re.sub('\\\\x92', \"'\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dev = dev_raw.Utterance\n",
    "y_dev = dev_raw.Emotion\n",
    "x_train = train_raw.Utterance\n",
    "y_train = train_raw.Emotion\n",
    "x_test = test_raw.Utterance\n",
    "y_test = test_raw.Emotion\n",
    "z_dev = dev_raw.Sentiment\n",
    "z_train = train_raw.Sentiment\n",
    "z_test = test_raw.Sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tfidf + SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(lowercase=True, stop_words='english', ngram_range=(1,3))\n",
    "tfidf.fit(x_train)\n",
    "x_dev_tf = tfidf.transform(x_dev)\n",
    "x_train_tf = tfidf.transform(x_train)\n",
    "x_test_tf = tfidf.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svd = TruncatedSVD(n_components=300)\n",
    "# x_dev_tr = svd.fit_transform(x_dev_tf)\n",
    "# x_train_tr = svd.fit_transform(x_train_tf)\n",
    "# x_test_tr = svd.fit_transform(x_test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(C=10, kernel='linear', probability=True)\n",
    "# param_grid = { \n",
    "#     'C': [1,10,100], 'kernel': ['linear', 'rbf']\n",
    "# }\n",
    "# clf = GridSearchCV(estimator=svm, param_grid=param_grid, cv=5)\n",
    "# clf.fit(x_train_tr, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Best model by GridSearchCV**  \n",
    "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,  \n",
    "decision_function_shape='ovr', degree=3, gamma='auto_deprecated',  \n",
    "kernel='linear', max_iter=-1, probability=True, random_state=None,  \n",
    "shrinking=True, tol=0.001, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.fit(X=x_train_tf, y=y_train)\n",
    "y_pred_svm = svm.predict(x_test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42923347861223476"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=y_pred_svm, y_true=y_test, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 45.5172%\n"
     ]
    }
   ],
   "source": [
    "svm_accuracy = 100*np.sum(y_pred_svm==y_test)/len(y_pred_svm)\n",
    "print('Test accuracy: %.4f%%' % svm_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras TF-IDF tokenizer + Neural nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural network won't accept sentences with different dimension(i.e. number of words) as input. By padding the inputs, we decide the maximum length of words in a sentence, then zero pads the rest, if the input length is shorter than the designated length. In the case where it exceeds the maximum length, then it will also truncate either from the beginning or from the end.  \n",
    "*Ref_1* https://keras.io/preprocessing/sequence/  \n",
    "*Ref_2* https://towardsdatascience.com/another-twitter-sentiment-analysis-with-python-part-11-cnn-word2vec-41f5e28eda74\n",
    "\n",
    "https://medium.com/@sabber/classifying-yelp-review-comments-using-lstm-and-word-embeddings-part-1-eb2275e4066b\n",
    "#### Dense - Fully Connected Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For emotion analysis\n",
    "num_classes = 7\n",
    "# For sentiment analysis\n",
    "num_polarities = 3\n",
    "\n",
    "vocabulary_size = 20000\n",
    "tokenizer = Tokenizer(num_words= vocabulary_size)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "x_train = tokenizer.texts_to_matrix(x_train, mode='tfidf')\n",
    "x_test = tokenizer.texts_to_matrix(x_test, mode='tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anger': 0,\n",
       " 'disgust': 1,\n",
       " 'fear': 2,\n",
       " 'joy': 3,\n",
       " 'neutral': 4,\n",
       " 'sadness': 5,\n",
       " 'surprise': 6}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prep target labels for emotion analysis\n",
    "targets, uniques = pd.factorize(y_train, sort=True)\n",
    "y_train = to_categorical(targets, num_classes)\n",
    "\n",
    "label_map = dict(zip(list(uniques), range(num_classes)))\n",
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'negative': 0, 'neutral': 1, 'positive': 2}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prep target labels for sentiment analysis\n",
    "sen_targets, sen_uniques = pd.factorize(z_train, sort=True)\n",
    "z_train = to_categorical(sen_targets, num_polarities)\n",
    "\n",
    "sen_label_map = dict(zip(list(sen_uniques), range(num_polarities)))\n",
    "sen_label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenizer.fit_on_sequences(x_dev)\n",
    "# tokenizer.texts_to_sequences(x_dev)\n",
    "# tokenizer.texts_to_matrix(x_dev, mode='tfidf')\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 1.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_transf = list(map(label_map.get, y_test))\n",
    "z_transf = list(map(sen_label_map.get, z_test))\n",
    "y_true = to_categorical(np.array(y_transf), num_classes)\n",
    "z_true = to_categorical(np.array(z_transf), num_polarities)\n",
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_checkpts = ModelCheckpoint(filepath=os.path.join(os.getcwd() + '/saved_models/text/emotion/dense.weights.best.hdf5'), \n",
    "                               verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/cheuky/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 32)                640032    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 651,367\n",
      "Trainable params: 651,367\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_classes = 7\n",
    "\n",
    "dense = Sequential()\n",
    "dense.add(Dense(32, activation='relu', input_dim=20000))\n",
    "# model.add(Dropout(0.2))\n",
    "dense.add(Dense(64, activation='relu'))\n",
    "dense.add(Dense(128, activation='relu'))\n",
    "dense.add(Dense(num_classes, activation='softmax'))\n",
    "dense.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "dense.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conv1D is generally good for text, whereas Conv2D is good for audio and images where spatial matter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/cheuky/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 5993 samples, validate on 3996 samples\n",
      "Epoch 1/10\n",
      "5993/5993 [==============================] - 3s 427us/step - loss: 1.5417 - acc: 0.4757 - val_loss: 1.4436 - val_acc: 0.4880\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.44364, saving model to /Users/cheuky/Documents/Code_Blue/ml_nanodegree/capstone/saved_models/text/emotion/dense.weights.best.hdf5\n",
      "Epoch 2/10\n",
      "5993/5993 [==============================] - 2s 264us/step - loss: 1.1467 - acc: 0.5985 - val_loss: 1.5058 - val_acc: 0.4735\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.44364\n",
      "Epoch 3/10\n",
      "5993/5993 [==============================] - 2s 307us/step - loss: 0.7818 - acc: 0.7280 - val_loss: 1.8114 - val_acc: 0.4770\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.44364\n",
      "Epoch 4/10\n",
      "5993/5993 [==============================] - 2s 308us/step - loss: 0.5549 - acc: 0.8079 - val_loss: 2.1546 - val_acc: 0.4700\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.44364\n",
      "Epoch 5/10\n",
      "5993/5993 [==============================] - 2s 268us/step - loss: 0.4129 - acc: 0.8620 - val_loss: 2.4220 - val_acc: 0.4282\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.44364\n",
      "Epoch 6/10\n",
      "5993/5993 [==============================] - 2s 298us/step - loss: 0.3245 - acc: 0.8925 - val_loss: 2.7086 - val_acc: 0.4329\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.44364\n",
      "Epoch 7/10\n",
      "5993/5993 [==============================] - 2s 361us/step - loss: 0.2793 - acc: 0.9051 - val_loss: 2.9520 - val_acc: 0.4424\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.44364\n",
      "Epoch 8/10\n",
      "5993/5993 [==============================] - 2s 265us/step - loss: 0.2443 - acc: 0.9157 - val_loss: 3.1706 - val_acc: 0.4492\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.44364\n",
      "Epoch 9/10\n",
      "5993/5993 [==============================] - 2s 285us/step - loss: 0.2239 - acc: 0.9229 - val_loss: 3.3144 - val_acc: 0.4374\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.44364\n",
      "Epoch 10/10\n",
      "5993/5993 [==============================] - 2s 313us/step - loss: 0.2079 - acc: 0.9249 - val_loss: 3.5481 - val_acc: 0.4522\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.44364\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x116c0cc50>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense.fit(x_train, y_train, validation_split=0.4, epochs=10, callbacks=[dense_checkpts], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data = pad_sequences(tokenizer.texts_to_sequences(x_test), maxlen=50)\n",
    "y_pred_dense = dense.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({4: 1535, 3: 383, 0: 284, 5: 145, 1: 26, 6: 199, 2: 38})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_pred_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2610/2610 [==============================] - 0s 82us/step\n",
      "Test accuracy: 45.8621%\n"
     ]
    }
   ],
   "source": [
    "# test_accuracy = 100*np.sum(y_pred_dense==y_true)/len(y_true)\n",
    "# print('Test accuracy: %.4f%%' % test_accuracy)\n",
    "dense_accuracy = dense.evaluate(x_test, y_true, batch_size=128)[1] * 100\n",
    "print('Test accuracy: %.4f%%' % dense_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['anger', 'disgust', 'fear', 'joy', 'neutral', 'sadness', 'surprise'], dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__About batch_size__  \n",
    "Advantages of using a batch size < number of all samples:\n",
    "\n",
    "- It requires less memory. Since you train the network using fewer samples, the overall training procedure requires less memory. That's especially important if you are not able to fit the whole dataset in your machine's memory.\n",
    "\n",
    "- Typically networks train faster with mini-batches. That's because we update the weights after each propagation. In our example we've propagated 11 batches (10 of them had 100 samples and 1 had 50 samples) and after each of them we've updated our network's parameters. If we used all samples during propagation we would make only 1 update for the network's parameter.\n",
    "\n",
    "Disadvantages of using a batch size < number of all samples:\n",
    "\n",
    "- The smaller the batch the less accurate the estimate of the gradient will be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN - Convolutional Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 7\n",
    "n_length = x_train.shape[0]\n",
    "n_features = x_train.shape[1]\n",
    "\n",
    "x_train_reshaped = x_train.reshape(n_length, n_features, 1)\n",
    "x_test_reshaped = x_test.reshape(x_test.shape[0], n_features, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_checkpts = ModelCheckpoint(filepath=os.path.join(os.getcwd() + '/saved_models/text/emotion/cnn.weights.best.hdf5'), \n",
    "                               verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_CNN(num_classes):\n",
    "    cnn = Sequential()\n",
    "    cnn.add(Conv1D(filters=16, kernel_size=2, padding='same', activation='relu', input_shape=(n_features, 1)))\n",
    "    cnn.add(MaxPooling1D(pool_size=2))\n",
    "    cnn.add(Conv1D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "    cnn.add(MaxPooling1D(pool_size=2))\n",
    "    cnn.add(Conv1D(filters=64, kernel_size=2, padding='same', activation='relu'))\n",
    "    cnn.add(MaxPooling1D(pool_size=2))\n",
    "    # cnn.add(GlobalAveragePooling1D())\n",
    "    cnn.add(Flatten())\n",
    "    cnn.add(Dense(128, activation='relu'))\n",
    "    cnn.add(Dense(num_classes, activation='softmax'))\n",
    "    cnn.compile(optimizer='adam',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    print(cnn.summary())\n",
    "    return cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 20000, 16)         48        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 10000, 16)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 10000, 32)         1056      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 5000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 5000, 64)          4160      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 2500, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 160000)            0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               20480128  \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 20,486,295\n",
      "Trainable params: 20,486,295\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "cnn = build_CNN(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5993 samples, validate on 3996 samples\n",
      "Epoch 1/5\n",
      "5993/5993 [==============================] - 123s 21ms/step - loss: 1.5272 - acc: 0.4744 - val_loss: 1.4688 - val_acc: 0.4767\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.46878, saving model to /Users/cheuky/Documents/Code_Blue/ml_nanodegree/capstone/saved_models/text/emotion/cnn.weights.best.hdf5\n",
      "Epoch 2/5\n",
      "5993/5993 [==============================] - 126s 21ms/step - loss: 1.2066 - acc: 0.5618 - val_loss: 1.5293 - val_acc: 0.4745\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.46878\n",
      "Epoch 3/5\n",
      "5993/5993 [==============================] - 130s 22ms/step - loss: 0.8297 - acc: 0.6971 - val_loss: 1.8249 - val_acc: 0.4637\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.46878\n",
      "Epoch 4/5\n",
      "5993/5993 [==============================] - 125s 21ms/step - loss: 0.5794 - acc: 0.7868 - val_loss: 2.2210 - val_acc: 0.4660\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.46878\n",
      "Epoch 5/5\n",
      "5993/5993 [==============================] - 121s 20ms/step - loss: 0.4303 - acc: 0.8408 - val_loss: 2.6364 - val_acc: 0.4535\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.46878\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1acdd0278>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(x_train_reshaped, y_train, validation_split=0.4, epochs=5, callbacks=[cnn_checkpts], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({4: 1647, 0: 183, 3: 235, 5: 117, 1: 28, 6: 363, 2: 37})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_cnn = cnn.predict_classes(x_test_reshaped)\n",
    "# y_pred_cnn = [np.argmax(x) for x in cnn.predict(x_test_reshaped)]\n",
    "Counter(y_pred_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2610/2610 [==============================] - 12s 5ms/step\n",
      "Test accuracy: 46.4751%\n"
     ]
    }
   ],
   "source": [
    "# cnn_accuracy = 100*np.sum(y_pred_cnn==y_true)/len(y_pred_cnn)\n",
    "# print('Test accuracy: %.4f%%' % cnn_accuracy)\n",
    "cnn_accuracy = cnn.evaluate(x_test_reshaped, y_true, batch_size=128)[1] * 100\n",
    "print('Test accuracy: %.4f%%' % cnn_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn_score = cnn.evaluate(x_test_reshaped, y_pred_cnn, verbose=1)\n",
    "# print(\"%s: %.2f%%\" % (cnn.metrics_names[1], cnn_score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Serialise the model architecture to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(os.getcwd(), \"saved_models\", \"text\", \"emotion\", \"cnn.model.json\", \"w\") as json_file:\n",
    "    json_file.write(cnn.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json and create model\n",
    "json_file = open('./saved_models/text/emotion/cnn.json', 'r')\n",
    "loaded_cnn_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_cnn = model_from_json(loaded_cnn_json)\n",
    "# load weights into new model\n",
    "loaded_cnn.load_weights(\"cnn.weights.best.hdf5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENGLISH_STOP_WORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WordEnbedding + LSTM  \n",
    "- checkpoint: try a pre-trained embedding layer e.g. GloVe Embedding, Word2Vec  \n",
    "  \n",
    "Building the embedding from scratch instead of using pre-trained (*this can be a slower approach, but tailors the model to a specific training dataset*)  \n",
    "\n",
    "Ref_1: https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_checkpts = ModelCheckpoint(filepath=os.path.join(os.getcwd() + '/saved_models/text/emotion/lstm.weights.best.hdf5'), \n",
    "                               verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_13 (Embedding)     (None, 20000, 128)        2560000   \n",
      "_________________________________________________________________\n",
      "lstm_13 (LSTM)               (None, 20000, 64)         49408     \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 1280000)           0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 7)                 8960007   \n",
      "=================================================================\n",
      "Total params: 11,569,415\n",
      "Trainable params: 11,569,415\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocabulary_size = 20000\n",
    "embedding_size=128\n",
    "lstm_output_size=64  #70\n",
    "num_classes=7\n",
    "\n",
    "lstm = Sequential()\n",
    "lstm.add(Embedding(input_dim=vocabulary_size, output_dim=embedding_size, input_length=20000))\n",
    "lstm.add(LSTM(units=lstm_output_size, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n",
    "lstm.add(Flatten())\n",
    "lstm.add(Dense(num_classes, activation='sigmoid'))\n",
    "          \n",
    "lstm.compile(loss='categorical_crossentropy',\n",
    "            optimizer='adam',\n",
    "            metrics=['accuracy'])\n",
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5993 samples, validate on 3996 samples\n",
      "Epoch 1/3\n",
      "5993/5993 [==============================] - 1072s 179ms/step - loss: 1.5608 - acc: 0.4726 - val_loss: 1.5449 - val_acc: 0.4670\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.54495, saving model to C:\\Users\\syip\\Desktop\\DaSci\\Nanodegree\\ml_nanodegree\\capstone/saved_models/lstm.weights.best.hdf5\n",
      "Epoch 2/3\n",
      "5993/5993 [==============================] - 1074s 179ms/step - loss: 1.5429 - acc: 0.4746 - val_loss: 1.5357 - val_acc: 0.4670\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.54495 to 1.53567, saving model to C:\\Users\\syip\\Desktop\\DaSci\\Nanodegree\\ml_nanodegree\\capstone/saved_models/lstm.weights.best.hdf5\n",
      "Epoch 3/3\n",
      "5993/5993 [==============================] - 1067s 178ms/step - loss: 1.5419 - acc: 0.4746 - val_loss: 1.5396 - val_acc: 0.4670\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.53567\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f206cfb550>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.fit(x_train, y_train, validation_split=0.4, epochs=1, callbacks=[lstm_checkpts], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({4: 2610})"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_lstm = lstm.predict_classes(x_test)\n",
    "Counter(y_pred_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_accuracy = 100*np.sum(y_pred_lstm==y_true)/len(y_pred_lstm)\n",
    "print('Test accuracy: %.4f%%' % lstm_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_lstm = load_model('./saved_models/text/emotion/lstm.weights.best.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 4, 4, 4, 4], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_lstm.predict_classes(x_test[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WordEmbedding + ConvLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, 20000, 128)        2560000   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 20000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 19996, 64)         41024     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 4999, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 4999, 32)          12416     \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 159968)            0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 7)                 1119783   \n",
      "=================================================================\n",
      "Total params: 3,733,223\n",
      "Trainable params: 3,733,223\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "max_features=20000\n",
    "embedding_size=128\n",
    "lstm_output_size=32  #70\n",
    "num_classes=7\n",
    "\n",
    "conv_lstm = Sequential()\n",
    "conv_lstm.add(Embedding(input_dim=max_features, output_dim=embedding_size, input_length=20000))\n",
    "conv_lstm.add(Dropout(0.25))\n",
    "conv_lstm.add(Conv1D(filters=64,\n",
    "                 kernel_size=5,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1))\n",
    "conv_lstm.add(MaxPooling1D(pool_size=4))\n",
    "conv_lstm.add(LSTM(units=lstm_output_size, return_sequences=True))\n",
    "conv_lstm.add(Flatten())\n",
    "conv_lstm.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "conv_lstm.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "conv_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_lstm_checkpts = ModelCheckpoint(filepath=os.path.join(os.getcwd() + '/saved_models/text/emotion/conv_lstm.weights.best.hdf5'), \n",
    "                               verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_lstm.fit(x_train, y_train, validation_split=0.4, callback=[conv_lstm_checkpts], epochs=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({4: 2610})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_conv_lstm = conv_lstm.predict_classes(x_test)\n",
    "Counter(y_pred_conv_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.0000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syip\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "conv_lstm_accuracy = 100*np.sum(y_pred_conv_lstm==y_true)/len(y_true)\n",
    "print('Test accuracy: %.4f%%' % conv_lstm_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec  \n",
    "Do transfer learning with pre-trained word embedding layers, such as Word2Vec & GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dev_tokens = [sentence.split() for sentence in x_dev]\n",
    "x_train_tokens = [sentence.split() for sentence in x_train]\n",
    "\n",
    "model = Word2Vec(\n",
    "    x_train_tokens,\n",
    "    size=150,\n",
    "    window=10,\n",
    "    min_count=2,\n",
    "    workers=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first parameter passed to gensim.models.Word2Vec is an iterable of sentences. Sentences themselves are a list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(x_train_tokens, total_examples=len(x_train), epochs=10)\n",
    "\n",
    "w = ['good']\n",
    "# w = filter(lambda x: x in model.vocab, x_train.tokens)\n",
    "model.wv.most_similar(positive=w,\n",
    "#                       topn=6\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GloVe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract word embeddings from the Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = dict()\n",
    "f = open('../../saved_models/glove.6B.100d.txt', encoding=\"utf8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a weight matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size=20000\n",
    "\n",
    "embedding_matrix = np.zeros((vocabulary_size, 100))\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    if index > vocabulary_size - 1:\n",
    "        break\n",
    "    else:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[index] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create ConvLSTM model with GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ConvLSTM(num_classes, dense_activation=None, optimizer=None, use_glove=None):\n",
    "    dense_activation = dense_activation or 'sigmoid'\n",
    "    optimizer = optimizer or 'adam'\n",
    "    use_glove = use_glove or True\n",
    "    max_features=20000\n",
    "    embedding_size=100\n",
    "    lstm_output_size=128\n",
    "    \n",
    "    model = Sequential()\n",
    "    if use_glove:\n",
    "        model.add(Embedding(input_dim=vocabulary_size, output_dim=embedding_size, input_length=20000,\n",
    "                            weights=[embedding_matrix], trainable=False))\n",
    "    else:\n",
    "        model.add(Embedding(input_dim=vocabulary_size, output_dim=embedding_size, input_length=20000))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv1D(filters=64,\n",
    "                     kernel_size=5,\n",
    "                     padding='valid',\n",
    "                     activation='relu',\n",
    "                     strides=1))\n",
    "    model.add(MaxPooling1D(pool_size=4))\n",
    "    model.add(LSTM(units=lstm_output_size, return_sequences=True))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(TimeDistributed(Dense(32)))\n",
    "#     model.add(Flatten())\n",
    "    model.add(GlobalAveragePooling1D())\n",
    "    model.add(Dense(num_classes, activation=dense_activation))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\syip\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 5993 samples, validate on 3996 samples\n",
      "Epoch 1/1\n",
      "5993/5993 [==============================] - ETA: 3:19:05 - loss: 1.9459 - acc: 0.18 - ETA: 3:15:05 - loss: 1.9447 - acc: 0.34 - ETA: 3:07:14 - loss: 1.9431 - acc: 0.40 - ETA: 3:03:22 - loss: 1.9421 - acc: 0.41 - ETA: 3:02:30 - loss: 1.9413 - acc: 0.40 - ETA: 3:00:31 - loss: 1.9404 - acc: 0.39 - ETA: 2:58:45 - loss: 1.9382 - acc: 0.40 - ETA: 2:57:20 - loss: 1.9364 - acc: 0.39 - ETA: 2:55:46 - loss: 1.9335 - acc: 0.40 - ETA: 2:54:50 - loss: 1.9295 - acc: 0.40 - ETA: 2:53:49 - loss: 1.9201 - acc: 0.42 - ETA: 2:54:11 - loss: 1.9096 - acc: 0.43 - ETA: 2:53:43 - loss: 1.8961 - acc: 0.43 - ETA: 2:53:01 - loss: 1.8770 - acc: 0.44 - ETA: 2:52:27 - loss: 1.8598 - acc: 0.44 - ETA: 2:52:09 - loss: 1.8400 - acc: 0.45 - ETA: 2:51:38 - loss: 1.8327 - acc: 0.44 - ETA: 2:50:57 - loss: 1.8168 - acc: 0.45 - ETA: 2:48:58 - loss: 1.8044 - acc: 0.45 - ETA: 2:47:00 - loss: 1.7974 - acc: 0.45 - ETA: 2:45:22 - loss: 1.7902 - acc: 0.44 - ETA: 2:43:51 - loss: 1.7789 - acc: 0.45 - ETA: 2:42:04 - loss: 1.7771 - acc: 0.44 - ETA: 2:40:17 - loss: 1.7629 - acc: 0.45 - ETA: 2:38:46 - loss: 1.7547 - acc: 0.45 - ETA: 2:37:13 - loss: 1.7510 - acc: 0.44 - ETA: 2:35:50 - loss: 1.7481 - acc: 0.44 - ETA: 2:34:29 - loss: 1.7336 - acc: 0.45 - ETA: 2:33:05 - loss: 1.7284 - acc: 0.45 - ETA: 2:31:39 - loss: 1.7176 - acc: 0.45 - ETA: 2:30:17 - loss: 1.7083 - acc: 0.45 - ETA: 2:28:55 - loss: 1.6981 - acc: 0.46 - ETA: 2:27:44 - loss: 1.7018 - acc: 0.45 - ETA: 2:26:24 - loss: 1.6922 - acc: 0.46 - ETA: 2:25:18 - loss: 1.6919 - acc: 0.46 - ETA: 2:24:01 - loss: 1.6939 - acc: 0.45 - ETA: 2:22:50 - loss: 1.6869 - acc: 0.46 - ETA: 2:21:42 - loss: 1.6811 - acc: 0.46 - ETA: 2:20:35 - loss: 1.6769 - acc: 0.46 - ETA: 2:19:22 - loss: 1.6750 - acc: 0.46 - ETA: 2:18:13 - loss: 1.6700 - acc: 0.46 - ETA: 2:17:11 - loss: 1.6684 - acc: 0.46 - ETA: 2:16:04 - loss: 1.6689 - acc: 0.46 - ETA: 2:14:52 - loss: 1.6689 - acc: 0.46 - ETA: 2:13:51 - loss: 1.6672 - acc: 0.46 - ETA: 2:12:47 - loss: 1.6672 - acc: 0.46 - ETA: 2:11:47 - loss: 1.6636 - acc: 0.46 - ETA: 2:10:43 - loss: 1.6578 - acc: 0.46 - ETA: 2:09:40 - loss: 1.6550 - acc: 0.46 - ETA: 2:08:33 - loss: 1.6498 - acc: 0.46 - ETA: 2:07:29 - loss: 1.6477 - acc: 0.46 - ETA: 2:06:24 - loss: 1.6438 - acc: 0.46 - ETA: 2:05:24 - loss: 1.6384 - acc: 0.46 - ETA: 2:04:30 - loss: 1.6362 - acc: 0.47 - ETA: 2:03:33 - loss: 1.6353 - acc: 0.47 - ETA: 2:02:33 - loss: 1.6338 - acc: 0.46 - ETA: 2:01:40 - loss: 1.6345 - acc: 0.46 - ETA: 2:00:51 - loss: 1.6276 - acc: 0.47 - ETA: 1:59:53 - loss: 1.6276 - acc: 0.47 - ETA: 1:58:57 - loss: 1.6298 - acc: 0.47 - ETA: 1:58:01 - loss: 1.6247 - acc: 0.47 - ETA: 1:57:04 - loss: 1.6240 - acc: 0.47 - ETA: 1:56:04 - loss: 1.6213 - acc: 0.47 - ETA: 1:55:06 - loss: 1.6191 - acc: 0.47 - ETA: 1:54:11 - loss: 1.6210 - acc: 0.47 - ETA: 1:53:15 - loss: 1.6213 - acc: 0.46 - ETA: 1:52:17 - loss: 1.6211 - acc: 0.46 - ETA: 1:51:20 - loss: 1.6228 - acc: 0.46 - ETA: 1:50:22 - loss: 1.6224 - acc: 0.46 - ETA: 1:49:25 - loss: 1.6219 - acc: 0.46 - ETA: 1:48:30 - loss: 1.6226 - acc: 0.46 - ETA: 1:47:30 - loss: 1.6222 - acc: 0.46 - ETA: 1:46:47 - loss: 1.6163 - acc: 0.46 - ETA: 1:45:48 - loss: 1.6201 - acc: 0.46 - ETA: 1:44:48 - loss: 1.6179 - acc: 0.46 - ETA: 1:43:49 - loss: 1.6160 - acc: 0.46 - ETA: 1:42:50 - loss: 1.6164 - acc: 0.46 - ETA: 1:41:51 - loss: 1.6178 - acc: 0.46 - ETA: 1:40:52 - loss: 1.6181 - acc: 0.46 - ETA: 1:39:54 - loss: 1.6197 - acc: 0.46 - ETA: 1:38:55 - loss: 1.6176 - acc: 0.46 - ETA: 1:37:58 - loss: 1.6154 - acc: 0.46 - ETA: 1:36:58 - loss: 1.6141 - acc: 0.46 - ETA: 1:35:59 - loss: 1.6137 - acc: 0.46 - ETA: 1:35:01 - loss: 1.6131 - acc: 0.46 - ETA: 1:34:03 - loss: 1.6147 - acc: 0.46 - ETA: 1:33:09 - loss: 1.6132 - acc: 0.46 - ETA: 1:32:13 - loss: 1.6111 - acc: 0.46 - ETA: 1:31:14 - loss: 1.6094 - acc: 0.46 - ETA: 1:30:19 - loss: 1.6089 - acc: 0.46 - ETA: 1:29:20 - loss: 1.6078 - acc: 0.46 - ETA: 1:28:20 - loss: 1.6051 - acc: 0.46 - ETA: 1:27:24 - loss: 1.6053 - acc: 0.46 - ETA: 1:26:28 - loss: 1.6023 - acc: 0.47 - ETA: 1:25:31 - loss: 1.5996 - acc: 0.47 - ETA: 1:24:33 - loss: 1.5990 - acc: 0.47 - ETA: 1:23:39 - loss: 1.5978 - acc: 0.47 - ETA: 1:22:40 - loss: 1.5995 - acc: 0.47 - ETA: 1:21:45 - loss: 1.6008 - acc: 0.47 - ETA: 1:20:49 - loss: 1.6009 - acc: 0.47 - ETA: 1:19:50 - loss: 1.5998 - acc: 0.47 - ETA: 1:18:53 - loss: 1.6025 - acc: 0.47 - ETA: 1:17:58 - loss: 1.6042 - acc: 0.46 - ETA: 1:17:02 - loss: 1.6031 - acc: 0.46 - ETA: 1:16:06 - loss: 1.6015 - acc: 0.46 - ETA: 1:15:09 - loss: 1.5991 - acc: 0.47 - ETA: 1:14:12 - loss: 1.5992 - acc: 0.47 - ETA: 1:13:15 - loss: 1.5978 - acc: 0.47 - ETA: 1:12:18 - loss: 1.5999 - acc: 0.46 - ETA: 1:11:23 - loss: 1.5962 - acc: 0.47 - ETA: 1:10:28 - loss: 1.5956 - acc: 0.47 - ETA: 1:09:32 - loss: 1.5949 - acc: 0.47 - ETA: 1:08:36 - loss: 1.5939 - acc: 0.47 - ETA: 1:07:40 - loss: 1.5928 - acc: 0.47 - ETA: 1:06:43 - loss: 1.5913 - acc: 0.47 - ETA: 1:05:47 - loss: 1.5898 - acc: 0.47 - ETA: 1:04:50 - loss: 1.5894 - acc: 0.47 - ETA: 1:03:54 - loss: 1.5876 - acc: 0.47 - ETA: 1:02:57 - loss: 1.5863 - acc: 0.47 - ETA: 1:02:00 - loss: 1.5870 - acc: 0.47 - ETA: 1:01:04 - loss: 1.5880 - acc: 0.47 - ETA: 1:00:08 - loss: 1.5889 - acc: 0.47 - ETA: 59:12 - loss: 1.5866 - acc: 0.4756 - ETA: 58:16 - loss: 1.5846 - acc: 0.47 - ETA: 57:21 - loss: 1.5832 - acc: 0.47 - ETA: 56:26 - loss: 1.5804 - acc: 0.47 - ETA: 55:31 - loss: 1.5780 - acc: 0.47 - ETA: 54:36 - loss: 1.5772 - acc: 0.47 - ETA: 53:40 - loss: 1.5784 - acc: 0.47 - ETA: 52:44 - loss: 1.5783 - acc: 0.47 - ETA: 51:48 - loss: 1.5792 - acc: 0.47 - ETA: 50:52 - loss: 1.5810 - acc: 0.47 - ETA: 49:58 - loss: 1.5813 - acc: 0.47 - ETA: 49:04 - loss: 1.5822 - acc: 0.47 - ETA: 48:08 - loss: 1.5826 - acc: 0.47 - ETA: 47:12 - loss: 1.5838 - acc: 0.47 - ETA: 46:18 - loss: 1.5830 - acc: 0.47 - ETA: 45:22 - loss: 1.5825 - acc: 0.47 - ETA: 44:27 - loss: 1.5826 - acc: 0.47 - ETA: 43:30 - loss: 1.5823 - acc: 0.47 - ETA: 42:36 - loss: 1.5825 - acc: 0.47 - ETA: 41:39 - loss: 1.5819 - acc: 0.47 - ETA: 40:43 - loss: 1.5804 - acc: 0.47 - ETA: 39:47 - loss: 1.5811 - acc: 0.47 - ETA: 38:52 - loss: 1.5797 - acc: 0.47 - ETA: 37:56 - loss: 1.5798 - acc: 0.47 - ETA: 37:01 - loss: 1.5785 - acc: 0.47 - ETA: 36:06 - loss: 1.5772 - acc: 0.47 - ETA: 35:11 - loss: 1.5765 - acc: 0.47 - ETA: 34:15 - loss: 1.5769 - acc: 0.47 - ETA: 33:19 - loss: 1.5778 - acc: 0.47 - ETA: 32:25 - loss: 1.5777 - acc: 0.47 - ETA: 31:30 - loss: 1.5775 - acc: 0.47 - ETA: 30:35 - loss: 1.5746 - acc: 0.47 - ETA: 29:41 - loss: 1.5758 - acc: 0.47 - ETA: 28:46 - loss: 1.5746 - acc: 0.47 - ETA: 27:51 - loss: 1.5734 - acc: 0.47 - ETA: 26:56 - loss: 1.5738 - acc: 0.47 - ETA: 26:01 - loss: 1.5746 - acc: 0.47 - ETA: 25:06 - loss: 1.5740 - acc: 0.47 - ETA: 24:11 - loss: 1.5733 - acc: 0.47 - ETA: 23:16 - loss: 1.5729 - acc: 0.47 - ETA: 22:20 - loss: 1.5730 - acc: 0.47 - ETA: 21:25 - loss: 1.5733 - acc: 0.47 - ETA: 20:29 - loss: 1.5727 - acc: 0.47 - ETA: 19:34 - loss: 1.5720 - acc: 0.47 - ETA: 18:39 - loss: 1.5727 - acc: 0.47 - ETA: 17:43 - loss: 1.5726 - acc: 0.47 - ETA: 16:48 - loss: 1.5726 - acc: 0.47 - ETA: 15:53 - loss: 1.5717 - acc: 0.47 - ETA: 14:58 - loss: 1.5721 - acc: 0.47 - ETA: 14:02 - loss: 1.5722 - acc: 0.47 - ETA: 13:07 - loss: 1.5717 - acc: 0.47 - ETA: 12:12 - loss: 1.5724 - acc: 0.47 - ETA: 11:17 - loss: 1.5729 - acc: 0.47 - ETA: 10:22 - loss: 1.5736 - acc: 0.47 - ETA: 9:26 - loss: 1.5721 - acc: 0.4746 - ETA: 8:31 - loss: 1.5720 - acc: 0.474 - ETA: 7:36 - loss: 1.5720 - acc: 0.474 - ETA: 6:41 - loss: 1.5708 - acc: 0.475 - ETA: 5:46 - loss: 1.5715 - acc: 0.474 - ETA: 4:51 - loss: 1.5723 - acc: 0.473 - ETA: 3:56 - loss: 1.5725 - acc: 0.473 - ETA: 3:00 - loss: 1.5729 - acc: 0.473 - ETA: 2:05 - loss: 1.5734 - acc: 0.473 - ETA: 1:10 - loss: 1.5730 - acc: 0.473 - ETA: 15s - loss: 1.5733 - acc: 0.473 - 10518s 2s/step - loss: 1.5737 - acc: 0.4729 - val_loss: 1.5469 - val_acc: 0.4670\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.54687, saving model to C:\\Users\\syip\\Desktop\\DaSci\\Nanodegree\\ml_nanodegree\\capstone/saved_models/glove.weights.best.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x250d08c6a20>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_checkpts = ModelCheckpoint(filepath=os.path.join(os.getcwd() + '/saved_models/text/emotion/glove.weights.best.hdf5'), \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "glove.fit(x_train, y_train, validation_split=0.4, epochs=1, callbacks=[glove_checkpts], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({4: 2610})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_glove = glove.predict_classes(x_test)\n",
    "Counter(y_pred_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({4: 4710, 6: 1205, 2: 268, 5: 683, 3: 1743, 1: 271, 0: 1109})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis  \n",
    "__Predicting 3 classes: Positive, Negative & Neutral__  \n",
    "  \n",
    "**Models ready at disposal:**  \n",
    "- svm  \n",
    "- dense  \n",
    "- cnn  \n",
    "- lstm  \n",
    "- conv_lstm  \n",
    "\n",
    "**Accuracy records**  \n",
    "- cnn: 48.5824%  \n",
    "- lstm with glove: 48.3908%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'negative': 0, 'neutral': 1, 'positive': 2}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_polarities = 3\n",
    "\n",
    "sen_targets, sen_uniques = pd.factorize(z_train, sort=True)\n",
    "z_train = to_categorical(sen_targets, num_polarities)\n",
    "\n",
    "sen_label_map = dict(zip(list(sen_uniques), range(num_polarities)))\n",
    "sen_label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 4710, 2: 2334, 0: 2945})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(sen_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GloVe + LSTM  \n",
    "Note: To solve the problem of LSTM always predicting the same class even when trained with balanced data, the 'return_sequences' param in the LSTM layer needs to be set to True and add a Flatten layer. In addition, 'return_sequences=True' must be set when stacking LSTM layers so that the second LSTM layer has a three-dimensional sequence inpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 20000, 100)        2000000   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 20000, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 19996, 64)         32064     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 4999, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 4999, 128)         98816     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 4999, 128)         512       \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 4999, 32)          4128      \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 2,135,619\n",
      "Trainable params: 135,363\n",
      "Non-trainable params: 2,000,256\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "sen_glove = build_ConvLSTM(num_classes=num_polarities, dense_activation='softmax', use_glove=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: to use 'callback', one must provide 'validation_split' or 'validation_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5993 samples, validate on 3996 samples\n",
      "Epoch 1/5\n",
      "5993/5993 [==============================] - 2918s 487ms/step - loss: 1.0511 - acc: 0.4716 - val_loss: 2.3347 - val_acc: 0.2367\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.33468, saving model to /Users/cheuky/Documents/Code_Blue/ml_nanodegree/capstone/saved_models/text/sentiment/glove.weights.best.hdf5\n",
      "Epoch 2/5\n",
      "5993/5993 [==============================] - 1648s 275ms/step - loss: 1.0476 - acc: 0.4759 - val_loss: 1.2299 - val_acc: 0.2370\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.33468 to 1.22994, saving model to /Users/cheuky/Documents/Code_Blue/ml_nanodegree/capstone/saved_models/text/sentiment/glove.weights.best.hdf5\n",
      "Epoch 3/5\n",
      "5993/5993 [==============================] - 1758s 293ms/step - loss: 1.0459 - acc: 0.4746 - val_loss: 1.7933 - val_acc: 0.2963\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.22994\n",
      "Epoch 4/5\n",
      " 928/5993 [===>..........................] - ETA: 22:05 - loss: 1.0398 - acc: 0.4849"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-230bd47b1ad5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# writing history is for plotting the graph later\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mglove_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msen_glove\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mglove_checkpts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "glove_checkpts = ModelCheckpoint(filepath=os.path.join(os.getcwd(),'saved_models','text','sentiment','glove.weights.best.hdf5'), \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "# writing history is for plotting the graph later\n",
    "glove_history = sen_glove.fit(x_train, z_train, validation_split=0.4, epochs=5, callbacks=[glove_checkpts], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 2573, 0: 37})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_pred_glove = sen_glove.predict_classes(x_test)\n",
    "Counter(z_pred_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 48.3908%\n"
     ]
    }
   ],
   "source": [
    "glove_accuracy = 100*np.sum(z_pred_glove==z_transf)/len(z_transf)\n",
    "print('Test accuracy: %.4f%%' % glove_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2610, 2610)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(z_pred_glove), len(z_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.495, Test: 0.484\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "_, train_acc = sen_glove.evaluate(x_train, z_train, verbose=0)\n",
    "_, test_acc = sen_glove.evaluate(x_test, z_true, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss during training\n",
    "plt.subplot(211)\n",
    "plt.title('Loss')\n",
    "plt.plot(glove_history.history['loss'], label='train')\n",
    "plt.plot(glove_history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "# plot accuracy during training\n",
    "plt.subplot(212)\n",
    "plt.title('Accuracy')\n",
    "plt.plot(glove_history.history['acc'], label='train')\n",
    "plt.plot(glove_history.history['val_acc'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_7 (Conv1D)            (None, 20000, 16)         48        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 10000, 16)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 10000, 32)         1056      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 5000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 5000, 64)          4160      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 2500, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 160000)            0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               20480128  \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 20,485,779\n",
      "Trainable params: 20,485,779\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From C:\\Users\\syip\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 5993 samples, validate on 3996 samples\n",
      "Epoch 1/5\n",
      "5993/5993 [==============================] - ETA: 7:28 - loss: 1.1019 - acc: 0.250 - ETA: 4:54 - loss: 1.0970 - acc: 0.312 - ETA: 4:09 - loss: 1.1283 - acc: 0.354 - ETA: 3:45 - loss: 1.0907 - acc: 0.398 - ETA: 3:26 - loss: 1.0824 - acc: 0.412 - ETA: 3:18 - loss: 1.0901 - acc: 0.395 - ETA: 3:08 - loss: 1.0802 - acc: 0.401 - ETA: 3:04 - loss: 1.0796 - acc: 0.398 - ETA: 2:58 - loss: 1.0883 - acc: 0.392 - ETA: 2:55 - loss: 1.0848 - acc: 0.393 - ETA: 2:55 - loss: 1.0800 - acc: 0.403 - ETA: 2:49 - loss: 1.0815 - acc: 0.401 - ETA: 2:46 - loss: 1.0781 - acc: 0.408 - ETA: 2:42 - loss: 1.0798 - acc: 0.410 - ETA: 2:38 - loss: 1.0723 - acc: 0.420 - ETA: 2:38 - loss: 1.0778 - acc: 0.429 - ETA: 2:35 - loss: 1.0752 - acc: 0.433 - ETA: 2:33 - loss: 1.0671 - acc: 0.444 - ETA: 2:30 - loss: 1.0664 - acc: 0.450 - ETA: 2:28 - loss: 1.0644 - acc: 0.448 - ETA: 2:26 - loss: 1.0644 - acc: 0.450 - ETA: 2:25 - loss: 1.0625 - acc: 0.454 - ETA: 2:23 - loss: 1.0704 - acc: 0.449 - ETA: 2:22 - loss: 1.0735 - acc: 0.446 - ETA: 2:20 - loss: 1.0689 - acc: 0.447 - ETA: 2:20 - loss: 1.0647 - acc: 0.450 - ETA: 2:18 - loss: 1.0652 - acc: 0.454 - ETA: 2:17 - loss: 1.0625 - acc: 0.457 - ETA: 2:15 - loss: 1.0615 - acc: 0.458 - ETA: 2:14 - loss: 1.0606 - acc: 0.457 - ETA: 2:13 - loss: 1.0612 - acc: 0.457 - ETA: 2:12 - loss: 1.0618 - acc: 0.460 - ETA: 2:12 - loss: 1.0617 - acc: 0.457 - ETA: 2:12 - loss: 1.0629 - acc: 0.454 - ETA: 2:13 - loss: 1.0643 - acc: 0.453 - ETA: 2:13 - loss: 1.0675 - acc: 0.448 - ETA: 2:12 - loss: 1.0676 - acc: 0.449 - ETA: 2:12 - loss: 1.0679 - acc: 0.449 - ETA: 2:12 - loss: 1.0670 - acc: 0.448 - ETA: 2:11 - loss: 1.0671 - acc: 0.447 - ETA: 2:10 - loss: 1.0667 - acc: 0.447 - ETA: 2:09 - loss: 1.0648 - acc: 0.450 - ETA: 2:08 - loss: 1.0644 - acc: 0.452 - ETA: 2:07 - loss: 1.0651 - acc: 0.450 - ETA: 2:07 - loss: 1.0656 - acc: 0.450 - ETA: 2:05 - loss: 1.0656 - acc: 0.451 - ETA: 2:04 - loss: 1.0657 - acc: 0.449 - ETA: 2:03 - loss: 1.0649 - acc: 0.449 - ETA: 2:02 - loss: 1.0648 - acc: 0.449 - ETA: 2:00 - loss: 1.0637 - acc: 0.452 - ETA: 1:59 - loss: 1.0632 - acc: 0.453 - ETA: 1:58 - loss: 1.0623 - acc: 0.455 - ETA: 1:56 - loss: 1.0621 - acc: 0.455 - ETA: 1:55 - loss: 1.0591 - acc: 0.460 - ETA: 1:54 - loss: 1.0587 - acc: 0.461 - ETA: 1:52 - loss: 1.0567 - acc: 0.464 - ETA: 1:51 - loss: 1.0567 - acc: 0.464 - ETA: 1:50 - loss: 1.0551 - acc: 0.466 - ETA: 1:49 - loss: 1.0572 - acc: 0.465 - ETA: 1:48 - loss: 1.0583 - acc: 0.464 - ETA: 1:47 - loss: 1.0599 - acc: 0.463 - ETA: 1:45 - loss: 1.0585 - acc: 0.463 - ETA: 1:44 - loss: 1.0597 - acc: 0.461 - ETA: 1:43 - loss: 1.0608 - acc: 0.460 - ETA: 1:42 - loss: 1.0604 - acc: 0.462 - ETA: 1:41 - loss: 1.0600 - acc: 0.462 - ETA: 1:40 - loss: 1.0589 - acc: 0.462 - ETA: 1:39 - loss: 1.0584 - acc: 0.461 - ETA: 1:38 - loss: 1.0570 - acc: 0.462 - ETA: 1:37 - loss: 1.0580 - acc: 0.462 - ETA: 1:36 - loss: 1.0575 - acc: 0.464 - ETA: 1:35 - loss: 1.0572 - acc: 0.463 - ETA: 1:34 - loss: 1.0573 - acc: 0.464 - ETA: 1:33 - loss: 1.0570 - acc: 0.464 - ETA: 1:32 - loss: 1.0566 - acc: 0.466 - ETA: 1:31 - loss: 1.0548 - acc: 0.467 - ETA: 1:30 - loss: 1.0579 - acc: 0.467 - ETA: 1:29 - loss: 1.0578 - acc: 0.467 - ETA: 1:28 - loss: 1.0565 - acc: 0.467 - ETA: 1:27 - loss: 1.0557 - acc: 0.468 - ETA: 1:26 - loss: 1.0567 - acc: 0.466 - ETA: 1:25 - loss: 1.0567 - acc: 0.465 - ETA: 1:24 - loss: 1.0560 - acc: 0.467 - ETA: 1:23 - loss: 1.0560 - acc: 0.466 - ETA: 1:22 - loss: 1.0556 - acc: 0.465 - ETA: 1:21 - loss: 1.0553 - acc: 0.466 - ETA: 1:20 - loss: 1.0548 - acc: 0.468 - ETA: 1:20 - loss: 1.0554 - acc: 0.468 - ETA: 1:19 - loss: 1.0547 - acc: 0.469 - ETA: 1:18 - loss: 1.0548 - acc: 0.468 - ETA: 1:17 - loss: 1.0539 - acc: 0.469 - ETA: 1:16 - loss: 1.0530 - acc: 0.470 - ETA: 1:15 - loss: 1.0541 - acc: 0.468 - ETA: 1:14 - loss: 1.0539 - acc: 0.468 - ETA: 1:13 - loss: 1.0530 - acc: 0.469 - ETA: 1:12 - loss: 1.0535 - acc: 0.469 - ETA: 1:12 - loss: 1.0526 - acc: 0.470 - ETA: 1:11 - loss: 1.0516 - acc: 0.470 - ETA: 1:10 - loss: 1.0523 - acc: 0.468 - ETA: 1:09 - loss: 1.0523 - acc: 0.468 - ETA: 1:08 - loss: 1.0531 - acc: 0.468 - ETA: 1:07 - loss: 1.0519 - acc: 0.469 - ETA: 1:06 - loss: 1.0519 - acc: 0.468 - ETA: 1:06 - loss: 1.0512 - acc: 0.469 - ETA: 1:05 - loss: 1.0508 - acc: 0.469 - ETA: 1:04 - loss: 1.0499 - acc: 0.469 - ETA: 1:03 - loss: 1.0496 - acc: 0.468 - ETA: 1:02 - loss: 1.0488 - acc: 0.469 - ETA: 1:01 - loss: 1.0488 - acc: 0.469 - ETA: 1:01 - loss: 1.0477 - acc: 0.470 - ETA: 1:00 - loss: 1.0475 - acc: 0.469 - ETA: 59s - loss: 1.0480 - acc: 0.469 - ETA: 58s - loss: 1.0474 - acc: 0.46 - ETA: 57s - loss: 1.0466 - acc: 0.47 - ETA: 56s - loss: 1.0447 - acc: 0.47 - ETA: 56s - loss: 1.0446 - acc: 0.47 - ETA: 55s - loss: 1.0429 - acc: 0.47 - ETA: 54s - loss: 1.0430 - acc: 0.47 - ETA: 53s - loss: 1.0430 - acc: 0.47 - ETA: 52s - loss: 1.0423 - acc: 0.47 - ETA: 52s - loss: 1.0420 - acc: 0.47 - ETA: 51s - loss: 1.0414 - acc: 0.47 - ETA: 50s - loss: 1.0416 - acc: 0.47 - ETA: 49s - loss: 1.0416 - acc: 0.47 - ETA: 48s - loss: 1.0417 - acc: 0.47 - ETA: 47s - loss: 1.0419 - acc: 0.47 - ETA: 47s - loss: 1.0417 - acc: 0.47 - ETA: 46s - loss: 1.0427 - acc: 0.47 - ETA: 45s - loss: 1.0432 - acc: 0.47 - ETA: 44s - loss: 1.0426 - acc: 0.47 - ETA: 43s - loss: 1.0424 - acc: 0.47 - ETA: 43s - loss: 1.0423 - acc: 0.47 - ETA: 42s - loss: 1.0419 - acc: 0.47 - ETA: 41s - loss: 1.0414 - acc: 0.47 - ETA: 40s - loss: 1.0417 - acc: 0.47 - ETA: 39s - loss: 1.0416 - acc: 0.47 - ETA: 39s - loss: 1.0406 - acc: 0.47 - ETA: 38s - loss: 1.0408 - acc: 0.47 - ETA: 37s - loss: 1.0407 - acc: 0.47 - ETA: 36s - loss: 1.0399 - acc: 0.47 - ETA: 35s - loss: 1.0389 - acc: 0.47 - ETA: 35s - loss: 1.0386 - acc: 0.47 - ETA: 34s - loss: 1.0382 - acc: 0.47 - ETA: 33s - loss: 1.0383 - acc: 0.47 - ETA: 32s - loss: 1.0379 - acc: 0.47 - ETA: 31s - loss: 1.0368 - acc: 0.48 - ETA: 31s - loss: 1.0372 - acc: 0.48 - ETA: 30s - loss: 1.0364 - acc: 0.48 - ETA: 29s - loss: 1.0356 - acc: 0.48 - ETA: 28s - loss: 1.0355 - acc: 0.48 - ETA: 27s - loss: 1.0352 - acc: 0.48 - ETA: 27s - loss: 1.0357 - acc: 0.48 - ETA: 26s - loss: 1.0358 - acc: 0.48 - ETA: 25s - loss: 1.0350 - acc: 0.48 - ETA: 24s - loss: 1.0351 - acc: 0.48 - ETA: 24s - loss: 1.0354 - acc: 0.48 - ETA: 23s - loss: 1.0349 - acc: 0.48 - ETA: 22s - loss: 1.0347 - acc: 0.48 - ETA: 21s - loss: 1.0346 - acc: 0.48 - ETA: 20s - loss: 1.0350 - acc: 0.48 - ETA: 20s - loss: 1.0357 - acc: 0.48 - ETA: 19s - loss: 1.0353 - acc: 0.48 - ETA: 18s - loss: 1.0342 - acc: 0.48 - ETA: 17s - loss: 1.0350 - acc: 0.48 - ETA: 17s - loss: 1.0348 - acc: 0.48 - ETA: 16s - loss: 1.0343 - acc: 0.48 - ETA: 15s - loss: 1.0338 - acc: 0.48 - ETA: 14s - loss: 1.0338 - acc: 0.48 - ETA: 14s - loss: 1.0339 - acc: 0.48 - ETA: 13s - loss: 1.0335 - acc: 0.48 - ETA: 12s - loss: 1.0333 - acc: 0.48 - ETA: 11s - loss: 1.0332 - acc: 0.48 - ETA: 10s - loss: 1.0324 - acc: 0.48 - ETA: 10s - loss: 1.0329 - acc: 0.48 - ETA: 9s - loss: 1.0323 - acc: 0.4855 - ETA: 8s - loss: 1.0320 - acc: 0.485 - ETA: 7s - loss: 1.0317 - acc: 0.485 - ETA: 7s - loss: 1.0321 - acc: 0.485 - ETA: 6s - loss: 1.0320 - acc: 0.485 - ETA: 5s - loss: 1.0317 - acc: 0.485 - ETA: 4s - loss: 1.0317 - acc: 0.486 - ETA: 4s - loss: 1.0322 - acc: 0.485 - ETA: 3s - loss: 1.0318 - acc: 0.485 - ETA: 2s - loss: 1.0320 - acc: 0.485 - ETA: 1s - loss: 1.0319 - acc: 0.484 - ETA: 0s - loss: 1.0322 - acc: 0.484 - ETA: 0s - loss: 1.0319 - acc: 0.484 - 160s 27ms/step - loss: 1.0321 - acc: 0.4842 - val_loss: 1.0078 - val_acc: 0.5080\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.00784, saving model to C:\\Users\\syip\\Desktop\\DaSci\\Nanodegree\\ml_nanodegree\\capstone/saved_models/sentiment/cnn.weights.best.hdf5\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5993/5993 [==============================] - ETA: 2:07 - loss: 0.9519 - acc: 0.468 - ETA: 2:10 - loss: 0.9183 - acc: 0.562 - ETA: 2:11 - loss: 0.8883 - acc: 0.625 - ETA: 2:10 - loss: 0.8919 - acc: 0.617 - ETA: 2:10 - loss: 0.8930 - acc: 0.618 - ETA: 2:11 - loss: 0.8927 - acc: 0.614 - ETA: 2:11 - loss: 0.8899 - acc: 0.620 - ETA: 2:12 - loss: 0.8865 - acc: 0.628 - ETA: 2:11 - loss: 0.8904 - acc: 0.618 - ETA: 2:10 - loss: 0.8894 - acc: 0.615 - ETA: 2:10 - loss: 0.8791 - acc: 0.622 - ETA: 2:08 - loss: 0.8781 - acc: 0.606 - ETA: 2:07 - loss: 0.8722 - acc: 0.605 - ETA: 2:06 - loss: 0.8611 - acc: 0.611 - ETA: 2:05 - loss: 0.8659 - acc: 0.604 - ETA: 2:04 - loss: 0.8626 - acc: 0.601 - ETA: 2:03 - loss: 0.8552 - acc: 0.606 - ETA: 2:03 - loss: 0.8450 - acc: 0.618 - ETA: 2:02 - loss: 0.8456 - acc: 0.616 - ETA: 2:01 - loss: 0.8428 - acc: 0.615 - ETA: 2:00 - loss: 0.8419 - acc: 0.617 - ETA: 2:00 - loss: 0.8465 - acc: 0.613 - ETA: 2:00 - loss: 0.8477 - acc: 0.615 - ETA: 1:59 - loss: 0.8439 - acc: 0.617 - ETA: 1:59 - loss: 0.8419 - acc: 0.618 - ETA: 1:58 - loss: 0.8381 - acc: 0.622 - ETA: 1:58 - loss: 0.8328 - acc: 0.625 - ETA: 1:58 - loss: 0.8315 - acc: 0.625 - ETA: 1:57 - loss: 0.8296 - acc: 0.622 - ETA: 1:57 - loss: 0.8286 - acc: 0.622 - ETA: 1:56 - loss: 0.8275 - acc: 0.624 - ETA: 1:55 - loss: 0.8210 - acc: 0.628 - ETA: 1:54 - loss: 0.8229 - acc: 0.630 - ETA: 1:54 - loss: 0.8247 - acc: 0.632 - ETA: 1:53 - loss: 0.8221 - acc: 0.633 - ETA: 1:53 - loss: 0.8195 - acc: 0.634 - ETA: 1:52 - loss: 0.8250 - acc: 0.630 - ETA: 1:52 - loss: 0.8246 - acc: 0.631 - ETA: 1:51 - loss: 0.8296 - acc: 0.627 - ETA: 1:51 - loss: 0.8328 - acc: 0.624 - ETA: 1:50 - loss: 0.8326 - acc: 0.625 - ETA: 1:50 - loss: 0.8299 - acc: 0.630 - ETA: 1:49 - loss: 0.8318 - acc: 0.630 - ETA: 1:48 - loss: 0.8349 - acc: 0.625 - ETA: 1:47 - loss: 0.8381 - acc: 0.622 - ETA: 1:46 - loss: 0.8428 - acc: 0.618 - ETA: 1:46 - loss: 0.8458 - acc: 0.615 - ETA: 1:45 - loss: 0.8455 - acc: 0.617 - ETA: 1:44 - loss: 0.8460 - acc: 0.618 - ETA: 1:43 - loss: 0.8467 - acc: 0.615 - ETA: 1:43 - loss: 0.8472 - acc: 0.615 - ETA: 1:42 - loss: 0.8453 - acc: 0.617 - ETA: 1:41 - loss: 0.8445 - acc: 0.617 - ETA: 1:40 - loss: 0.8431 - acc: 0.618 - ETA: 1:40 - loss: 0.8414 - acc: 0.619 - ETA: 1:39 - loss: 0.8416 - acc: 0.618 - ETA: 1:38 - loss: 0.8415 - acc: 0.618 - ETA: 1:37 - loss: 0.8400 - acc: 0.620 - ETA: 1:37 - loss: 0.8413 - acc: 0.618 - ETA: 1:36 - loss: 0.8435 - acc: 0.618 - ETA: 1:35 - loss: 0.8412 - acc: 0.619 - ETA: 1:34 - loss: 0.8400 - acc: 0.620 - ETA: 1:33 - loss: 0.8378 - acc: 0.622 - ETA: 1:33 - loss: 0.8373 - acc: 0.621 - ETA: 1:32 - loss: 0.8344 - acc: 0.622 - ETA: 1:31 - loss: 0.8335 - acc: 0.623 - ETA: 1:30 - loss: 0.8327 - acc: 0.625 - ETA: 1:30 - loss: 0.8349 - acc: 0.624 - ETA: 1:29 - loss: 0.8360 - acc: 0.624 - ETA: 1:28 - loss: 0.8356 - acc: 0.624 - ETA: 1:27 - loss: 0.8354 - acc: 0.624 - ETA: 1:27 - loss: 0.8359 - acc: 0.624 - ETA: 1:26 - loss: 0.8340 - acc: 0.624 - ETA: 1:25 - loss: 0.8341 - acc: 0.623 - ETA: 1:24 - loss: 0.8328 - acc: 0.623 - ETA: 1:23 - loss: 0.8326 - acc: 0.623 - ETA: 1:23 - loss: 0.8304 - acc: 0.625 - ETA: 1:22 - loss: 0.8282 - acc: 0.626 - ETA: 1:21 - loss: 0.8260 - acc: 0.628 - ETA: 1:20 - loss: 0.8256 - acc: 0.628 - ETA: 1:19 - loss: 0.8275 - acc: 0.627 - ETA: 1:19 - loss: 0.8275 - acc: 0.628 - ETA: 1:18 - loss: 0.8305 - acc: 0.627 - ETA: 1:17 - loss: 0.8312 - acc: 0.627 - ETA: 1:17 - loss: 0.8335 - acc: 0.625 - ETA: 1:16 - loss: 0.8346 - acc: 0.623 - ETA: 1:15 - loss: 0.8340 - acc: 0.623 - ETA: 1:14 - loss: 0.8356 - acc: 0.621 - ETA: 1:14 - loss: 0.8378 - acc: 0.618 - ETA: 1:13 - loss: 0.8360 - acc: 0.620 - ETA: 1:12 - loss: 0.8359 - acc: 0.619 - ETA: 1:12 - loss: 0.8352 - acc: 0.619 - ETA: 1:11 - loss: 0.8344 - acc: 0.619 - ETA: 1:10 - loss: 0.8333 - acc: 0.619 - ETA: 1:09 - loss: 0.8323 - acc: 0.620 - ETA: 1:09 - loss: 0.8316 - acc: 0.620 - ETA: 1:08 - loss: 0.8308 - acc: 0.620 - ETA: 1:07 - loss: 0.8309 - acc: 0.620 - ETA: 1:06 - loss: 0.8317 - acc: 0.619 - ETA: 1:05 - loss: 0.8330 - acc: 0.618 - ETA: 1:05 - loss: 0.8341 - acc: 0.619 - ETA: 1:04 - loss: 0.8341 - acc: 0.619 - ETA: 1:03 - loss: 0.8356 - acc: 0.616 - ETA: 1:02 - loss: 0.8341 - acc: 0.618 - ETA: 1:02 - loss: 0.8336 - acc: 0.618 - ETA: 1:01 - loss: 0.8343 - acc: 0.618 - ETA: 1:00 - loss: 0.8354 - acc: 0.618 - ETA: 59s - loss: 0.8346 - acc: 0.619 - ETA: 59s - loss: 0.8354 - acc: 0.61 - ETA: 58s - loss: 0.8351 - acc: 0.61 - ETA: 57s - loss: 0.8340 - acc: 0.61 - ETA: 56s - loss: 0.8368 - acc: 0.61 - ETA: 56s - loss: 0.8382 - acc: 0.61 - ETA: 55s - loss: 0.8381 - acc: 0.61 - ETA: 54s - loss: 0.8374 - acc: 0.61 - ETA: 54s - loss: 0.8383 - acc: 0.61 - ETA: 53s - loss: 0.8387 - acc: 0.61 - ETA: 52s - loss: 0.8391 - acc: 0.61 - ETA: 52s - loss: 0.8400 - acc: 0.61 - ETA: 51s - loss: 0.8404 - acc: 0.61 - ETA: 50s - loss: 0.8401 - acc: 0.61 - ETA: 49s - loss: 0.8411 - acc: 0.61 - ETA: 49s - loss: 0.8406 - acc: 0.61 - ETA: 48s - loss: 0.8412 - acc: 0.61 - ETA: 47s - loss: 0.8409 - acc: 0.61 - ETA: 46s - loss: 0.8403 - acc: 0.61 - ETA: 46s - loss: 0.8394 - acc: 0.61 - ETA: 45s - loss: 0.8400 - acc: 0.61 - ETA: 44s - loss: 0.8391 - acc: 0.61 - ETA: 43s - loss: 0.8396 - acc: 0.61 - ETA: 42s - loss: 0.8401 - acc: 0.61 - ETA: 42s - loss: 0.8401 - acc: 0.61 - ETA: 41s - loss: 0.8405 - acc: 0.61 - ETA: 40s - loss: 0.8410 - acc: 0.61 - ETA: 39s - loss: 0.8402 - acc: 0.61 - ETA: 39s - loss: 0.8394 - acc: 0.61 - ETA: 38s - loss: 0.8385 - acc: 0.61 - ETA: 37s - loss: 0.8386 - acc: 0.61 - ETA: 36s - loss: 0.8381 - acc: 0.61 - ETA: 36s - loss: 0.8379 - acc: 0.61 - ETA: 35s - loss: 0.8373 - acc: 0.61 - ETA: 34s - loss: 0.8371 - acc: 0.61 - ETA: 33s - loss: 0.8380 - acc: 0.61 - ETA: 33s - loss: 0.8401 - acc: 0.61 - ETA: 32s - loss: 0.8404 - acc: 0.61 - ETA: 31s - loss: 0.8403 - acc: 0.61 - ETA: 30s - loss: 0.8400 - acc: 0.61 - ETA: 29s - loss: 0.8392 - acc: 0.61 - ETA: 29s - loss: 0.8403 - acc: 0.61 - ETA: 28s - loss: 0.8412 - acc: 0.61 - ETA: 27s - loss: 0.8415 - acc: 0.61 - ETA: 26s - loss: 0.8414 - acc: 0.61 - ETA: 26s - loss: 0.8425 - acc: 0.61 - ETA: 25s - loss: 0.8443 - acc: 0.60 - ETA: 24s - loss: 0.8437 - acc: 0.61 - ETA: 23s - loss: 0.8451 - acc: 0.60 - ETA: 23s - loss: 0.8462 - acc: 0.60 - ETA: 22s - loss: 0.8464 - acc: 0.60 - ETA: 21s - loss: 0.8457 - acc: 0.60 - ETA: 20s - loss: 0.8462 - acc: 0.60 - ETA: 20s - loss: 0.8460 - acc: 0.60 - ETA: 19s - loss: 0.8461 - acc: 0.60 - ETA: 18s - loss: 0.8459 - acc: 0.60 - ETA: 17s - loss: 0.8465 - acc: 0.60 - ETA: 17s - loss: 0.8472 - acc: 0.60 - ETA: 16s - loss: 0.8474 - acc: 0.60 - ETA: 15s - loss: 0.8476 - acc: 0.60 - ETA: 15s - loss: 0.8474 - acc: 0.60 - ETA: 14s - loss: 0.8476 - acc: 0.60 - ETA: 13s - loss: 0.8469 - acc: 0.60 - ETA: 12s - loss: 0.8471 - acc: 0.60 - ETA: 12s - loss: 0.8464 - acc: 0.60 - ETA: 11s - loss: 0.8461 - acc: 0.60 - ETA: 10s - loss: 0.8460 - acc: 0.60 - ETA: 9s - loss: 0.8459 - acc: 0.6066 - ETA: 8s - loss: 0.8468 - acc: 0.606 - ETA: 8s - loss: 0.8461 - acc: 0.606 - ETA: 7s - loss: 0.8468 - acc: 0.606 - ETA: 6s - loss: 0.8467 - acc: 0.605 - ETA: 5s - loss: 0.8477 - acc: 0.605 - ETA: 5s - loss: 0.8481 - acc: 0.604 - ETA: 4s - loss: 0.8474 - acc: 0.605 - ETA: 3s - loss: 0.8472 - acc: 0.605 - ETA: 2s - loss: 0.8470 - acc: 0.605 - ETA: 1s - loss: 0.8473 - acc: 0.605 - ETA: 1s - loss: 0.8472 - acc: 0.605 - ETA: 0s - loss: 0.8482 - acc: 0.605 - 175s 29ms/step - loss: 0.8485 - acc: 0.6050 - val_loss: 1.0572 - val_acc: 0.5055\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.00784\n",
      "Epoch 3/5\n",
      "5993/5993 [==============================] - ETA: 2:19 - loss: 0.6897 - acc: 0.687 - ETA: 2:25 - loss: 0.5620 - acc: 0.750 - ETA: 2:22 - loss: 0.5606 - acc: 0.781 - ETA: 2:22 - loss: 0.6220 - acc: 0.750 - ETA: 2:20 - loss: 0.6003 - acc: 0.756 - ETA: 2:26 - loss: 0.6157 - acc: 0.750 - ETA: 2:25 - loss: 0.6062 - acc: 0.763 - ETA: 2:29 - loss: 0.6031 - acc: 0.761 - ETA: 2:34 - loss: 0.6081 - acc: 0.760 - ETA: 2:34 - loss: 0.5971 - acc: 0.765 - ETA: 2:36 - loss: 0.6036 - acc: 0.761 - ETA: 2:38 - loss: 0.6059 - acc: 0.755 - ETA: 2:39 - loss: 0.6106 - acc: 0.750 - ETA: 2:39 - loss: 0.6035 - acc: 0.758 - ETA: 2:38 - loss: 0.5989 - acc: 0.760 - ETA: 2:39 - loss: 0.5878 - acc: 0.767 - ETA: 2:40 - loss: 0.5839 - acc: 0.766 - ETA: 2:40 - loss: 0.5808 - acc: 0.772 - ETA: 2:40 - loss: 0.5881 - acc: 0.769 - ETA: 2:40 - loss: 0.5845 - acc: 0.773 - ETA: 2:40 - loss: 0.5862 - acc: 0.769 - ETA: 2:39 - loss: 0.5801 - acc: 0.771 - ETA: 2:39 - loss: 0.5825 - acc: 0.767 - ETA: 2:40 - loss: 0.5852 - acc: 0.764 - ETA: 2:39 - loss: 0.5974 - acc: 0.758 - ETA: 2:38 - loss: 0.6021 - acc: 0.757 - ETA: 2:37 - loss: 0.5949 - acc: 0.761 - ETA: 2:35 - loss: 0.5947 - acc: 0.761 - ETA: 2:35 - loss: 0.5942 - acc: 0.758 - ETA: 2:34 - loss: 0.5861 - acc: 0.763 - ETA: 2:33 - loss: 0.5811 - acc: 0.766 - ETA: 2:32 - loss: 0.5755 - acc: 0.769 - ETA: 2:31 - loss: 0.5714 - acc: 0.769 - ETA: 2:29 - loss: 0.5680 - acc: 0.771 - ETA: 2:28 - loss: 0.5686 - acc: 0.768 - ETA: 2:27 - loss: 0.5684 - acc: 0.769 - ETA: 2:26 - loss: 0.5705 - acc: 0.767 - ETA: 2:25 - loss: 0.5700 - acc: 0.768 - ETA: 2:23 - loss: 0.5637 - acc: 0.770 - ETA: 2:22 - loss: 0.5605 - acc: 0.769 - ETA: 2:21 - loss: 0.5625 - acc: 0.766 - ETA: 2:20 - loss: 0.5606 - acc: 0.768 - ETA: 2:19 - loss: 0.5606 - acc: 0.768 - ETA: 2:18 - loss: 0.5612 - acc: 0.769 - ETA: 2:16 - loss: 0.5613 - acc: 0.769 - ETA: 2:15 - loss: 0.5649 - acc: 0.769 - ETA: 2:14 - loss: 0.5633 - acc: 0.769 - ETA: 2:12 - loss: 0.5635 - acc: 0.769 - ETA: 2:11 - loss: 0.5680 - acc: 0.765 - ETA: 2:10 - loss: 0.5690 - acc: 0.767 - ETA: 2:08 - loss: 0.5676 - acc: 0.768 - ETA: 2:07 - loss: 0.5689 - acc: 0.766 - ETA: 2:06 - loss: 0.5701 - acc: 0.765 - ETA: 2:05 - loss: 0.5678 - acc: 0.765 - ETA: 2:04 - loss: 0.5648 - acc: 0.765 - ETA: 2:03 - loss: 0.5627 - acc: 0.765 - ETA: 2:02 - loss: 0.5676 - acc: 0.761 - ETA: 2:01 - loss: 0.5678 - acc: 0.760 - ETA: 2:00 - loss: 0.5664 - acc: 0.761 - ETA: 1:59 - loss: 0.5657 - acc: 0.762 - ETA: 1:57 - loss: 0.5649 - acc: 0.762 - ETA: 1:56 - loss: 0.5657 - acc: 0.761 - ETA: 1:55 - loss: 0.5643 - acc: 0.762 - ETA: 1:54 - loss: 0.5629 - acc: 0.762 - ETA: 1:53 - loss: 0.5615 - acc: 0.763 - ETA: 1:52 - loss: 0.5595 - acc: 0.763 - ETA: 1:51 - loss: 0.5598 - acc: 0.763 - ETA: 1:50 - loss: 0.5593 - acc: 0.763 - ETA: 1:49 - loss: 0.5576 - acc: 0.764 - ETA: 1:47 - loss: 0.5593 - acc: 0.763 - ETA: 1:46 - loss: 0.5602 - acc: 0.763 - ETA: 1:45 - loss: 0.5603 - acc: 0.763 - ETA: 1:44 - loss: 0.5594 - acc: 0.763 - ETA: 1:43 - loss: 0.5572 - acc: 0.765 - ETA: 1:42 - loss: 0.5578 - acc: 0.764 - ETA: 1:41 - loss: 0.5545 - acc: 0.766 - ETA: 1:39 - loss: 0.5585 - acc: 0.765 - ETA: 1:38 - loss: 0.5579 - acc: 0.765 - ETA: 1:37 - loss: 0.5595 - acc: 0.763 - ETA: 1:36 - loss: 0.5571 - acc: 0.764 - ETA: 1:35 - loss: 0.5582 - acc: 0.762 - ETA: 1:34 - loss: 0.5591 - acc: 0.762 - ETA: 1:33 - loss: 0.5580 - acc: 0.762 - ETA: 1:32 - loss: 0.5568 - acc: 0.763 - ETA: 1:31 - loss: 0.5563 - acc: 0.762 - ETA: 1:30 - loss: 0.5586 - acc: 0.763 - ETA: 1:29 - loss: 0.5585 - acc: 0.763 - ETA: 1:28 - loss: 0.5583 - acc: 0.763 - ETA: 1:27 - loss: 0.5578 - acc: 0.763 - ETA: 1:26 - loss: 0.5581 - acc: 0.764 - ETA: 1:25 - loss: 0.5567 - acc: 0.765 - ETA: 1:24 - loss: 0.5569 - acc: 0.767 - ETA: 1:23 - loss: 0.5584 - acc: 0.765 - ETA: 1:22 - loss: 0.5594 - acc: 0.765 - ETA: 1:21 - loss: 0.5593 - acc: 0.765 - ETA: 1:20 - loss: 0.5585 - acc: 0.765 - ETA: 1:19 - loss: 0.5588 - acc: 0.765 - ETA: 1:18 - loss: 0.5594 - acc: 0.764 - ETA: 1:17 - loss: 0.5587 - acc: 0.764 - ETA: 1:16 - loss: 0.5601 - acc: 0.763 - ETA: 1:15 - loss: 0.5618 - acc: 0.761 - ETA: 1:14 - loss: 0.5631 - acc: 0.761 - ETA: 1:13 - loss: 0.5610 - acc: 0.761 - ETA: 1:12 - loss: 0.5649 - acc: 0.760 - ETA: 1:11 - loss: 0.5650 - acc: 0.760 - ETA: 1:10 - loss: 0.5637 - acc: 0.760 - ETA: 1:09 - loss: 0.5646 - acc: 0.760 - ETA: 1:08 - loss: 0.5636 - acc: 0.760 - ETA: 1:07 - loss: 0.5643 - acc: 0.759 - ETA: 1:06 - loss: 0.5648 - acc: 0.759 - ETA: 1:05 - loss: 0.5662 - acc: 0.758 - ETA: 1:04 - loss: 0.5658 - acc: 0.757 - ETA: 1:03 - loss: 0.5669 - acc: 0.758 - ETA: 1:02 - loss: 0.5674 - acc: 0.757 - ETA: 1:02 - loss: 0.5687 - acc: 0.757 - ETA: 1:01 - loss: 0.5678 - acc: 0.758 - ETA: 1:00 - loss: 0.5678 - acc: 0.758 - ETA: 59s - loss: 0.5678 - acc: 0.759 - ETA: 58s - loss: 0.5685 - acc: 0.75 - ETA: 57s - loss: 0.5690 - acc: 0.75 - ETA: 56s - loss: 0.5687 - acc: 0.75 - ETA: 55s - loss: 0.5679 - acc: 0.75 - ETA: 54s - loss: 0.5683 - acc: 0.75 - ETA: 54s - loss: 0.5703 - acc: 0.75 - ETA: 53s - loss: 0.5704 - acc: 0.75 - ETA: 52s - loss: 0.5700 - acc: 0.75 - ETA: 51s - loss: 0.5688 - acc: 0.75 - ETA: 50s - loss: 0.5696 - acc: 0.75 - ETA: 49s - loss: 0.5696 - acc: 0.75 - ETA: 48s - loss: 0.5702 - acc: 0.75 - ETA: 47s - loss: 0.5706 - acc: 0.75 - ETA: 47s - loss: 0.5707 - acc: 0.75 - ETA: 46s - loss: 0.5702 - acc: 0.75 - ETA: 45s - loss: 0.5708 - acc: 0.75 - ETA: 44s - loss: 0.5706 - acc: 0.75 - ETA: 43s - loss: 0.5702 - acc: 0.75 - ETA: 42s - loss: 0.5710 - acc: 0.75 - ETA: 42s - loss: 0.5723 - acc: 0.75 - ETA: 41s - loss: 0.5713 - acc: 0.75 - ETA: 40s - loss: 0.5729 - acc: 0.75 - ETA: 39s - loss: 0.5745 - acc: 0.75 - ETA: 38s - loss: 0.5734 - acc: 0.75 - ETA: 37s - loss: 0.5745 - acc: 0.75 - ETA: 36s - loss: 0.5739 - acc: 0.75 - ETA: 35s - loss: 0.5732 - acc: 0.75 - ETA: 35s - loss: 0.5741 - acc: 0.75 - ETA: 34s - loss: 0.5752 - acc: 0.75 - ETA: 33s - loss: 0.5751 - acc: 0.75 - ETA: 32s - loss: 0.5750 - acc: 0.75 - ETA: 31s - loss: 0.5757 - acc: 0.75 - ETA: 30s - loss: 0.5758 - acc: 0.75 - ETA: 29s - loss: 0.5753 - acc: 0.75 - ETA: 28s - loss: 0.5751 - acc: 0.75 - ETA: 28s - loss: 0.5756 - acc: 0.75 - ETA: 27s - loss: 0.5763 - acc: 0.75 - ETA: 26s - loss: 0.5772 - acc: 0.75 - ETA: 25s - loss: 0.5777 - acc: 0.75 - ETA: 24s - loss: 0.5788 - acc: 0.75 - ETA: 23s - loss: 0.5797 - acc: 0.75 - ETA: 22s - loss: 0.5793 - acc: 0.75 - ETA: 22s - loss: 0.5801 - acc: 0.75 - ETA: 21s - loss: 0.5800 - acc: 0.75 - ETA: 20s - loss: 0.5802 - acc: 0.75 - ETA: 19s - loss: 0.5805 - acc: 0.75 - ETA: 18s - loss: 0.5795 - acc: 0.75 - ETA: 17s - loss: 0.5795 - acc: 0.75 - ETA: 16s - loss: 0.5794 - acc: 0.75 - ETA: 16s - loss: 0.5794 - acc: 0.75 - ETA: 15s - loss: 0.5793 - acc: 0.75 - ETA: 14s - loss: 0.5798 - acc: 0.75 - ETA: 13s - loss: 0.5813 - acc: 0.75 - ETA: 12s - loss: 0.5814 - acc: 0.75 - ETA: 11s - loss: 0.5818 - acc: 0.75 - ETA: 11s - loss: 0.5825 - acc: 0.75 - ETA: 10s - loss: 0.5825 - acc: 0.75 - ETA: 9s - loss: 0.5822 - acc: 0.7511 - ETA: 8s - loss: 0.5814 - acc: 0.751 - ETA: 7s - loss: 0.5810 - acc: 0.752 - ETA: 6s - loss: 0.5815 - acc: 0.752 - ETA: 6s - loss: 0.5826 - acc: 0.751 - ETA: 5s - loss: 0.5828 - acc: 0.751 - ETA: 4s - loss: 0.5828 - acc: 0.752 - ETA: 3s - loss: 0.5833 - acc: 0.751 - ETA: 2s - loss: 0.5834 - acc: 0.752 - ETA: 1s - loss: 0.5832 - acc: 0.752 - ETA: 1s - loss: 0.5829 - acc: 0.752 - ETA: 0s - loss: 0.5827 - acc: 0.752 - 174s 29ms/step - loss: 0.5825 - acc: 0.7527 - val_loss: 1.2357 - val_acc: 0.4910\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.00784\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5993/5993 [==============================] - ETA: 2:27 - loss: 0.3017 - acc: 0.906 - ETA: 2:21 - loss: 0.3332 - acc: 0.906 - ETA: 2:17 - loss: 0.3287 - acc: 0.916 - ETA: 2:19 - loss: 0.3678 - acc: 0.882 - ETA: 2:25 - loss: 0.3684 - acc: 0.893 - ETA: 2:24 - loss: 0.3992 - acc: 0.864 - ETA: 2:25 - loss: 0.3887 - acc: 0.875 - ETA: 2:23 - loss: 0.3885 - acc: 0.875 - ETA: 2:21 - loss: 0.3889 - acc: 0.871 - ETA: 2:21 - loss: 0.3822 - acc: 0.871 - ETA: 2:19 - loss: 0.3742 - acc: 0.872 - ETA: 2:18 - loss: 0.3694 - acc: 0.880 - ETA: 2:17 - loss: 0.3708 - acc: 0.875 - ETA: 2:16 - loss: 0.3683 - acc: 0.877 - ETA: 2:15 - loss: 0.3736 - acc: 0.877 - ETA: 2:14 - loss: 0.3851 - acc: 0.869 - ETA: 2:13 - loss: 0.3842 - acc: 0.869 - ETA: 2:13 - loss: 0.3846 - acc: 0.868 - ETA: 2:13 - loss: 0.3781 - acc: 0.870 - ETA: 2:14 - loss: 0.3821 - acc: 0.870 - ETA: 2:14 - loss: 0.3895 - acc: 0.866 - ETA: 2:13 - loss: 0.3831 - acc: 0.866 - ETA: 2:14 - loss: 0.3714 - acc: 0.872 - ETA: 2:13 - loss: 0.3789 - acc: 0.869 - ETA: 2:12 - loss: 0.3750 - acc: 0.871 - ETA: 2:11 - loss: 0.3715 - acc: 0.871 - ETA: 2:10 - loss: 0.3677 - acc: 0.872 - ETA: 2:09 - loss: 0.3755 - acc: 0.868 - ETA: 2:08 - loss: 0.3791 - acc: 0.865 - ETA: 2:07 - loss: 0.3713 - acc: 0.869 - ETA: 2:06 - loss: 0.3734 - acc: 0.865 - ETA: 2:07 - loss: 0.3738 - acc: 0.866 - ETA: 2:06 - loss: 0.3719 - acc: 0.865 - ETA: 2:08 - loss: 0.3707 - acc: 0.867 - ETA: 2:10 - loss: 0.3706 - acc: 0.867 - ETA: 2:11 - loss: 0.3703 - acc: 0.866 - ETA: 2:10 - loss: 0.3690 - acc: 0.866 - ETA: 2:09 - loss: 0.3667 - acc: 0.866 - ETA: 2:10 - loss: 0.3689 - acc: 0.863 - ETA: 2:11 - loss: 0.3685 - acc: 0.861 - ETA: 2:10 - loss: 0.3657 - acc: 0.862 - ETA: 2:10 - loss: 0.3705 - acc: 0.860 - ETA: 2:09 - loss: 0.3713 - acc: 0.860 - ETA: 2:09 - loss: 0.3706 - acc: 0.861 - ETA: 2:07 - loss: 0.3673 - acc: 0.862 - ETA: 2:06 - loss: 0.3666 - acc: 0.862 - ETA: 2:06 - loss: 0.3657 - acc: 0.861 - ETA: 2:05 - loss: 0.3664 - acc: 0.860 - ETA: 2:05 - loss: 0.3657 - acc: 0.862 - ETA: 2:04 - loss: 0.3626 - acc: 0.863 - ETA: 2:03 - loss: 0.3601 - acc: 0.864 - ETA: 2:02 - loss: 0.3652 - acc: 0.863 - ETA: 2:01 - loss: 0.3629 - acc: 0.864 - ETA: 2:00 - loss: 0.3609 - acc: 0.865 - ETA: 1:59 - loss: 0.3620 - acc: 0.863 - ETA: 1:57 - loss: 0.3614 - acc: 0.864 - ETA: 1:56 - loss: 0.3600 - acc: 0.864 - ETA: 1:55 - loss: 0.3595 - acc: 0.864 - ETA: 1:55 - loss: 0.3605 - acc: 0.863 - ETA: 1:53 - loss: 0.3584 - acc: 0.865 - ETA: 1:52 - loss: 0.3601 - acc: 0.864 - ETA: 1:51 - loss: 0.3640 - acc: 0.862 - ETA: 1:50 - loss: 0.3647 - acc: 0.862 - ETA: 1:49 - loss: 0.3658 - acc: 0.861 - ETA: 1:48 - loss: 0.3632 - acc: 0.863 - ETA: 1:47 - loss: 0.3676 - acc: 0.862 - ETA: 1:46 - loss: 0.3652 - acc: 0.863 - ETA: 1:45 - loss: 0.3640 - acc: 0.864 - ETA: 1:44 - loss: 0.3613 - acc: 0.865 - ETA: 1:43 - loss: 0.3605 - acc: 0.865 - ETA: 1:42 - loss: 0.3605 - acc: 0.865 - ETA: 1:41 - loss: 0.3587 - acc: 0.865 - ETA: 1:40 - loss: 0.3577 - acc: 0.866 - ETA: 1:39 - loss: 0.3574 - acc: 0.867 - ETA: 1:38 - loss: 0.3594 - acc: 0.866 - ETA: 1:36 - loss: 0.3581 - acc: 0.867 - ETA: 1:35 - loss: 0.3583 - acc: 0.867 - ETA: 1:34 - loss: 0.3603 - acc: 0.865 - ETA: 1:33 - loss: 0.3606 - acc: 0.864 - ETA: 1:33 - loss: 0.3618 - acc: 0.864 - ETA: 1:32 - loss: 0.3626 - acc: 0.864 - ETA: 1:31 - loss: 0.3627 - acc: 0.863 - ETA: 1:30 - loss: 0.3624 - acc: 0.864 - ETA: 1:29 - loss: 0.3636 - acc: 0.863 - ETA: 1:28 - loss: 0.3621 - acc: 0.864 - ETA: 1:27 - loss: 0.3619 - acc: 0.865 - ETA: 1:26 - loss: 0.3617 - acc: 0.865 - ETA: 1:25 - loss: 0.3599 - acc: 0.866 - ETA: 1:24 - loss: 0.3594 - acc: 0.866 - ETA: 1:23 - loss: 0.3601 - acc: 0.864 - ETA: 1:22 - loss: 0.3599 - acc: 0.864 - ETA: 1:21 - loss: 0.3594 - acc: 0.864 - ETA: 1:20 - loss: 0.3612 - acc: 0.863 - ETA: 1:19 - loss: 0.3633 - acc: 0.862 - ETA: 1:19 - loss: 0.3623 - acc: 0.863 - ETA: 1:18 - loss: 0.3621 - acc: 0.863 - ETA: 1:17 - loss: 0.3603 - acc: 0.863 - ETA: 1:16 - loss: 0.3603 - acc: 0.863 - ETA: 1:15 - loss: 0.3605 - acc: 0.863 - ETA: 1:14 - loss: 0.3600 - acc: 0.862 - ETA: 1:13 - loss: 0.3605 - acc: 0.862 - ETA: 1:12 - loss: 0.3606 - acc: 0.862 - ETA: 1:11 - loss: 0.3602 - acc: 0.862 - ETA: 1:10 - loss: 0.3605 - acc: 0.861 - ETA: 1:09 - loss: 0.3618 - acc: 0.861 - ETA: 1:09 - loss: 0.3611 - acc: 0.861 - ETA: 1:08 - loss: 0.3611 - acc: 0.860 - ETA: 1:07 - loss: 0.3609 - acc: 0.860 - ETA: 1:06 - loss: 0.3618 - acc: 0.860 - ETA: 1:05 - loss: 0.3609 - acc: 0.860 - ETA: 1:05 - loss: 0.3611 - acc: 0.860 - ETA: 1:04 - loss: 0.3606 - acc: 0.860 - ETA: 1:03 - loss: 0.3613 - acc: 0.860 - ETA: 1:02 - loss: 0.3613 - acc: 0.860 - ETA: 1:01 - loss: 0.3617 - acc: 0.860 - ETA: 1:00 - loss: 0.3618 - acc: 0.859 - ETA: 59s - loss: 0.3608 - acc: 0.860 - ETA: 59s - loss: 0.3615 - acc: 0.85 - ETA: 58s - loss: 0.3640 - acc: 0.85 - ETA: 57s - loss: 0.3632 - acc: 0.85 - ETA: 56s - loss: 0.3628 - acc: 0.85 - ETA: 55s - loss: 0.3623 - acc: 0.85 - ETA: 54s - loss: 0.3652 - acc: 0.85 - ETA: 53s - loss: 0.3663 - acc: 0.85 - ETA: 52s - loss: 0.3671 - acc: 0.85 - ETA: 51s - loss: 0.3677 - acc: 0.85 - ETA: 50s - loss: 0.3668 - acc: 0.85 - ETA: 50s - loss: 0.3667 - acc: 0.85 - ETA: 49s - loss: 0.3676 - acc: 0.85 - ETA: 48s - loss: 0.3675 - acc: 0.85 - ETA: 47s - loss: 0.3673 - acc: 0.85 - ETA: 46s - loss: 0.3678 - acc: 0.85 - ETA: 45s - loss: 0.3688 - acc: 0.85 - ETA: 44s - loss: 0.3704 - acc: 0.85 - ETA: 44s - loss: 0.3716 - acc: 0.85 - ETA: 43s - loss: 0.3723 - acc: 0.85 - ETA: 42s - loss: 0.3731 - acc: 0.85 - ETA: 41s - loss: 0.3733 - acc: 0.85 - ETA: 40s - loss: 0.3728 - acc: 0.85 - ETA: 39s - loss: 0.3738 - acc: 0.85 - ETA: 38s - loss: 0.3744 - acc: 0.85 - ETA: 38s - loss: 0.3761 - acc: 0.85 - ETA: 37s - loss: 0.3758 - acc: 0.85 - ETA: 36s - loss: 0.3756 - acc: 0.85 - ETA: 35s - loss: 0.3757 - acc: 0.85 - ETA: 34s - loss: 0.3752 - acc: 0.85 - ETA: 33s - loss: 0.3756 - acc: 0.85 - ETA: 32s - loss: 0.3764 - acc: 0.85 - ETA: 32s - loss: 0.3758 - acc: 0.85 - ETA: 31s - loss: 0.3751 - acc: 0.85 - ETA: 30s - loss: 0.3749 - acc: 0.85 - ETA: 29s - loss: 0.3739 - acc: 0.85 - ETA: 28s - loss: 0.3735 - acc: 0.85 - ETA: 27s - loss: 0.3723 - acc: 0.85 - ETA: 27s - loss: 0.3718 - acc: 0.85 - ETA: 26s - loss: 0.3725 - acc: 0.85 - ETA: 25s - loss: 0.3730 - acc: 0.85 - ETA: 24s - loss: 0.3734 - acc: 0.85 - ETA: 23s - loss: 0.3729 - acc: 0.85 - ETA: 22s - loss: 0.3723 - acc: 0.85 - ETA: 22s - loss: 0.3725 - acc: 0.85 - ETA: 21s - loss: 0.3731 - acc: 0.85 - ETA: 20s - loss: 0.3722 - acc: 0.85 - ETA: 19s - loss: 0.3714 - acc: 0.85 - ETA: 18s - loss: 0.3714 - acc: 0.85 - ETA: 17s - loss: 0.3711 - acc: 0.85 - ETA: 17s - loss: 0.3725 - acc: 0.85 - ETA: 16s - loss: 0.3723 - acc: 0.85 - ETA: 15s - loss: 0.3730 - acc: 0.85 - ETA: 14s - loss: 0.3731 - acc: 0.85 - ETA: 13s - loss: 0.3741 - acc: 0.85 - ETA: 12s - loss: 0.3755 - acc: 0.85 - ETA: 11s - loss: 0.3766 - acc: 0.85 - ETA: 11s - loss: 0.3770 - acc: 0.85 - ETA: 10s - loss: 0.3769 - acc: 0.85 - ETA: 9s - loss: 0.3772 - acc: 0.8528 - ETA: 8s - loss: 0.3778 - acc: 0.852 - ETA: 7s - loss: 0.3790 - acc: 0.851 - ETA: 6s - loss: 0.3787 - acc: 0.851 - ETA: 6s - loss: 0.3786 - acc: 0.851 - ETA: 5s - loss: 0.3785 - acc: 0.852 - ETA: 4s - loss: 0.3787 - acc: 0.851 - ETA: 3s - loss: 0.3792 - acc: 0.851 - ETA: 2s - loss: 0.3810 - acc: 0.850 - ETA: 1s - loss: 0.3818 - acc: 0.850 - ETA: 1s - loss: 0.3823 - acc: 0.849 - ETA: 0s - loss: 0.3823 - acc: 0.849 - 176s 29ms/step - loss: 0.3821 - acc: 0.8493 - val_loss: 1.5040 - val_acc: 0.4842\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.00784\n",
      "Epoch 5/5\n",
      "5993/5993 [==============================] - ETA: 2:17 - loss: 0.2071 - acc: 0.937 - ETA: 2:16 - loss: 0.2365 - acc: 0.937 - ETA: 2:15 - loss: 0.2448 - acc: 0.916 - ETA: 2:15 - loss: 0.2149 - acc: 0.929 - ETA: 2:14 - loss: 0.2059 - acc: 0.937 - ETA: 2:13 - loss: 0.2266 - acc: 0.937 - ETA: 2:13 - loss: 0.2279 - acc: 0.942 - ETA: 2:12 - loss: 0.2303 - acc: 0.937 - ETA: 2:13 - loss: 0.2238 - acc: 0.941 - ETA: 2:13 - loss: 0.2301 - acc: 0.931 - ETA: 2:13 - loss: 0.2309 - acc: 0.931 - ETA: 2:12 - loss: 0.2321 - acc: 0.932 - ETA: 2:12 - loss: 0.2274 - acc: 0.932 - ETA: 2:12 - loss: 0.2286 - acc: 0.935 - ETA: 2:11 - loss: 0.2343 - acc: 0.931 - ETA: 2:11 - loss: 0.2394 - acc: 0.927 - ETA: 2:10 - loss: 0.2371 - acc: 0.926 - ETA: 2:09 - loss: 0.2390 - acc: 0.923 - ETA: 2:09 - loss: 0.2322 - acc: 0.927 - ETA: 2:08 - loss: 0.2295 - acc: 0.925 - ETA: 2:07 - loss: 0.2216 - acc: 0.928 - ETA: 2:06 - loss: 0.2321 - acc: 0.920 - ETA: 2:05 - loss: 0.2354 - acc: 0.918 - ETA: 2:04 - loss: 0.2325 - acc: 0.918 - ETA: 2:04 - loss: 0.2313 - acc: 0.917 - ETA: 2:03 - loss: 0.2358 - acc: 0.914 - ETA: 2:02 - loss: 0.2309 - acc: 0.916 - ETA: 2:01 - loss: 0.2345 - acc: 0.915 - ETA: 2:01 - loss: 0.2310 - acc: 0.917 - ETA: 2:00 - loss: 0.2255 - acc: 0.918 - ETA: 2:00 - loss: 0.2263 - acc: 0.919 - ETA: 2:00 - loss: 0.2308 - acc: 0.918 - ETA: 1:59 - loss: 0.2268 - acc: 0.921 - ETA: 1:59 - loss: 0.2302 - acc: 0.920 - ETA: 1:59 - loss: 0.2285 - acc: 0.920 - ETA: 1:58 - loss: 0.2300 - acc: 0.920 - ETA: 1:57 - loss: 0.2308 - acc: 0.917 - ETA: 1:57 - loss: 0.2312 - acc: 0.916 - ETA: 1:56 - loss: 0.2318 - acc: 0.915 - ETA: 1:55 - loss: 0.2299 - acc: 0.916 - ETA: 1:54 - loss: 0.2320 - acc: 0.915 - ETA: 1:54 - loss: 0.2327 - acc: 0.915 - ETA: 1:53 - loss: 0.2316 - acc: 0.915 - ETA: 1:52 - loss: 0.2317 - acc: 0.915 - ETA: 1:51 - loss: 0.2317 - acc: 0.915 - ETA: 1:50 - loss: 0.2308 - acc: 0.914 - ETA: 1:50 - loss: 0.2337 - acc: 0.913 - ETA: 1:49 - loss: 0.2319 - acc: 0.914 - ETA: 1:48 - loss: 0.2314 - acc: 0.913 - ETA: 1:47 - loss: 0.2359 - acc: 0.911 - ETA: 1:46 - loss: 0.2359 - acc: 0.909 - ETA: 1:45 - loss: 0.2352 - acc: 0.910 - ETA: 1:45 - loss: 0.2369 - acc: 0.908 - ETA: 1:44 - loss: 0.2417 - acc: 0.906 - ETA: 1:43 - loss: 0.2424 - acc: 0.905 - ETA: 1:42 - loss: 0.2451 - acc: 0.903 - ETA: 1:41 - loss: 0.2467 - acc: 0.902 - ETA: 1:41 - loss: 0.2455 - acc: 0.903 - ETA: 1:40 - loss: 0.2466 - acc: 0.903 - ETA: 1:39 - loss: 0.2464 - acc: 0.903 - ETA: 1:38 - loss: 0.2441 - acc: 0.904 - ETA: 1:38 - loss: 0.2440 - acc: 0.903 - ETA: 1:37 - loss: 0.2468 - acc: 0.902 - ETA: 1:36 - loss: 0.2500 - acc: 0.899 - ETA: 1:36 - loss: 0.2488 - acc: 0.901 - ETA: 1:35 - loss: 0.2505 - acc: 0.900 - ETA: 1:34 - loss: 0.2490 - acc: 0.901 - ETA: 1:33 - loss: 0.2510 - acc: 0.900 - ETA: 1:32 - loss: 0.2534 - acc: 0.899 - ETA: 1:32 - loss: 0.2536 - acc: 0.898 - ETA: 1:31 - loss: 0.2512 - acc: 0.899 - ETA: 1:30 - loss: 0.2518 - acc: 0.900 - ETA: 1:29 - loss: 0.2534 - acc: 0.899 - ETA: 1:28 - loss: 0.2519 - acc: 0.899 - ETA: 1:28 - loss: 0.2515 - acc: 0.899 - ETA: 1:27 - loss: 0.2535 - acc: 0.898 - ETA: 1:26 - loss: 0.2579 - acc: 0.896 - ETA: 1:25 - loss: 0.2579 - acc: 0.896 - ETA: 1:25 - loss: 0.2574 - acc: 0.896 - ETA: 1:24 - loss: 0.2573 - acc: 0.896 - ETA: 1:23 - loss: 0.2581 - acc: 0.896 - ETA: 1:22 - loss: 0.2603 - acc: 0.895 - ETA: 1:21 - loss: 0.2604 - acc: 0.895 - ETA: 1:21 - loss: 0.2599 - acc: 0.895 - ETA: 1:20 - loss: 0.2592 - acc: 0.896 - ETA: 1:19 - loss: 0.2586 - acc: 0.895 - ETA: 1:18 - loss: 0.2602 - acc: 0.894 - ETA: 1:17 - loss: 0.2608 - acc: 0.894 - ETA: 1:17 - loss: 0.2590 - acc: 0.895 - ETA: 1:16 - loss: 0.2587 - acc: 0.895 - ETA: 1:15 - loss: 0.2581 - acc: 0.896 - ETA: 1:14 - loss: 0.2561 - acc: 0.897 - ETA: 1:13 - loss: 0.2569 - acc: 0.897 - ETA: 1:13 - loss: 0.2553 - acc: 0.897 - ETA: 1:12 - loss: 0.2570 - acc: 0.897 - ETA: 1:11 - loss: 0.2589 - acc: 0.896 - ETA: 1:10 - loss: 0.2591 - acc: 0.896 - ETA: 1:09 - loss: 0.2574 - acc: 0.898 - ETA: 1:09 - loss: 0.2570 - acc: 0.898 - ETA: 1:08 - loss: 0.2566 - acc: 0.898 - ETA: 1:07 - loss: 0.2570 - acc: 0.897 - ETA: 1:06 - loss: 0.2602 - acc: 0.896 - ETA: 1:05 - loss: 0.2603 - acc: 0.896 - ETA: 1:05 - loss: 0.2620 - acc: 0.895 - ETA: 1:04 - loss: 0.2626 - acc: 0.895 - ETA: 1:03 - loss: 0.2639 - acc: 0.894 - ETA: 1:02 - loss: 0.2633 - acc: 0.894 - ETA: 1:02 - loss: 0.2642 - acc: 0.894 - ETA: 1:01 - loss: 0.2652 - acc: 0.893 - ETA: 1:00 - loss: 0.2639 - acc: 0.894 - ETA: 59s - loss: 0.2641 - acc: 0.895 - ETA: 58s - loss: 0.2628 - acc: 0.89 - ETA: 58s - loss: 0.2627 - acc: 0.89 - ETA: 57s - loss: 0.2627 - acc: 0.89 - ETA: 56s - loss: 0.2643 - acc: 0.89 - ETA: 55s - loss: 0.2658 - acc: 0.89 - ETA: 55s - loss: 0.2662 - acc: 0.89 - ETA: 54s - loss: 0.2665 - acc: 0.89 - ETA: 53s - loss: 0.2663 - acc: 0.89 - ETA: 52s - loss: 0.2665 - acc: 0.89 - ETA: 51s - loss: 0.2684 - acc: 0.89 - ETA: 51s - loss: 0.2685 - acc: 0.89 - ETA: 50s - loss: 0.2714 - acc: 0.89 - ETA: 49s - loss: 0.2718 - acc: 0.89 - ETA: 48s - loss: 0.2707 - acc: 0.89 - ETA: 48s - loss: 0.2727 - acc: 0.89 - ETA: 47s - loss: 0.2728 - acc: 0.89 - ETA: 46s - loss: 0.2733 - acc: 0.89 - ETA: 45s - loss: 0.2744 - acc: 0.89 - ETA: 44s - loss: 0.2741 - acc: 0.89 - ETA: 44s - loss: 0.2751 - acc: 0.88 - ETA: 43s - loss: 0.2744 - acc: 0.88 - ETA: 42s - loss: 0.2743 - acc: 0.88 - ETA: 41s - loss: 0.2758 - acc: 0.88 - ETA: 41s - loss: 0.2767 - acc: 0.88 - ETA: 40s - loss: 0.2764 - acc: 0.88 - ETA: 39s - loss: 0.2768 - acc: 0.88 - ETA: 38s - loss: 0.2779 - acc: 0.88 - ETA: 37s - loss: 0.2775 - acc: 0.88 - ETA: 37s - loss: 0.2778 - acc: 0.88 - ETA: 36s - loss: 0.2780 - acc: 0.88 - ETA: 35s - loss: 0.2798 - acc: 0.88 - ETA: 34s - loss: 0.2790 - acc: 0.88 - ETA: 33s - loss: 0.2795 - acc: 0.88 - ETA: 33s - loss: 0.2794 - acc: 0.88 - ETA: 32s - loss: 0.2804 - acc: 0.88 - ETA: 31s - loss: 0.2795 - acc: 0.88 - ETA: 30s - loss: 0.2792 - acc: 0.88 - ETA: 30s - loss: 0.2794 - acc: 0.88 - ETA: 29s - loss: 0.2796 - acc: 0.88 - ETA: 28s - loss: 0.2801 - acc: 0.88 - ETA: 27s - loss: 0.2795 - acc: 0.88 - ETA: 26s - loss: 0.2796 - acc: 0.88 - ETA: 26s - loss: 0.2797 - acc: 0.88 - ETA: 25s - loss: 0.2802 - acc: 0.88 - ETA: 24s - loss: 0.2813 - acc: 0.88 - ETA: 23s - loss: 0.2821 - acc: 0.88 - ETA: 23s - loss: 0.2821 - acc: 0.88 - ETA: 22s - loss: 0.2830 - acc: 0.88 - ETA: 21s - loss: 0.2820 - acc: 0.88 - ETA: 20s - loss: 0.2817 - acc: 0.88 - ETA: 19s - loss: 0.2808 - acc: 0.88 - ETA: 19s - loss: 0.2807 - acc: 0.88 - ETA: 18s - loss: 0.2802 - acc: 0.88 - ETA: 17s - loss: 0.2801 - acc: 0.88 - ETA: 16s - loss: 0.2799 - acc: 0.88 - ETA: 16s - loss: 0.2800 - acc: 0.88 - ETA: 15s - loss: 0.2797 - acc: 0.88 - ETA: 14s - loss: 0.2788 - acc: 0.88 - ETA: 13s - loss: 0.2788 - acc: 0.88 - ETA: 12s - loss: 0.2792 - acc: 0.88 - ETA: 12s - loss: 0.2783 - acc: 0.88 - ETA: 11s - loss: 0.2782 - acc: 0.88 - ETA: 10s - loss: 0.2781 - acc: 0.88 - ETA: 9s - loss: 0.2787 - acc: 0.8859 - ETA: 8s - loss: 0.2789 - acc: 0.886 - ETA: 8s - loss: 0.2788 - acc: 0.886 - ETA: 7s - loss: 0.2788 - acc: 0.886 - ETA: 6s - loss: 0.2785 - acc: 0.886 - ETA: 5s - loss: 0.2783 - acc: 0.886 - ETA: 4s - loss: 0.2777 - acc: 0.886 - ETA: 4s - loss: 0.2777 - acc: 0.886 - ETA: 3s - loss: 0.2777 - acc: 0.886 - ETA: 2s - loss: 0.2779 - acc: 0.886 - ETA: 1s - loss: 0.2785 - acc: 0.886 - ETA: 1s - loss: 0.2780 - acc: 0.886 - ETA: 0s - loss: 0.2771 - acc: 0.886 - 168s 28ms/step - loss: 0.2772 - acc: 0.8867 - val_loss: 1.9140 - val_acc: 0.4837\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.00784\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x235f8312518>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_checkpts = ModelCheckpoint(filepath=os.path.join(os.getcwd() + '/saved_models/text/sentiment/cnn.weights.best.hdf5'), \n",
    "                               verbose=1, save_best_only=True)\n",
    "sen_cnn = build_CNN(num_polarities)\n",
    "sen_cnn.fit(x_train_reshaped, z_train, validation_split=0.4, epochs=5, callbacks=[cnn_checkpts], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 1339, 0: 751, 2: 520})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_pred_cnn = sen_cnn.predict_classes(x_test_reshaped)\n",
    "Counter(z_pred_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 48.5824%\n"
     ]
    }
   ],
   "source": [
    "cnn_accuracy = 100*np.sum(z_pred_cnn==z_transf)/len(z_transf)\n",
    "print('Test accuracy: %.4f%%' % cnn_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
