{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "# import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from math import floor\n",
    "from collections import Counter\n",
    "# from factory_func import plot_confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, ENGLISH_STOP_WORDS\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, f1_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Embedding, Conv1D, Conv2D, Lambda, LSTM, ConvLSTM2D, TimeDistributed, Masking, Bidirectional\n",
    "from keras.layers import Reshape, Flatten, Dropout, Concatenate, Activation, MaxPooling1D, GlobalAveragePooling1D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Model, load_model, Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import to_categorical\n",
    "from keras import optimizers\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gzip\n",
    "# from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. ETL & Cleansing  \n",
    "### 2. Rebalancing (Undersampling)  \n",
    "### 3. Feature Extraction  \n",
    "### 4. Model Selection & Evaluation  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Records  \n",
    "SVM: 45.5172%  \n",
    "Dense NN: 45.1724%  \n",
    "CNN: 47.2414%  \n",
    "LSTM: tbc  \n",
    "  \n",
    "*(there might be a ceiling for how much you can improve the accuracy)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_raw = pd.read_csv(os.path.join(os.getcwd(), 'data','dev_sent_emo.csv'))\n",
    "train_raw = pd.read_csv(os.path.join(os.getcwd(), 'data','train_sent_emo.csv'))\n",
    "test_raw = pd.read_csv(os.path.join(os.getcwd(), 'data','test_sent_emo.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sr No.</th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Dialogue_ID</th>\n",
       "      <th>Utterance_ID</th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>StartTime</th>\n",
       "      <th>EndTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Oh my God, hes lost it. Hes totally lost it.</td>\n",
       "      <td>Phoebe</td>\n",
       "      <td>sadness</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>00:20:57,256</td>\n",
       "      <td>00:21:00,049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>What?</td>\n",
       "      <td>Monica</td>\n",
       "      <td>surprise</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>00:21:01,927</td>\n",
       "      <td>00:21:03,261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Or! Or, we could go to the bank, close our acc...</td>\n",
       "      <td>Ross</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>00:12:24,660</td>\n",
       "      <td>00:12:30,915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Youre a genius!</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>joy</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>00:12:32,334</td>\n",
       "      <td>00:12:33,960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Aww, man, now we wont be bank buddies!</td>\n",
       "      <td>Joey</td>\n",
       "      <td>sadness</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>00:12:34,211</td>\n",
       "      <td>00:12:37,505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sr No.                                          Utterance   Speaker  \\\n",
       "0       1     Oh my God, hes lost it. Hes totally lost it.    Phoebe   \n",
       "1       2                                              What?    Monica   \n",
       "2       3  Or! Or, we could go to the bank, close our acc...      Ross   \n",
       "3       4                                   Youre a genius!  Chandler   \n",
       "4       5            Aww, man, now we wont be bank buddies!      Joey   \n",
       "\n",
       "    Emotion Sentiment  Dialogue_ID  Utterance_ID  Season  Episode  \\\n",
       "0   sadness  negative            0             0       4        7   \n",
       "1  surprise  negative            0             1       4        7   \n",
       "2   neutral   neutral            1             0       4        4   \n",
       "3       joy  positive            1             1       4        4   \n",
       "4   sadness  negative            1             2       4        4   \n",
       "\n",
       "      StartTime       EndTime  \n",
       "0  00:20:57,256  00:21:00,049  \n",
       "1  00:21:01,927  00:21:03,261  \n",
       "2  00:12:24,660  00:12:30,915  \n",
       "3  00:12:32,334  00:12:33,960  \n",
       "4  00:12:34,211  00:12:37,505  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'testing set')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, axes = plt.subplots(1, 3, figsize=(15,4))\n",
    "sns.countplot(x='Sentiment', data=dev_raw, ax=axes[0], order=['negative','neutral','positive']).set_title('dev set')\n",
    "sns.countplot(x='Sentiment', data=train_raw, ax=axes[1], order=['negative','neutral','positive']).set_title('training set')\n",
    "sns.countplot(x='Sentiment', data=test_raw, ax=axes[2], order=['negative','neutral','positive']).set_title('testing set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'neutral': 470, 'negative': 406, 'positive': 233})\n",
      "Counter({'neutral': 4710, 'negative': 2945, 'positive': 2334})\n",
      "Counter({'neutral': 1256, 'negative': 833, 'positive': 521})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(dev_raw.Sentiment))\n",
    "print(Counter(train_raw.Sentiment))\n",
    "print(Counter(test_raw.Sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_raw.Utterance = dev_raw.Utterance.apply(lambda x: re.sub('\\\\x92', \"'\", x))\n",
    "train_raw.Utterance = train_raw.Utterance.apply(lambda x: re.sub('\\\\x92', \"'\", x))\n",
    "test_raw.Utterance = test_raw.Utterance.apply(lambda x: re.sub('\\\\x92', \"'\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'train+test set')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_raw['source'] = 'train'\n",
    "test_raw['source'] = 'test'\n",
    "data_raw = pd.concat([train_raw, test_raw])\n",
    "data_raw.shape\n",
    "sns.countplot(x='Sentiment', data=data_raw, order=['negative','neutral','positive']).set_title('train+test set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling  \n",
    "To deal with imbalanced datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3778 negative, 5966 neutral and 2855 positive utternaces.\n"
     ]
    }
   ],
   "source": [
    "count_neutral, count_negative, count_positive = data_raw.Sentiment.value_counts()\n",
    "print(f'There are {count_negative} negative, {count_neutral} neutral and {count_positive} positive utternaces.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df_negative = data_raw[data_raw.Sentiment == 'negative']\n",
    "tmp_df_neutral = data_raw[data_raw.Sentiment == 'neutral']\n",
    "tmp_df_positive = data_raw[data_raw.Sentiment == 'positive']\n",
    "\n",
    "tmp_df_negative_undersampled = tmp_df_negative.sample(floor(count_positive*1.1)).reset_index(drop=True)\n",
    "tmp_df_neutral_undersampled = tmp_df_neutral.sample(floor(count_positive*0.95)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sr No.</th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Dialogue_ID</th>\n",
       "      <th>Utterance_ID</th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>StartTime</th>\n",
       "      <th>EndTime</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2234</th>\n",
       "      <td>5909</td>\n",
       "      <td>Don't call us that!</td>\n",
       "      <td>Rachel</td>\n",
       "      <td>anger</td>\n",
       "      <td>negative</td>\n",
       "      <td>596</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>00:15:20,002</td>\n",
       "      <td>00:15:23,379</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3673</th>\n",
       "      <td>3878</td>\n",
       "      <td>Kinda, but I've just been having way too much ...</td>\n",
       "      <td>Joey</td>\n",
       "      <td>joy</td>\n",
       "      <td>positive</td>\n",
       "      <td>392</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>00:18:15,761</td>\n",
       "      <td>00:18:18,596</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>2765</td>\n",
       "      <td>I'm not listening to you!</td>\n",
       "      <td>Joey</td>\n",
       "      <td>anger</td>\n",
       "      <td>negative</td>\n",
       "      <td>275</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>00:15:48,822</td>\n",
       "      <td>00:15:50,907</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>2584</td>\n",
       "      <td>Oh god, oh god.</td>\n",
       "      <td>Monica</td>\n",
       "      <td>joy</td>\n",
       "      <td>positive</td>\n",
       "      <td>255</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>00:13:14,752</td>\n",
       "      <td>00:13:16,669</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2802</th>\n",
       "      <td>7459</td>\n",
       "      <td>Well, it's official there are no good movies.</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>sadness</td>\n",
       "      <td>negative</td>\n",
       "      <td>745</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>00:01:53,780</td>\n",
       "      <td>00:01:56,240</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sr No.                                          Utterance   Speaker  \\\n",
       "2234    5909                                Don't call us that!    Rachel   \n",
       "3673    3878  Kinda, but I've just been having way too much ...      Joey   \n",
       "1985    2765                          I'm not listening to you!      Joey   \n",
       "2441    2584                                    Oh god, oh god.    Monica   \n",
       "2802    7459      Well, it's official there are no good movies.  Chandler   \n",
       "\n",
       "      Emotion Sentiment  Dialogue_ID  Utterance_ID  Season  Episode  \\\n",
       "2234    anger  negative          596            19       6        5   \n",
       "3673      joy  positive          392             9       4       23   \n",
       "1985    anger  negative          275            16       5       11   \n",
       "2441      joy  positive          255            12       1       22   \n",
       "2802  sadness  negative          745             0       3        4   \n",
       "\n",
       "         StartTime       EndTime source  \n",
       "2234  00:15:20,002  00:15:23,379  train  \n",
       "3673  00:18:15,761  00:18:18,596  train  \n",
       "1985  00:15:48,822  00:15:50,907  train  \n",
       "2441  00:13:14,752  00:13:16,669  train  \n",
       "2802  00:01:53,780  00:01:56,240  train  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_balanced = pd.concat([tmp_df_negative_undersampled, tmp_df_neutral_undersampled, tmp_df_positive], axis=0)\n",
    "data_balanced = shuffle(data_balanced)\n",
    "data_balanced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3140 negative, 2712 neutral and 2855 positive utternaces.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'rebalanced set')"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_c_negative, new_c_positive, new_c_neutral = data_balanced.Sentiment.value_counts()\n",
    "print(f'There are {new_c_negative} negative, {new_c_neutral} neutral and {new_c_positive} positive utternaces.')\n",
    "sns.countplot(x='Sentiment', data=data_balanced, order=['negative','neutral','positive']).set_title('rebalanced set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_balanced.Utterance\n",
    "y = data_balanced.Sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tfidf + SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(lowercase=True, stop_words='english', ngram_range=(1,3))\n",
    "tfidf.fit(x_train)\n",
    "x_dev_tf = tfidf.transform(x_dev)\n",
    "x_train_tf = tfidf.transform(x_train)\n",
    "x_test_tf = tfidf.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svd = TruncatedSVD(n_components=300)\n",
    "# x_dev_tr = svd.fit_transform(x_dev_tf)\n",
    "# x_train_tr = svd.fit_transform(x_train_tf)\n",
    "# x_test_tr = svd.fit_transform(x_test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(C=10, kernel='linear', probability=True)\n",
    "# param_grid = { \n",
    "#     'C': [1,10,100], 'kernel': ['linear', 'rbf']\n",
    "# }\n",
    "# clf = GridSearchCV(estimator=svm, param_grid=param_grid, cv=5)\n",
    "# clf.fit(x_train_tr, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Best model by GridSearchCV**  \n",
    "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,  \n",
    "decision_function_shape='ovr', degree=3, gamma='auto_deprecated',  \n",
    "kernel='linear', max_iter=-1, probability=True, random_state=None,  \n",
    "shrinking=True, tol=0.001, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.fit(X=x_train_tf, y=y_train)\n",
    "y_pred_svm = svm.predict(x_test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42923347861223476"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=y_pred_svm, y_true=y_test, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 45.5172%\n"
     ]
    }
   ],
   "source": [
    "svm_accuracy = 100*np.sum(y_pred_svm==y_test)/len(y_pred_svm)\n",
    "print('Test accuracy: %.4f%%' % svm_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras TF-IDF tokenizer + Neural nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural network won't accept sentences with different dimension(i.e. number of words) as input. By padding the inputs, we decide the maximum length of words in a sentence, then zero pads the rest, if the input length is shorter than the designated length. In the case where it exceeds the maximum length, then it will also truncate either from the beginning or from the end.  \n",
    "*Ref_1* https://keras.io/preprocessing/sequence/  \n",
    "*Ref_2* https://towardsdatascience.com/another-twitter-sentiment-analysis-with-python-part-11-cnn-word2vec-41f5e28eda74\n",
    "\n",
    "https://medium.com/@sabber/classifying-yelp-review-comments-using-lstm-and-word-embeddings-part-1-eb2275e4066b\n",
    "#### Dense - Fully Connected Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5851 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "# For sentiment analysis\n",
    "num_polarities = 3\n",
    "\n",
    "vocabulary_size = 12000\n",
    "tokenizer = Tokenizer(num_words= vocabulary_size, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{}~', lower=True)\n",
    "tokenizer.fit_on_texts(x_train.values)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = tokenizer.texts_to_matrix(x_train, mode='tfidf')\n",
    "# x_test = tokenizer.texts_to_matrix(x_test, mode='tfidf')\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anger': 0,\n",
       " 'disgust': 1,\n",
       " 'fear': 2,\n",
       " 'joy': 3,\n",
       " 'neutral': 4,\n",
       " 'sadness': 5,\n",
       " 'surprise': 6}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prep target labels for emotion analysis\n",
    "targets, uniques = pd.factorize(y_train, sort=True)\n",
    "y_train = to_categorical(targets, num_classes)\n",
    "\n",
    "label_map = dict(zip(list(uniques), range(num_classes)))\n",
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'negative': 0, 'neutral': 1, 'positive': 2}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prep target labels for sentiment analysis\n",
    "sen_targets, sen_uniques = pd.factorize(z_train, sort=True)\n",
    "z_train = to_categorical(sen_targets, num_polarities)\n",
    "\n",
    "sen_label_map = dict(zip(list(sen_uniques), range(num_polarities)))\n",
    "sen_label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.fit_on_sequences(x_dev)\n",
    "# tokenizer.texts_to_sequences(x_dev)\n",
    "# tokenizer.texts_to_matrix(x_dev, mode='tfidf')\n",
    "# y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 1.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_transf = list(map(label_map.get, y_test))\n",
    "z_transf = list(map(sen_label_map.get, z_test))\n",
    "y_true = to_categorical(np.array(y_transf), num_classes)\n",
    "z_true = to_categorical(np.array(z_transf), num_polarities)\n",
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_checkpts = ModelCheckpoint(filepath=os.path.join(os.getcwd(),'dense.weights.best.hdf5'), \n",
    "                               verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 32)                640032    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 651,367\n",
      "Trainable params: 651,367\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_classes = 7\n",
    "\n",
    "dense = Sequential()\n",
    "dense.add(Dense(32, activation='relu', input_dim=20000))\n",
    "# model.add(Dropout(0.2))\n",
    "dense.add(Dense(64, activation='relu'))\n",
    "dense.add(Dense(128, activation='relu'))\n",
    "dense.add(Dense(num_classes, activation='softmax'))\n",
    "dense.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "dense.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conv1D is generally good for text, whereas Conv2D is good for audio and images where spatial matter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 5993 samples, validate on 3996 samples\n",
      "Epoch 1/10\n",
      "5993/5993 [==============================] - 12s 2ms/step - loss: 1.5441 - acc: 0.4752 - val_loss: 1.4405 - val_acc: 0.4962\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.44054, saving model to /home/ubuntu/dense.weights.best.hdf5\n",
      "Epoch 2/10\n",
      "5993/5993 [==============================] - 2s 259us/step - loss: 1.1404 - acc: 0.5912 - val_loss: 1.4937 - val_acc: 0.4857\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.44054\n",
      "Epoch 3/10\n",
      "5993/5993 [==============================] - 2s 263us/step - loss: 0.7363 - acc: 0.7470 - val_loss: 1.7717 - val_acc: 0.4647\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.44054\n",
      "Epoch 4/10\n",
      "5993/5993 [==============================] - 2s 258us/step - loss: 0.5081 - acc: 0.8275 - val_loss: 2.1122 - val_acc: 0.4530\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.44054\n",
      "Epoch 5/10\n",
      "5993/5993 [==============================] - 2s 263us/step - loss: 0.3890 - acc: 0.8693 - val_loss: 2.4845 - val_acc: 0.4757\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.44054\n",
      "Epoch 6/10\n",
      "5993/5993 [==============================] - 2s 262us/step - loss: 0.3234 - acc: 0.8922 - val_loss: 2.6374 - val_acc: 0.4464\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.44054\n",
      "Epoch 7/10\n",
      "5993/5993 [==============================] - 2s 260us/step - loss: 0.2707 - acc: 0.9086 - val_loss: 2.8719 - val_acc: 0.4374\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.44054\n",
      "Epoch 8/10\n",
      "5993/5993 [==============================] - 2s 258us/step - loss: 0.2425 - acc: 0.9154 - val_loss: 3.1739 - val_acc: 0.4532\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.44054\n",
      "Epoch 9/10\n",
      "5993/5993 [==============================] - 2s 260us/step - loss: 0.2184 - acc: 0.9266 - val_loss: 3.2531 - val_acc: 0.4334\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.44054\n",
      "Epoch 10/10\n",
      "5993/5993 [==============================] - 2s 261us/step - loss: 0.2023 - acc: 0.9309 - val_loss: 3.4404 - val_acc: 0.4404\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.44054\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fac685b5f60>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense.fit(x_train, y_train, validation_split=0.4, epochs=10, callbacks=[dense_checkpts], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data = pad_sequences(tokenizer.texts_to_sequences(x_test), maxlen=50)\n",
    "y_pred_dense = dense.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({4: 1497, 3: 317, 6: 280, 0: 249, 5: 201, 2: 39, 1: 27})"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_pred_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2610/2610 [==============================] - 0s 107us/step\n",
      "Test accuracy: 44.8276%\n"
     ]
    }
   ],
   "source": [
    "# test_accuracy = 100*np.sum(y_pred_dense==y_true)/len(y_true)\n",
    "# print('Test accuracy: %.4f%%' % test_accuracy)\n",
    "dense_accuracy = dense.evaluate(x_test, y_true, batch_size=128)[1] * 100\n",
    "print('Test accuracy: %.4f%%' % dense_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['anger', 'disgust', 'fear', 'joy', 'neutral', 'sadness', 'surprise'], dtype='object')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__About batch_size__  \n",
    "Advantages of using a batch size < number of all samples:\n",
    "\n",
    "- It requires less memory. Since you train the network using fewer samples, the overall training procedure requires less memory. That's especially important if you are not able to fit the whole dataset in your machine's memory.\n",
    "\n",
    "- Typically networks train faster with mini-batches. That's because we update the weights after each propagation. In our example we've propagated 11 batches (10 of them had 100 samples and 1 had 50 samples) and after each of them we've updated our network's parameters. If we used all samples during propagation we would make only 1 update for the network's parameter.\n",
    "\n",
    "Disadvantages of using a batch size < number of all samples:\n",
    "\n",
    "- The smaller the batch the less accurate the estimate of the gradient will be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN - Convolutional Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 7\n",
    "n_length = x_train.shape[0]\n",
    "n_features = x_train.shape[1]\n",
    "\n",
    "x_train_reshaped = x_train.reshape(n_length, n_features, 1)\n",
    "x_test_reshaped = x_test.reshape(x_test.shape[0], n_features, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_checkpts = ModelCheckpoint(filepath=os.path.join(os.getcwd(), 'cnn.weights.best.hdf5'), \n",
    "                               verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_CNN(num_classes):\n",
    "    cnn = Sequential()\n",
    "    cnn.add(Conv1D(filters=16, kernel_size=2, padding='same', activation='relu', input_shape=(n_features, 1)))\n",
    "    cnn.add(MaxPooling1D(pool_size=2))\n",
    "    cnn.add(Conv1D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "    cnn.add(MaxPooling1D(pool_size=2))\n",
    "    cnn.add(Conv1D(filters=64, kernel_size=2, padding='same', activation='relu'))\n",
    "    cnn.add(MaxPooling1D(pool_size=2))\n",
    "    # cnn.add(GlobalAveragePooling1D())\n",
    "    cnn.add(Flatten())\n",
    "    cnn.add(Dense(128, activation='relu'))\n",
    "    cnn.add(Dense(num_classes, activation='softmax'))\n",
    "    cnn.compile(optimizer='adam',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    print(cnn.summary())\n",
    "    return cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 20000, 16)         48        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 10000, 16)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 10000, 32)         1056      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 5000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 5000, 64)          4160      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 2500, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 160000)            0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 128)               20480128  \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 20,486,295\n",
      "Trainable params: 20,486,295\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "cnn = build_CNN(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5993 samples, validate on 3996 samples\n",
      "Epoch 1/5\n",
      "5993/5993 [==============================] - 46s 8ms/step - loss: 1.5400 - acc: 0.4724 - val_loss: 1.4826 - val_acc: 0.4855\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.48262, saving model to /home/ubuntu/cnn.weights.best.hdf5\n",
      "Epoch 2/5\n",
      "5993/5993 [==============================] - 17s 3ms/step - loss: 1.2248 - acc: 0.5496 - val_loss: 1.5161 - val_acc: 0.4852\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.48262\n",
      "Epoch 3/5\n",
      "5993/5993 [==============================] - 17s 3ms/step - loss: 0.8583 - acc: 0.6848 - val_loss: 1.7594 - val_acc: 0.4622\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.48262\n",
      "Epoch 4/5\n",
      "5993/5993 [==============================] - 17s 3ms/step - loss: 0.5880 - acc: 0.7873 - val_loss: 2.1419 - val_acc: 0.4417\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.48262\n",
      "Epoch 5/5\n",
      "5993/5993 [==============================] - 17s 3ms/step - loss: 0.4343 - acc: 0.8453 - val_loss: 2.5547 - val_acc: 0.4362\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.48262\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fac145421d0>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(x_train_reshaped, y_train, validation_split=0.4, epochs=5, callbacks=[cnn_checkpts], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({4: 1519, 3: 377, 5: 129, 1: 49, 6: 270, 0: 229, 2: 37})"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_cnn = cnn.predict_classes(x_test_reshaped)\n",
    "# y_pred_cnn = [np.argmax(x) for x in cnn.predict(x_test_reshaped)]\n",
    "Counter(y_pred_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2610/2610 [==============================] - 2s 673us/step\n",
      "Test accuracy: 43.6782%\n"
     ]
    }
   ],
   "source": [
    "# cnn_accuracy = 100*np.sum(y_pred_cnn==y_true)/len(y_pred_cnn)\n",
    "# print('Test accuracy: %.4f%%' % cnn_accuracy)\n",
    "cnn_accuracy = cnn.evaluate(x_test_reshaped, y_true, batch_size=128)[1] * 100\n",
    "print('Test accuracy: %.4f%%' % cnn_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn_score = cnn.evaluate(x_test_reshaped, y_pred_cnn, verbose=1)\n",
    "# print(\"%s: %.2f%%\" % (cnn.metrics_names[1], cnn_score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Serialise the model architecture to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(os.getcwd(), \"saved_models\", \"text\", \"emotion\", \"cnn.model.json\", \"w\") as json_file:\n",
    "    json_file.write(cnn.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json and create model\n",
    "json_file = open('./saved_models/text/emotion/cnn.json', 'r')\n",
    "loaded_cnn_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_cnn = model_from_json(loaded_cnn_json)\n",
    "# load weights into new model\n",
    "loaded_cnn.load_weights(\"cnn.weights.best.hdf5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENGLISH_STOP_WORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WordEnbedding + LSTM  \n",
    "- checkpoint: try a pre-trained embedding layer e.g. GloVe Embedding, Word2Vec  \n",
    "  \n",
    "Building the embedding from scratch instead of using pre-trained (*this can be a slower approach, but tailors the model to a specific training dataset*)  \n",
    "\n",
    "Ref_1: https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_checkpts = ModelCheckpoint(filepath=os.path.join(os.getcwd() + '/saved_models/text/emotion/lstm.weights.best.hdf5'), \n",
    "                               verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_13 (Embedding)     (None, 20000, 128)        2560000   \n",
      "_________________________________________________________________\n",
      "lstm_13 (LSTM)               (None, 20000, 64)         49408     \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 1280000)           0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 7)                 8960007   \n",
      "=================================================================\n",
      "Total params: 11,569,415\n",
      "Trainable params: 11,569,415\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# vocabulary_size = 20000\n",
    "embedding_size=128\n",
    "lstm_output_size=64  #70\n",
    "num_classes=7\n",
    "\n",
    "lstm = Sequential()\n",
    "lstm.add(Embedding(input_dim=vocabulary_size, output_dim=embedding_size, input_length=20000))\n",
    "lstm.add(LSTM(units=lstm_output_size, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n",
    "lstm.add(Flatten())\n",
    "lstm.add(Dense(num_classes, activation='sigmoid'))\n",
    "          \n",
    "lstm.compile(loss='categorical_crossentropy',\n",
    "            optimizer='adam',\n",
    "            metrics=['accuracy'])\n",
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5993 samples, validate on 3996 samples\n",
      "Epoch 1/3\n",
      "5993/5993 [==============================] - 1072s 179ms/step - loss: 1.5608 - acc: 0.4726 - val_loss: 1.5449 - val_acc: 0.4670\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.54495, saving model to C:\\Users\\syip\\Desktop\\DaSci\\Nanodegree\\ml_nanodegree\\capstone/saved_models/lstm.weights.best.hdf5\n",
      "Epoch 2/3\n",
      "5993/5993 [==============================] - 1074s 179ms/step - loss: 1.5429 - acc: 0.4746 - val_loss: 1.5357 - val_acc: 0.4670\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.54495 to 1.53567, saving model to C:\\Users\\syip\\Desktop\\DaSci\\Nanodegree\\ml_nanodegree\\capstone/saved_models/lstm.weights.best.hdf5\n",
      "Epoch 3/3\n",
      "5993/5993 [==============================] - 1067s 178ms/step - loss: 1.5419 - acc: 0.4746 - val_loss: 1.5396 - val_acc: 0.4670\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.53567\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f206cfb550>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.fit(x_train, y_train, validation_split=0.4, epochs=1, callbacks=[lstm_checkpts], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({4: 2610})"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_lstm = lstm.predict_classes(x_test)\n",
    "Counter(y_pred_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_accuracy = 100*np.sum(y_pred_lstm==y_true)/len(y_pred_lstm)\n",
    "print('Test accuracy: %.4f%%' % lstm_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_lstm = load_model('./saved_models/text/emotion/lstm.weights.best.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 4, 4, 4, 4], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_lstm.predict_classes(x_test[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WordEmbedding + ConvLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, 20000, 128)        2560000   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 20000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 19996, 64)         41024     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 4999, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 4999, 32)          12416     \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 159968)            0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 7)                 1119783   \n",
      "=================================================================\n",
      "Total params: 3,733,223\n",
      "Trainable params: 3,733,223\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "max_features=20000\n",
    "embedding_size=128\n",
    "lstm_output_size=32  #70\n",
    "num_classes=7\n",
    "\n",
    "conv_lstm = Sequential()\n",
    "conv_lstm.add(Embedding(input_dim=max_features, output_dim=embedding_size, input_length=20000))\n",
    "conv_lstm.add(Dropout(0.25))\n",
    "conv_lstm.add(Conv1D(filters=64,\n",
    "                 kernel_size=5,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1))\n",
    "conv_lstm.add(MaxPooling1D(pool_size=4))\n",
    "conv_lstm.add(LSTM(units=lstm_output_size, return_sequences=True))\n",
    "conv_lstm.add(Flatten())\n",
    "conv_lstm.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "conv_lstm.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "conv_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_lstm_checkpts = ModelCheckpoint(filepath=os.path.join(os.getcwd() + '/saved_models/text/emotion/conv_lstm.weights.best.hdf5'), \n",
    "                               verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_lstm.fit(x_train, y_train, validation_split=0.4, callback=[conv_lstm_checkpts], epochs=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({4: 2610})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_conv_lstm = conv_lstm.predict_classes(x_test)\n",
    "Counter(y_pred_conv_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.0000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syip\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "conv_lstm_accuracy = 100*np.sum(y_pred_conv_lstm==y_true)/len(y_true)\n",
    "print('Test accuracy: %.4f%%' % conv_lstm_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec  \n",
    "Do transfer learning with pre-trained word embedding layers, such as Word2Vec & GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dev_tokens = [sentence.split() for sentence in x_dev]\n",
    "x_train_tokens = [sentence.split() for sentence in x_train]\n",
    "\n",
    "model = Word2Vec(\n",
    "    x_train_tokens,\n",
    "    size=150,\n",
    "    window=10,\n",
    "    min_count=2,\n",
    "    workers=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first parameter passed to gensim.models.Word2Vec is an iterable of sentences. Sentences themselves are a list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(x_train_tokens, total_examples=len(x_train), epochs=10)\n",
    "\n",
    "w = ['good']\n",
    "# w = filter(lambda x: x in model.vocab, x_train.tokens)\n",
    "model.wv.most_similar(positive=w,\n",
    "#                       topn=6\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GloVe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract word embeddings from the Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = dict()\n",
    "f = open('glove.6B.100d.txt', encoding=\"utf8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a weight matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocabulary_size=9000\n",
    "\n",
    "embedding_matrix = np.zeros((vocabulary_size, 100))\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    if index > vocabulary_size - 1:\n",
    "        break\n",
    "    else:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[index] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create ConvLSTM model with GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ConvLSTM(num_classes, vocabulary_size=None, dense_activation=None, optimizer=None, use_glove=None):\n",
    "    dense_activation = dense_activation or 'softmax'\n",
    "    optimizer = optimizer or 'adam'\n",
    "    use_glove = use_glove or True\n",
    "    embedding_size=100\n",
    "    lstm_output_size=128\n",
    "    vocabulary_size= vocabulary_size or 20000\n",
    "    \n",
    "    model = Sequential()\n",
    "    if use_glove:\n",
    "        model.add(Embedding(input_dim=vocabulary_size, output_dim=embedding_size, input_length=vocabulary_size,\n",
    "                            weights=[embedding_matrix], trainable=False))\n",
    "    else:\n",
    "        model.add(Embedding(input_dim=vocabulary_size, output_dim=embedding_size, input_length=vocabulary_size))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv1D(filters=64,\n",
    "                     kernel_size=5,\n",
    "                     padding='valid',\n",
    "                     activation='relu',\n",
    "                     kernel_regularizer=l2(0.01),\n",
    "                     strides=1))\n",
    "    model.add(MaxPooling1D(pool_size=4))\n",
    "    model.add(LSTM(units=lstm_output_size, return_sequences=True))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(TimeDistributed(Dense(32)))\n",
    "#     model.add(Flatten())\n",
    "    model.add(GlobalAveragePooling1D())\n",
    "    model.add(Dense(16, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dense(num_classes, activation=dense_activation))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_checkpts = ModelCheckpoint(filepath=os.path.join(os.getcwd() + '/saved_models/text/emotion/glove.weights.best.hdf5'), \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "glove.fit(x_train, y_train, validation_split=0.4, epochs=1, callbacks=[glove_checkpts], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({4: 2610})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_glove = glove.predict_classes(x_test)\n",
    "Counter(y_pred_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({4: 4710, 6: 1205, 2: 268, 5: 683, 3: 1743, 1: 271, 0: 1109})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis  \n",
    "__Predicting 3 classes: Positive, Negative & Neutral__  \n",
    "  \n",
    "**Models ready at disposal:**  \n",
    "- svm  \n",
    "- dense  \n",
    "- cnn  \n",
    "- lstm  \n",
    "- conv_lstm  \n",
    "\n",
    "**Accuracy records**  \n",
    "- cnn: 48.5824%  \n",
    "- lstm with glove: 48.3908%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'negative': 0, 'neutral': 1, 'positive': 2}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_polarities = 3\n",
    "\n",
    "# sen_targets, sen_uniques = pd.factorize(z_train, sort=True)\n",
    "# z_train = to_categorical(sen_targets, num_polarities)\n",
    "\n",
    "sen_label_map = dict(zip(list(sen_uniques), range(num_polarities)))\n",
    "sen_label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 4710, 2: 2334, 0: 2945})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(sen_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GloVe + LSTM  \n",
    "Note: To solve the problem of LSTM always predicting the same class even when trained with balanced data, the 'return_sequences' param in the LSTM layer needs to be set to True and add a Flatten layer. In addition, 'return_sequences=True' must be set when stacking LSTM layers so that the second LSTM layer has a three-dimensional sequence inpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 12000, 100)        1200000   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 12000, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 11996, 64)         32064     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 2999, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 2999, 128)         98816     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 2999, 128)         512       \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 2999, 32)          4128      \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 1,336,099\n",
      "Trainable params: 135,843\n",
      "Non-trainable params: 1,200,256\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "sen_glove = build_ConvLSTM(num_classes=num_polarities, vocabulary_size=vocabulary_size, dense_activation='softmax',\n",
    "                           optimizer=optimizers.adam(lr=0.001), use_glove=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: to use 'callback', one must provide 'validation_split' or 'validation_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_checkpts = ModelCheckpoint(filepath=os.path.join(os.getcwd(), 'glove.weights.best.hdf5'), \n",
    "                               verbose=1, save_best_only=True)\n",
    "# (Optional) load model\n",
    "# sen_glove.load_weights(os.path.join(os.getcwd(), 'glove.weights.best.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 6692 samples, validate on 3297 samples\n",
      "Epoch 1/10\n",
      "6692/6692 [==============================] - 1117s 167ms/step - loss: 1.6516 - acc: 0.4274 - val_loss: 1.5440 - val_acc: 0.3649\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.54401, saving model to /home/ubuntu/glove.weights.best.hdf5\n",
      "Epoch 2/10\n",
      "6692/6692 [==============================] - 1093s 163ms/step - loss: 1.4754 - acc: 0.4399 - val_loss: 2.0935 - val_acc: 0.4583\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.54401\n",
      "Epoch 3/10\n",
      "6692/6692 [==============================] - 1092s 163ms/step - loss: 1.4607 - acc: 0.4256 - val_loss: 1.8657 - val_acc: 0.4583\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.54401\n",
      "Epoch 4/10\n",
      "6692/6692 [==============================] - 1085s 162ms/step - loss: 1.4581 - acc: 0.4162 - val_loss: 1.5282 - val_acc: 0.2323\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.54401 to 1.52817, saving model to /home/ubuntu/glove.weights.best.hdf5\n",
      "Epoch 5/10\n",
      "5888/6692 [=========================>....] - ETA: 1:48 - loss: 1.4606 - acc: 0.4136"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-0b313079481c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m glove_history = sen_glove.fit(x_train, z_train, validation_split=0.33, epochs=10, \n\u001b[0;32m----> 2\u001b[0;31m                               class_weight={0: 1.5, 1: 1., 2: 1.8}, callbacks=[glove_checkpts], verbose=1)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "glove_history = sen_glove.fit(x_train, z_train, validation_split=0.33, epochs=10, \n",
    "                              class_weight={0: 1.5, 1: 1., 2: 1.8}, callbacks=[glove_checkpts], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 2610})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_pred_glove = sen_glove.predict_classes(x_test)\n",
    "Counter(z_pred_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 48.1226%\n"
     ]
    }
   ],
   "source": [
    "glove_accuracy = 100*np.sum(z_pred_glove==z_transf)/len(z_transf)\n",
    "print('Test accuracy: %.4f%%' % glove_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2610, 2610)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(z_pred_glove), len(z_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.472, Test: 0.481\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "_, train_acc = sen_glove.evaluate(x_train, z_train, verbose=0)\n",
    "_, test_acc = sen_glove.evaluate(x_test, z_true, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss during training\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.title('Loss')\n",
    "plt.plot(glove_history.history['loss'], label='train')\n",
    "plt.plot(glove_history.history['val_loss'], label='test')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot accuracy during training\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.title('Accuracy')\n",
    "plt.plot(glove_history.history['acc'], label='train')\n",
    "plt.plot(glove_history.history['val_acc'], label='test')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_7 (Conv1D)            (None, 20000, 16)         48        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 10000, 16)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 10000, 32)         1056      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 5000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 5000, 64)          4160      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 2500, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 160000)            0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               20480128  \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 20,485,779\n",
      "Trainable params: 20,485,779\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From C:\\Users\\syip\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 5993 samples, validate on 3996 samples\n",
      "Epoch 1/5\n",
      "5993/5993 [==============================] - ETA: 7:28 - loss: 1.1019 - acc: 0.250 - ETA: 4:54 - loss: 1.0970 - acc: 0.312 - ETA: 4:09 - loss: 1.1283 - acc: 0.354 - ETA: 3:45 - loss: 1.0907 - acc: 0.398 - ETA: 3:26 - loss: 1.0824 - acc: 0.412 - ETA: 3:18 - loss: 1.0901 - acc: 0.395 - ETA: 3:08 - loss: 1.0802 - acc: 0.401 - ETA: 3:04 - loss: 1.0796 - acc: 0.398 - ETA: 2:58 - loss: 1.0883 - acc: 0.392 - ETA: 2:55 - loss: 1.0848 - acc: 0.393 - ETA: 2:55 - loss: 1.0800 - acc: 0.403 - ETA: 2:49 - loss: 1.0815 - acc: 0.401 - ETA: 2:46 - loss: 1.0781 - acc: 0.408 - ETA: 2:42 - loss: 1.0798 - acc: 0.410 - ETA: 2:38 - loss: 1.0723 - acc: 0.420 - ETA: 2:38 - loss: 1.0778 - acc: 0.429 - ETA: 2:35 - loss: 1.0752 - acc: 0.433 - ETA: 2:33 - loss: 1.0671 - acc: 0.444 - ETA: 2:30 - loss: 1.0664 - acc: 0.450 - ETA: 2:28 - loss: 1.0644 - acc: 0.448 - ETA: 2:26 - loss: 1.0644 - acc: 0.450 - ETA: 2:25 - loss: 1.0625 - acc: 0.454 - ETA: 2:23 - loss: 1.0704 - acc: 0.449 - ETA: 2:22 - loss: 1.0735 - acc: 0.446 - ETA: 2:20 - loss: 1.0689 - acc: 0.447 - ETA: 2:20 - loss: 1.0647 - acc: 0.450 - ETA: 2:18 - loss: 1.0652 - acc: 0.454 - ETA: 2:17 - loss: 1.0625 - acc: 0.457 - ETA: 2:15 - loss: 1.0615 - acc: 0.458 - ETA: 2:14 - loss: 1.0606 - acc: 0.457 - ETA: 2:13 - loss: 1.0612 - acc: 0.457 - ETA: 2:12 - loss: 1.0618 - acc: 0.460 - ETA: 2:12 - loss: 1.0617 - acc: 0.457 - ETA: 2:12 - loss: 1.0629 - acc: 0.454 - ETA: 2:13 - loss: 1.0643 - acc: 0.453 - ETA: 2:13 - loss: 1.0675 - acc: 0.448 - ETA: 2:12 - loss: 1.0676 - acc: 0.449 - ETA: 2:12 - loss: 1.0679 - acc: 0.449 - ETA: 2:12 - loss: 1.0670 - acc: 0.448 - ETA: 2:11 - loss: 1.0671 - acc: 0.447 - ETA: 2:10 - loss: 1.0667 - acc: 0.447 - ETA: 2:09 - loss: 1.0648 - acc: 0.450 - ETA: 2:08 - loss: 1.0644 - acc: 0.452 - ETA: 2:07 - loss: 1.0651 - acc: 0.450 - ETA: 2:07 - loss: 1.0656 - acc: 0.450 - ETA: 2:05 - loss: 1.0656 - acc: 0.451 - ETA: 2:04 - loss: 1.0657 - acc: 0.449 - ETA: 2:03 - loss: 1.0649 - acc: 0.449 - ETA: 2:02 - loss: 1.0648 - acc: 0.449 - ETA: 2:00 - loss: 1.0637 - acc: 0.452 - ETA: 1:59 - loss: 1.0632 - acc: 0.453 - ETA: 1:58 - loss: 1.0623 - acc: 0.455 - ETA: 1:56 - loss: 1.0621 - acc: 0.455 - ETA: 1:55 - loss: 1.0591 - acc: 0.460 - ETA: 1:54 - loss: 1.0587 - acc: 0.461 - ETA: 1:52 - loss: 1.0567 - acc: 0.464 - ETA: 1:51 - loss: 1.0567 - acc: 0.464 - ETA: 1:50 - loss: 1.0551 - acc: 0.466 - ETA: 1:49 - loss: 1.0572 - acc: 0.465 - ETA: 1:48 - loss: 1.0583 - acc: 0.464 - ETA: 1:47 - loss: 1.0599 - acc: 0.463 - ETA: 1:45 - loss: 1.0585 - acc: 0.463 - ETA: 1:44 - loss: 1.0597 - acc: 0.461 - ETA: 1:43 - loss: 1.0608 - acc: 0.460 - ETA: 1:42 - loss: 1.0604 - acc: 0.462 - ETA: 1:41 - loss: 1.0600 - acc: 0.462 - ETA: 1:40 - loss: 1.0589 - acc: 0.462 - ETA: 1:39 - loss: 1.0584 - acc: 0.461 - ETA: 1:38 - loss: 1.0570 - acc: 0.462 - ETA: 1:37 - loss: 1.0580 - acc: 0.462 - ETA: 1:36 - loss: 1.0575 - acc: 0.464 - ETA: 1:35 - loss: 1.0572 - acc: 0.463 - ETA: 1:34 - loss: 1.0573 - acc: 0.464 - ETA: 1:33 - loss: 1.0570 - acc: 0.464 - ETA: 1:32 - loss: 1.0566 - acc: 0.466 - ETA: 1:31 - loss: 1.0548 - acc: 0.467 - ETA: 1:30 - loss: 1.0579 - acc: 0.467 - ETA: 1:29 - loss: 1.0578 - acc: 0.467 - ETA: 1:28 - loss: 1.0565 - acc: 0.467 - ETA: 1:27 - loss: 1.0557 - acc: 0.468 - ETA: 1:26 - loss: 1.0567 - acc: 0.466 - ETA: 1:25 - loss: 1.0567 - acc: 0.465 - ETA: 1:24 - loss: 1.0560 - acc: 0.467 - ETA: 1:23 - loss: 1.0560 - acc: 0.466 - ETA: 1:22 - loss: 1.0556 - acc: 0.465 - ETA: 1:21 - loss: 1.0553 - acc: 0.466 - ETA: 1:20 - loss: 1.0548 - acc: 0.468 - ETA: 1:20 - loss: 1.0554 - acc: 0.468 - ETA: 1:19 - loss: 1.0547 - acc: 0.469 - ETA: 1:18 - loss: 1.0548 - acc: 0.468 - ETA: 1:17 - loss: 1.0539 - acc: 0.469 - ETA: 1:16 - loss: 1.0530 - acc: 0.470 - ETA: 1:15 - loss: 1.0541 - acc: 0.468 - ETA: 1:14 - loss: 1.0539 - acc: 0.468 - ETA: 1:13 - loss: 1.0530 - acc: 0.469 - ETA: 1:12 - loss: 1.0535 - acc: 0.469 - ETA: 1:12 - loss: 1.0526 - acc: 0.470 - ETA: 1:11 - loss: 1.0516 - acc: 0.470 - ETA: 1:10 - loss: 1.0523 - acc: 0.468 - ETA: 1:09 - loss: 1.0523 - acc: 0.468 - ETA: 1:08 - loss: 1.0531 - acc: 0.468 - ETA: 1:07 - loss: 1.0519 - acc: 0.469 - ETA: 1:06 - loss: 1.0519 - acc: 0.468 - ETA: 1:06 - loss: 1.0512 - acc: 0.469 - ETA: 1:05 - loss: 1.0508 - acc: 0.469 - ETA: 1:04 - loss: 1.0499 - acc: 0.469 - ETA: 1:03 - loss: 1.0496 - acc: 0.468 - ETA: 1:02 - loss: 1.0488 - acc: 0.469 - ETA: 1:01 - loss: 1.0488 - acc: 0.469 - ETA: 1:01 - loss: 1.0477 - acc: 0.470 - ETA: 1:00 - loss: 1.0475 - acc: 0.469 - ETA: 59s - loss: 1.0480 - acc: 0.469 - ETA: 58s - loss: 1.0474 - acc: 0.46 - ETA: 57s - loss: 1.0466 - acc: 0.47 - ETA: 56s - loss: 1.0447 - acc: 0.47 - ETA: 56s - loss: 1.0446 - acc: 0.47 - ETA: 55s - loss: 1.0429 - acc: 0.47 - ETA: 54s - loss: 1.0430 - acc: 0.47 - ETA: 53s - loss: 1.0430 - acc: 0.47 - ETA: 52s - loss: 1.0423 - acc: 0.47 - ETA: 52s - loss: 1.0420 - acc: 0.47 - ETA: 51s - loss: 1.0414 - acc: 0.47 - ETA: 50s - loss: 1.0416 - acc: 0.47 - ETA: 49s - loss: 1.0416 - acc: 0.47 - ETA: 48s - loss: 1.0417 - acc: 0.47 - ETA: 47s - loss: 1.0419 - acc: 0.47 - ETA: 47s - loss: 1.0417 - acc: 0.47 - ETA: 46s - loss: 1.0427 - acc: 0.47 - ETA: 45s - loss: 1.0432 - acc: 0.47 - ETA: 44s - loss: 1.0426 - acc: 0.47 - ETA: 43s - loss: 1.0424 - acc: 0.47 - ETA: 43s - loss: 1.0423 - acc: 0.47 - ETA: 42s - loss: 1.0419 - acc: 0.47 - ETA: 41s - loss: 1.0414 - acc: 0.47 - ETA: 40s - loss: 1.0417 - acc: 0.47 - ETA: 39s - loss: 1.0416 - acc: 0.47 - ETA: 39s - loss: 1.0406 - acc: 0.47 - ETA: 38s - loss: 1.0408 - acc: 0.47 - ETA: 37s - loss: 1.0407 - acc: 0.47 - ETA: 36s - loss: 1.0399 - acc: 0.47 - ETA: 35s - loss: 1.0389 - acc: 0.47 - ETA: 35s - loss: 1.0386 - acc: 0.47 - ETA: 34s - loss: 1.0382 - acc: 0.47 - ETA: 33s - loss: 1.0383 - acc: 0.47 - ETA: 32s - loss: 1.0379 - acc: 0.47 - ETA: 31s - loss: 1.0368 - acc: 0.48 - ETA: 31s - loss: 1.0372 - acc: 0.48 - ETA: 30s - loss: 1.0364 - acc: 0.48 - ETA: 29s - loss: 1.0356 - acc: 0.48 - ETA: 28s - loss: 1.0355 - acc: 0.48 - ETA: 27s - loss: 1.0352 - acc: 0.48 - ETA: 27s - loss: 1.0357 - acc: 0.48 - ETA: 26s - loss: 1.0358 - acc: 0.48 - ETA: 25s - loss: 1.0350 - acc: 0.48 - ETA: 24s - loss: 1.0351 - acc: 0.48 - ETA: 24s - loss: 1.0354 - acc: 0.48 - ETA: 23s - loss: 1.0349 - acc: 0.48 - ETA: 22s - loss: 1.0347 - acc: 0.48 - ETA: 21s - loss: 1.0346 - acc: 0.48 - ETA: 20s - loss: 1.0350 - acc: 0.48 - ETA: 20s - loss: 1.0357 - acc: 0.48 - ETA: 19s - loss: 1.0353 - acc: 0.48 - ETA: 18s - loss: 1.0342 - acc: 0.48 - ETA: 17s - loss: 1.0350 - acc: 0.48 - ETA: 17s - loss: 1.0348 - acc: 0.48 - ETA: 16s - loss: 1.0343 - acc: 0.48 - ETA: 15s - loss: 1.0338 - acc: 0.48 - ETA: 14s - loss: 1.0338 - acc: 0.48 - ETA: 14s - loss: 1.0339 - acc: 0.48 - ETA: 13s - loss: 1.0335 - acc: 0.48 - ETA: 12s - loss: 1.0333 - acc: 0.48 - ETA: 11s - loss: 1.0332 - acc: 0.48 - ETA: 10s - loss: 1.0324 - acc: 0.48 - ETA: 10s - loss: 1.0329 - acc: 0.48 - ETA: 9s - loss: 1.0323 - acc: 0.4855 - ETA: 8s - loss: 1.0320 - acc: 0.485 - ETA: 7s - loss: 1.0317 - acc: 0.485 - ETA: 7s - loss: 1.0321 - acc: 0.485 - ETA: 6s - loss: 1.0320 - acc: 0.485 - ETA: 5s - loss: 1.0317 - acc: 0.485 - ETA: 4s - loss: 1.0317 - acc: 0.486 - ETA: 4s - loss: 1.0322 - acc: 0.485 - ETA: 3s - loss: 1.0318 - acc: 0.485 - ETA: 2s - loss: 1.0320 - acc: 0.485 - ETA: 1s - loss: 1.0319 - acc: 0.484 - ETA: 0s - loss: 1.0322 - acc: 0.484 - ETA: 0s - loss: 1.0319 - acc: 0.484 - 160s 27ms/step - loss: 1.0321 - acc: 0.4842 - val_loss: 1.0078 - val_acc: 0.5080\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.00784, saving model to C:\\Users\\syip\\Desktop\\DaSci\\Nanodegree\\ml_nanodegree\\capstone/saved_models/sentiment/cnn.weights.best.hdf5\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5993/5993 [==============================] - ETA: 2:07 - loss: 0.9519 - acc: 0.468 - ETA: 2:10 - loss: 0.9183 - acc: 0.562 - ETA: 2:11 - loss: 0.8883 - acc: 0.625 - ETA: 2:10 - loss: 0.8919 - acc: 0.617 - ETA: 2:10 - loss: 0.8930 - acc: 0.618 - ETA: 2:11 - loss: 0.8927 - acc: 0.614 - ETA: 2:11 - loss: 0.8899 - acc: 0.620 - ETA: 2:12 - loss: 0.8865 - acc: 0.628 - ETA: 2:11 - loss: 0.8904 - acc: 0.618 - ETA: 2:10 - loss: 0.8894 - acc: 0.615 - ETA: 2:10 - loss: 0.8791 - acc: 0.622 - ETA: 2:08 - loss: 0.8781 - acc: 0.606 - ETA: 2:07 - loss: 0.8722 - acc: 0.605 - ETA: 2:06 - loss: 0.8611 - acc: 0.611 - ETA: 2:05 - loss: 0.8659 - acc: 0.604 - ETA: 2:04 - loss: 0.8626 - acc: 0.601 - ETA: 2:03 - loss: 0.8552 - acc: 0.606 - ETA: 2:03 - loss: 0.8450 - acc: 0.618 - ETA: 2:02 - loss: 0.8456 - acc: 0.616 - ETA: 2:01 - loss: 0.8428 - acc: 0.615 - ETA: 2:00 - loss: 0.8419 - acc: 0.617 - ETA: 2:00 - loss: 0.8465 - acc: 0.613 - ETA: 2:00 - loss: 0.8477 - acc: 0.615 - ETA: 1:59 - loss: 0.8439 - acc: 0.617 - ETA: 1:59 - loss: 0.8419 - acc: 0.618 - ETA: 1:58 - loss: 0.8381 - acc: 0.622 - ETA: 1:58 - loss: 0.8328 - acc: 0.625 - ETA: 1:58 - loss: 0.8315 - acc: 0.625 - ETA: 1:57 - loss: 0.8296 - acc: 0.622 - ETA: 1:57 - loss: 0.8286 - acc: 0.622 - ETA: 1:56 - loss: 0.8275 - acc: 0.624 - ETA: 1:55 - loss: 0.8210 - acc: 0.628 - ETA: 1:54 - loss: 0.8229 - acc: 0.630 - ETA: 1:54 - loss: 0.8247 - acc: 0.632 - ETA: 1:53 - loss: 0.8221 - acc: 0.633 - ETA: 1:53 - loss: 0.8195 - acc: 0.634 - ETA: 1:52 - loss: 0.8250 - acc: 0.630 - ETA: 1:52 - loss: 0.8246 - acc: 0.631 - ETA: 1:51 - loss: 0.8296 - acc: 0.627 - ETA: 1:51 - loss: 0.8328 - acc: 0.624 - ETA: 1:50 - loss: 0.8326 - acc: 0.625 - ETA: 1:50 - loss: 0.8299 - acc: 0.630 - ETA: 1:49 - loss: 0.8318 - acc: 0.630 - ETA: 1:48 - loss: 0.8349 - acc: 0.625 - ETA: 1:47 - loss: 0.8381 - acc: 0.622 - ETA: 1:46 - loss: 0.8428 - acc: 0.618 - ETA: 1:46 - loss: 0.8458 - acc: 0.615 - ETA: 1:45 - loss: 0.8455 - acc: 0.617 - ETA: 1:44 - loss: 0.8460 - acc: 0.618 - ETA: 1:43 - loss: 0.8467 - acc: 0.615 - ETA: 1:43 - loss: 0.8472 - acc: 0.615 - ETA: 1:42 - loss: 0.8453 - acc: 0.617 - ETA: 1:41 - loss: 0.8445 - acc: 0.617 - ETA: 1:40 - loss: 0.8431 - acc: 0.618 - ETA: 1:40 - loss: 0.8414 - acc: 0.619 - ETA: 1:39 - loss: 0.8416 - acc: 0.618 - ETA: 1:38 - loss: 0.8415 - acc: 0.618 - ETA: 1:37 - loss: 0.8400 - acc: 0.620 - ETA: 1:37 - loss: 0.8413 - acc: 0.618 - ETA: 1:36 - loss: 0.8435 - acc: 0.618 - ETA: 1:35 - loss: 0.8412 - acc: 0.619 - ETA: 1:34 - loss: 0.8400 - acc: 0.620 - ETA: 1:33 - loss: 0.8378 - acc: 0.622 - ETA: 1:33 - loss: 0.8373 - acc: 0.621 - ETA: 1:32 - loss: 0.8344 - acc: 0.622 - ETA: 1:31 - loss: 0.8335 - acc: 0.623 - ETA: 1:30 - loss: 0.8327 - acc: 0.625 - ETA: 1:30 - loss: 0.8349 - acc: 0.624 - ETA: 1:29 - loss: 0.8360 - acc: 0.624 - ETA: 1:28 - loss: 0.8356 - acc: 0.624 - ETA: 1:27 - loss: 0.8354 - acc: 0.624 - ETA: 1:27 - loss: 0.8359 - acc: 0.624 - ETA: 1:26 - loss: 0.8340 - acc: 0.624 - ETA: 1:25 - loss: 0.8341 - acc: 0.623 - ETA: 1:24 - loss: 0.8328 - acc: 0.623 - ETA: 1:23 - loss: 0.8326 - acc: 0.623 - ETA: 1:23 - loss: 0.8304 - acc: 0.625 - ETA: 1:22 - loss: 0.8282 - acc: 0.626 - ETA: 1:21 - loss: 0.8260 - acc: 0.628 - ETA: 1:20 - loss: 0.8256 - acc: 0.628 - ETA: 1:19 - loss: 0.8275 - acc: 0.627 - ETA: 1:19 - loss: 0.8275 - acc: 0.628 - ETA: 1:18 - loss: 0.8305 - acc: 0.627 - ETA: 1:17 - loss: 0.8312 - acc: 0.627 - ETA: 1:17 - loss: 0.8335 - acc: 0.625 - ETA: 1:16 - loss: 0.8346 - acc: 0.623 - ETA: 1:15 - loss: 0.8340 - acc: 0.623 - ETA: 1:14 - loss: 0.8356 - acc: 0.621 - ETA: 1:14 - loss: 0.8378 - acc: 0.618 - ETA: 1:13 - loss: 0.8360 - acc: 0.620 - ETA: 1:12 - loss: 0.8359 - acc: 0.619 - ETA: 1:12 - loss: 0.8352 - acc: 0.619 - ETA: 1:11 - loss: 0.8344 - acc: 0.619 - ETA: 1:10 - loss: 0.8333 - acc: 0.619 - ETA: 1:09 - loss: 0.8323 - acc: 0.620 - ETA: 1:09 - loss: 0.8316 - acc: 0.620 - ETA: 1:08 - loss: 0.8308 - acc: 0.620 - ETA: 1:07 - loss: 0.8309 - acc: 0.620 - ETA: 1:06 - loss: 0.8317 - acc: 0.619 - ETA: 1:05 - loss: 0.8330 - acc: 0.618 - ETA: 1:05 - loss: 0.8341 - acc: 0.619 - ETA: 1:04 - loss: 0.8341 - acc: 0.619 - ETA: 1:03 - loss: 0.8356 - acc: 0.616 - ETA: 1:02 - loss: 0.8341 - acc: 0.618 - ETA: 1:02 - loss: 0.8336 - acc: 0.618 - ETA: 1:01 - loss: 0.8343 - acc: 0.618 - ETA: 1:00 - loss: 0.8354 - acc: 0.618 - ETA: 59s - loss: 0.8346 - acc: 0.619 - ETA: 59s - loss: 0.8354 - acc: 0.61 - ETA: 58s - loss: 0.8351 - acc: 0.61 - ETA: 57s - loss: 0.8340 - acc: 0.61 - ETA: 56s - loss: 0.8368 - acc: 0.61 - ETA: 56s - loss: 0.8382 - acc: 0.61 - ETA: 55s - loss: 0.8381 - acc: 0.61 - ETA: 54s - loss: 0.8374 - acc: 0.61 - ETA: 54s - loss: 0.8383 - acc: 0.61 - ETA: 53s - loss: 0.8387 - acc: 0.61 - ETA: 52s - loss: 0.8391 - acc: 0.61 - ETA: 52s - loss: 0.8400 - acc: 0.61 - ETA: 51s - loss: 0.8404 - acc: 0.61 - ETA: 50s - loss: 0.8401 - acc: 0.61 - ETA: 49s - loss: 0.8411 - acc: 0.61 - ETA: 49s - loss: 0.8406 - acc: 0.61 - ETA: 48s - loss: 0.8412 - acc: 0.61 - ETA: 47s - loss: 0.8409 - acc: 0.61 - ETA: 46s - loss: 0.8403 - acc: 0.61 - ETA: 46s - loss: 0.8394 - acc: 0.61 - ETA: 45s - loss: 0.8400 - acc: 0.61 - ETA: 44s - loss: 0.8391 - acc: 0.61 - ETA: 43s - loss: 0.8396 - acc: 0.61 - ETA: 42s - loss: 0.8401 - acc: 0.61 - ETA: 42s - loss: 0.8401 - acc: 0.61 - ETA: 41s - loss: 0.8405 - acc: 0.61 - ETA: 40s - loss: 0.8410 - acc: 0.61 - ETA: 39s - loss: 0.8402 - acc: 0.61 - ETA: 39s - loss: 0.8394 - acc: 0.61 - ETA: 38s - loss: 0.8385 - acc: 0.61 - ETA: 37s - loss: 0.8386 - acc: 0.61 - ETA: 36s - loss: 0.8381 - acc: 0.61 - ETA: 36s - loss: 0.8379 - acc: 0.61 - ETA: 35s - loss: 0.8373 - acc: 0.61 - ETA: 34s - loss: 0.8371 - acc: 0.61 - ETA: 33s - loss: 0.8380 - acc: 0.61 - ETA: 33s - loss: 0.8401 - acc: 0.61 - ETA: 32s - loss: 0.8404 - acc: 0.61 - ETA: 31s - loss: 0.8403 - acc: 0.61 - ETA: 30s - loss: 0.8400 - acc: 0.61 - ETA: 29s - loss: 0.8392 - acc: 0.61 - ETA: 29s - loss: 0.8403 - acc: 0.61 - ETA: 28s - loss: 0.8412 - acc: 0.61 - ETA: 27s - loss: 0.8415 - acc: 0.61 - ETA: 26s - loss: 0.8414 - acc: 0.61 - ETA: 26s - loss: 0.8425 - acc: 0.61 - ETA: 25s - loss: 0.8443 - acc: 0.60 - ETA: 24s - loss: 0.8437 - acc: 0.61 - ETA: 23s - loss: 0.8451 - acc: 0.60 - ETA: 23s - loss: 0.8462 - acc: 0.60 - ETA: 22s - loss: 0.8464 - acc: 0.60 - ETA: 21s - loss: 0.8457 - acc: 0.60 - ETA: 20s - loss: 0.8462 - acc: 0.60 - ETA: 20s - loss: 0.8460 - acc: 0.60 - ETA: 19s - loss: 0.8461 - acc: 0.60 - ETA: 18s - loss: 0.8459 - acc: 0.60 - ETA: 17s - loss: 0.8465 - acc: 0.60 - ETA: 17s - loss: 0.8472 - acc: 0.60 - ETA: 16s - loss: 0.8474 - acc: 0.60 - ETA: 15s - loss: 0.8476 - acc: 0.60 - ETA: 15s - loss: 0.8474 - acc: 0.60 - ETA: 14s - loss: 0.8476 - acc: 0.60 - ETA: 13s - loss: 0.8469 - acc: 0.60 - ETA: 12s - loss: 0.8471 - acc: 0.60 - ETA: 12s - loss: 0.8464 - acc: 0.60 - ETA: 11s - loss: 0.8461 - acc: 0.60 - ETA: 10s - loss: 0.8460 - acc: 0.60 - ETA: 9s - loss: 0.8459 - acc: 0.6066 - ETA: 8s - loss: 0.8468 - acc: 0.606 - ETA: 8s - loss: 0.8461 - acc: 0.606 - ETA: 7s - loss: 0.8468 - acc: 0.606 - ETA: 6s - loss: 0.8467 - acc: 0.605 - ETA: 5s - loss: 0.8477 - acc: 0.605 - ETA: 5s - loss: 0.8481 - acc: 0.604 - ETA: 4s - loss: 0.8474 - acc: 0.605 - ETA: 3s - loss: 0.8472 - acc: 0.605 - ETA: 2s - loss: 0.8470 - acc: 0.605 - ETA: 1s - loss: 0.8473 - acc: 0.605 - ETA: 1s - loss: 0.8472 - acc: 0.605 - ETA: 0s - loss: 0.8482 - acc: 0.605 - 175s 29ms/step - loss: 0.8485 - acc: 0.6050 - val_loss: 1.0572 - val_acc: 0.5055\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.00784\n",
      "Epoch 3/5\n",
      "5993/5993 [==============================] - ETA: 2:19 - loss: 0.6897 - acc: 0.687 - ETA: 2:25 - loss: 0.5620 - acc: 0.750 - ETA: 2:22 - loss: 0.5606 - acc: 0.781 - ETA: 2:22 - loss: 0.6220 - acc: 0.750 - ETA: 2:20 - loss: 0.6003 - acc: 0.756 - ETA: 2:26 - loss: 0.6157 - acc: 0.750 - ETA: 2:25 - loss: 0.6062 - acc: 0.763 - ETA: 2:29 - loss: 0.6031 - acc: 0.761 - ETA: 2:34 - loss: 0.6081 - acc: 0.760 - ETA: 2:34 - loss: 0.5971 - acc: 0.765 - ETA: 2:36 - loss: 0.6036 - acc: 0.761 - ETA: 2:38 - loss: 0.6059 - acc: 0.755 - ETA: 2:39 - loss: 0.6106 - acc: 0.750 - ETA: 2:39 - loss: 0.6035 - acc: 0.758 - ETA: 2:38 - loss: 0.5989 - acc: 0.760 - ETA: 2:39 - loss: 0.5878 - acc: 0.767 - ETA: 2:40 - loss: 0.5839 - acc: 0.766 - ETA: 2:40 - loss: 0.5808 - acc: 0.772 - ETA: 2:40 - loss: 0.5881 - acc: 0.769 - ETA: 2:40 - loss: 0.5845 - acc: 0.773 - ETA: 2:40 - loss: 0.5862 - acc: 0.769 - ETA: 2:39 - loss: 0.5801 - acc: 0.771 - ETA: 2:39 - loss: 0.5825 - acc: 0.767 - ETA: 2:40 - loss: 0.5852 - acc: 0.764 - ETA: 2:39 - loss: 0.5974 - acc: 0.758 - ETA: 2:38 - loss: 0.6021 - acc: 0.757 - ETA: 2:37 - loss: 0.5949 - acc: 0.761 - ETA: 2:35 - loss: 0.5947 - acc: 0.761 - ETA: 2:35 - loss: 0.5942 - acc: 0.758 - ETA: 2:34 - loss: 0.5861 - acc: 0.763 - ETA: 2:33 - loss: 0.5811 - acc: 0.766 - ETA: 2:32 - loss: 0.5755 - acc: 0.769 - ETA: 2:31 - loss: 0.5714 - acc: 0.769 - ETA: 2:29 - loss: 0.5680 - acc: 0.771 - ETA: 2:28 - loss: 0.5686 - acc: 0.768 - ETA: 2:27 - loss: 0.5684 - acc: 0.769 - ETA: 2:26 - loss: 0.5705 - acc: 0.767 - ETA: 2:25 - loss: 0.5700 - acc: 0.768 - ETA: 2:23 - loss: 0.5637 - acc: 0.770 - ETA: 2:22 - loss: 0.5605 - acc: 0.769 - ETA: 2:21 - loss: 0.5625 - acc: 0.766 - ETA: 2:20 - loss: 0.5606 - acc: 0.768 - ETA: 2:19 - loss: 0.5606 - acc: 0.768 - ETA: 2:18 - loss: 0.5612 - acc: 0.769 - ETA: 2:16 - loss: 0.5613 - acc: 0.769 - ETA: 2:15 - loss: 0.5649 - acc: 0.769 - ETA: 2:14 - loss: 0.5633 - acc: 0.769 - ETA: 2:12 - loss: 0.5635 - acc: 0.769 - ETA: 2:11 - loss: 0.5680 - acc: 0.765 - ETA: 2:10 - loss: 0.5690 - acc: 0.767 - ETA: 2:08 - loss: 0.5676 - acc: 0.768 - ETA: 2:07 - loss: 0.5689 - acc: 0.766 - ETA: 2:06 - loss: 0.5701 - acc: 0.765 - ETA: 2:05 - loss: 0.5678 - acc: 0.765 - ETA: 2:04 - loss: 0.5648 - acc: 0.765 - ETA: 2:03 - loss: 0.5627 - acc: 0.765 - ETA: 2:02 - loss: 0.5676 - acc: 0.761 - ETA: 2:01 - loss: 0.5678 - acc: 0.760 - ETA: 2:00 - loss: 0.5664 - acc: 0.761 - ETA: 1:59 - loss: 0.5657 - acc: 0.762 - ETA: 1:57 - loss: 0.5649 - acc: 0.762 - ETA: 1:56 - loss: 0.5657 - acc: 0.761 - ETA: 1:55 - loss: 0.5643 - acc: 0.762 - ETA: 1:54 - loss: 0.5629 - acc: 0.762 - ETA: 1:53 - loss: 0.5615 - acc: 0.763 - ETA: 1:52 - loss: 0.5595 - acc: 0.763 - ETA: 1:51 - loss: 0.5598 - acc: 0.763 - ETA: 1:50 - loss: 0.5593 - acc: 0.763 - ETA: 1:49 - loss: 0.5576 - acc: 0.764 - ETA: 1:47 - loss: 0.5593 - acc: 0.763 - ETA: 1:46 - loss: 0.5602 - acc: 0.763 - ETA: 1:45 - loss: 0.5603 - acc: 0.763 - ETA: 1:44 - loss: 0.5594 - acc: 0.763 - ETA: 1:43 - loss: 0.5572 - acc: 0.765 - ETA: 1:42 - loss: 0.5578 - acc: 0.764 - ETA: 1:41 - loss: 0.5545 - acc: 0.766 - ETA: 1:39 - loss: 0.5585 - acc: 0.765 - ETA: 1:38 - loss: 0.5579 - acc: 0.765 - ETA: 1:37 - loss: 0.5595 - acc: 0.763 - ETA: 1:36 - loss: 0.5571 - acc: 0.764 - ETA: 1:35 - loss: 0.5582 - acc: 0.762 - ETA: 1:34 - loss: 0.5591 - acc: 0.762 - ETA: 1:33 - loss: 0.5580 - acc: 0.762 - ETA: 1:32 - loss: 0.5568 - acc: 0.763 - ETA: 1:31 - loss: 0.5563 - acc: 0.762 - ETA: 1:30 - loss: 0.5586 - acc: 0.763 - ETA: 1:29 - loss: 0.5585 - acc: 0.763 - ETA: 1:28 - loss: 0.5583 - acc: 0.763 - ETA: 1:27 - loss: 0.5578 - acc: 0.763 - ETA: 1:26 - loss: 0.5581 - acc: 0.764 - ETA: 1:25 - loss: 0.5567 - acc: 0.765 - ETA: 1:24 - loss: 0.5569 - acc: 0.767 - ETA: 1:23 - loss: 0.5584 - acc: 0.765 - ETA: 1:22 - loss: 0.5594 - acc: 0.765 - ETA: 1:21 - loss: 0.5593 - acc: 0.765 - ETA: 1:20 - loss: 0.5585 - acc: 0.765 - ETA: 1:19 - loss: 0.5588 - acc: 0.765 - ETA: 1:18 - loss: 0.5594 - acc: 0.764 - ETA: 1:17 - loss: 0.5587 - acc: 0.764 - ETA: 1:16 - loss: 0.5601 - acc: 0.763 - ETA: 1:15 - loss: 0.5618 - acc: 0.761 - ETA: 1:14 - loss: 0.5631 - acc: 0.761 - ETA: 1:13 - loss: 0.5610 - acc: 0.761 - ETA: 1:12 - loss: 0.5649 - acc: 0.760 - ETA: 1:11 - loss: 0.5650 - acc: 0.760 - ETA: 1:10 - loss: 0.5637 - acc: 0.760 - ETA: 1:09 - loss: 0.5646 - acc: 0.760 - ETA: 1:08 - loss: 0.5636 - acc: 0.760 - ETA: 1:07 - loss: 0.5643 - acc: 0.759 - ETA: 1:06 - loss: 0.5648 - acc: 0.759 - ETA: 1:05 - loss: 0.5662 - acc: 0.758 - ETA: 1:04 - loss: 0.5658 - acc: 0.757 - ETA: 1:03 - loss: 0.5669 - acc: 0.758 - ETA: 1:02 - loss: 0.5674 - acc: 0.757 - ETA: 1:02 - loss: 0.5687 - acc: 0.757 - ETA: 1:01 - loss: 0.5678 - acc: 0.758 - ETA: 1:00 - loss: 0.5678 - acc: 0.758 - ETA: 59s - loss: 0.5678 - acc: 0.759 - ETA: 58s - loss: 0.5685 - acc: 0.75 - ETA: 57s - loss: 0.5690 - acc: 0.75 - ETA: 56s - loss: 0.5687 - acc: 0.75 - ETA: 55s - loss: 0.5679 - acc: 0.75 - ETA: 54s - loss: 0.5683 - acc: 0.75 - ETA: 54s - loss: 0.5703 - acc: 0.75 - ETA: 53s - loss: 0.5704 - acc: 0.75 - ETA: 52s - loss: 0.5700 - acc: 0.75 - ETA: 51s - loss: 0.5688 - acc: 0.75 - ETA: 50s - loss: 0.5696 - acc: 0.75 - ETA: 49s - loss: 0.5696 - acc: 0.75 - ETA: 48s - loss: 0.5702 - acc: 0.75 - ETA: 47s - loss: 0.5706 - acc: 0.75 - ETA: 47s - loss: 0.5707 - acc: 0.75 - ETA: 46s - loss: 0.5702 - acc: 0.75 - ETA: 45s - loss: 0.5708 - acc: 0.75 - ETA: 44s - loss: 0.5706 - acc: 0.75 - ETA: 43s - loss: 0.5702 - acc: 0.75 - ETA: 42s - loss: 0.5710 - acc: 0.75 - ETA: 42s - loss: 0.5723 - acc: 0.75 - ETA: 41s - loss: 0.5713 - acc: 0.75 - ETA: 40s - loss: 0.5729 - acc: 0.75 - ETA: 39s - loss: 0.5745 - acc: 0.75 - ETA: 38s - loss: 0.5734 - acc: 0.75 - ETA: 37s - loss: 0.5745 - acc: 0.75 - ETA: 36s - loss: 0.5739 - acc: 0.75 - ETA: 35s - loss: 0.5732 - acc: 0.75 - ETA: 35s - loss: 0.5741 - acc: 0.75 - ETA: 34s - loss: 0.5752 - acc: 0.75 - ETA: 33s - loss: 0.5751 - acc: 0.75 - ETA: 32s - loss: 0.5750 - acc: 0.75 - ETA: 31s - loss: 0.5757 - acc: 0.75 - ETA: 30s - loss: 0.5758 - acc: 0.75 - ETA: 29s - loss: 0.5753 - acc: 0.75 - ETA: 28s - loss: 0.5751 - acc: 0.75 - ETA: 28s - loss: 0.5756 - acc: 0.75 - ETA: 27s - loss: 0.5763 - acc: 0.75 - ETA: 26s - loss: 0.5772 - acc: 0.75 - ETA: 25s - loss: 0.5777 - acc: 0.75 - ETA: 24s - loss: 0.5788 - acc: 0.75 - ETA: 23s - loss: 0.5797 - acc: 0.75 - ETA: 22s - loss: 0.5793 - acc: 0.75 - ETA: 22s - loss: 0.5801 - acc: 0.75 - ETA: 21s - loss: 0.5800 - acc: 0.75 - ETA: 20s - loss: 0.5802 - acc: 0.75 - ETA: 19s - loss: 0.5805 - acc: 0.75 - ETA: 18s - loss: 0.5795 - acc: 0.75 - ETA: 17s - loss: 0.5795 - acc: 0.75 - ETA: 16s - loss: 0.5794 - acc: 0.75 - ETA: 16s - loss: 0.5794 - acc: 0.75 - ETA: 15s - loss: 0.5793 - acc: 0.75 - ETA: 14s - loss: 0.5798 - acc: 0.75 - ETA: 13s - loss: 0.5813 - acc: 0.75 - ETA: 12s - loss: 0.5814 - acc: 0.75 - ETA: 11s - loss: 0.5818 - acc: 0.75 - ETA: 11s - loss: 0.5825 - acc: 0.75 - ETA: 10s - loss: 0.5825 - acc: 0.75 - ETA: 9s - loss: 0.5822 - acc: 0.7511 - ETA: 8s - loss: 0.5814 - acc: 0.751 - ETA: 7s - loss: 0.5810 - acc: 0.752 - ETA: 6s - loss: 0.5815 - acc: 0.752 - ETA: 6s - loss: 0.5826 - acc: 0.751 - ETA: 5s - loss: 0.5828 - acc: 0.751 - ETA: 4s - loss: 0.5828 - acc: 0.752 - ETA: 3s - loss: 0.5833 - acc: 0.751 - ETA: 2s - loss: 0.5834 - acc: 0.752 - ETA: 1s - loss: 0.5832 - acc: 0.752 - ETA: 1s - loss: 0.5829 - acc: 0.752 - ETA: 0s - loss: 0.5827 - acc: 0.752 - 174s 29ms/step - loss: 0.5825 - acc: 0.7527 - val_loss: 1.2357 - val_acc: 0.4910\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.00784\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5993/5993 [==============================] - ETA: 2:27 - loss: 0.3017 - acc: 0.906 - ETA: 2:21 - loss: 0.3332 - acc: 0.906 - ETA: 2:17 - loss: 0.3287 - acc: 0.916 - ETA: 2:19 - loss: 0.3678 - acc: 0.882 - ETA: 2:25 - loss: 0.3684 - acc: 0.893 - ETA: 2:24 - loss: 0.3992 - acc: 0.864 - ETA: 2:25 - loss: 0.3887 - acc: 0.875 - ETA: 2:23 - loss: 0.3885 - acc: 0.875 - ETA: 2:21 - loss: 0.3889 - acc: 0.871 - ETA: 2:21 - loss: 0.3822 - acc: 0.871 - ETA: 2:19 - loss: 0.3742 - acc: 0.872 - ETA: 2:18 - loss: 0.3694 - acc: 0.880 - ETA: 2:17 - loss: 0.3708 - acc: 0.875 - ETA: 2:16 - loss: 0.3683 - acc: 0.877 - ETA: 2:15 - loss: 0.3736 - acc: 0.877 - ETA: 2:14 - loss: 0.3851 - acc: 0.869 - ETA: 2:13 - loss: 0.3842 - acc: 0.869 - ETA: 2:13 - loss: 0.3846 - acc: 0.868 - ETA: 2:13 - loss: 0.3781 - acc: 0.870 - ETA: 2:14 - loss: 0.3821 - acc: 0.870 - ETA: 2:14 - loss: 0.3895 - acc: 0.866 - ETA: 2:13 - loss: 0.3831 - acc: 0.866 - ETA: 2:14 - loss: 0.3714 - acc: 0.872 - ETA: 2:13 - loss: 0.3789 - acc: 0.869 - ETA: 2:12 - loss: 0.3750 - acc: 0.871 - ETA: 2:11 - loss: 0.3715 - acc: 0.871 - ETA: 2:10 - loss: 0.3677 - acc: 0.872 - ETA: 2:09 - loss: 0.3755 - acc: 0.868 - ETA: 2:08 - loss: 0.3791 - acc: 0.865 - ETA: 2:07 - loss: 0.3713 - acc: 0.869 - ETA: 2:06 - loss: 0.3734 - acc: 0.865 - ETA: 2:07 - loss: 0.3738 - acc: 0.866 - ETA: 2:06 - loss: 0.3719 - acc: 0.865 - ETA: 2:08 - loss: 0.3707 - acc: 0.867 - ETA: 2:10 - loss: 0.3706 - acc: 0.867 - ETA: 2:11 - loss: 0.3703 - acc: 0.866 - ETA: 2:10 - loss: 0.3690 - acc: 0.866 - ETA: 2:09 - loss: 0.3667 - acc: 0.866 - ETA: 2:10 - loss: 0.3689 - acc: 0.863 - ETA: 2:11 - loss: 0.3685 - acc: 0.861 - ETA: 2:10 - loss: 0.3657 - acc: 0.862 - ETA: 2:10 - loss: 0.3705 - acc: 0.860 - ETA: 2:09 - loss: 0.3713 - acc: 0.860 - ETA: 2:09 - loss: 0.3706 - acc: 0.861 - ETA: 2:07 - loss: 0.3673 - acc: 0.862 - ETA: 2:06 - loss: 0.3666 - acc: 0.862 - ETA: 2:06 - loss: 0.3657 - acc: 0.861 - ETA: 2:05 - loss: 0.3664 - acc: 0.860 - ETA: 2:05 - loss: 0.3657 - acc: 0.862 - ETA: 2:04 - loss: 0.3626 - acc: 0.863 - ETA: 2:03 - loss: 0.3601 - acc: 0.864 - ETA: 2:02 - loss: 0.3652 - acc: 0.863 - ETA: 2:01 - loss: 0.3629 - acc: 0.864 - ETA: 2:00 - loss: 0.3609 - acc: 0.865 - ETA: 1:59 - loss: 0.3620 - acc: 0.863 - ETA: 1:57 - loss: 0.3614 - acc: 0.864 - ETA: 1:56 - loss: 0.3600 - acc: 0.864 - ETA: 1:55 - loss: 0.3595 - acc: 0.864 - ETA: 1:55 - loss: 0.3605 - acc: 0.863 - ETA: 1:53 - loss: 0.3584 - acc: 0.865 - ETA: 1:52 - loss: 0.3601 - acc: 0.864 - ETA: 1:51 - loss: 0.3640 - acc: 0.862 - ETA: 1:50 - loss: 0.3647 - acc: 0.862 - ETA: 1:49 - loss: 0.3658 - acc: 0.861 - ETA: 1:48 - loss: 0.3632 - acc: 0.863 - ETA: 1:47 - loss: 0.3676 - acc: 0.862 - ETA: 1:46 - loss: 0.3652 - acc: 0.863 - ETA: 1:45 - loss: 0.3640 - acc: 0.864 - ETA: 1:44 - loss: 0.3613 - acc: 0.865 - ETA: 1:43 - loss: 0.3605 - acc: 0.865 - ETA: 1:42 - loss: 0.3605 - acc: 0.865 - ETA: 1:41 - loss: 0.3587 - acc: 0.865 - ETA: 1:40 - loss: 0.3577 - acc: 0.866 - ETA: 1:39 - loss: 0.3574 - acc: 0.867 - ETA: 1:38 - loss: 0.3594 - acc: 0.866 - ETA: 1:36 - loss: 0.3581 - acc: 0.867 - ETA: 1:35 - loss: 0.3583 - acc: 0.867 - ETA: 1:34 - loss: 0.3603 - acc: 0.865 - ETA: 1:33 - loss: 0.3606 - acc: 0.864 - ETA: 1:33 - loss: 0.3618 - acc: 0.864 - ETA: 1:32 - loss: 0.3626 - acc: 0.864 - ETA: 1:31 - loss: 0.3627 - acc: 0.863 - ETA: 1:30 - loss: 0.3624 - acc: 0.864 - ETA: 1:29 - loss: 0.3636 - acc: 0.863 - ETA: 1:28 - loss: 0.3621 - acc: 0.864 - ETA: 1:27 - loss: 0.3619 - acc: 0.865 - ETA: 1:26 - loss: 0.3617 - acc: 0.865 - ETA: 1:25 - loss: 0.3599 - acc: 0.866 - ETA: 1:24 - loss: 0.3594 - acc: 0.866 - ETA: 1:23 - loss: 0.3601 - acc: 0.864 - ETA: 1:22 - loss: 0.3599 - acc: 0.864 - ETA: 1:21 - loss: 0.3594 - acc: 0.864 - ETA: 1:20 - loss: 0.3612 - acc: 0.863 - ETA: 1:19 - loss: 0.3633 - acc: 0.862 - ETA: 1:19 - loss: 0.3623 - acc: 0.863 - ETA: 1:18 - loss: 0.3621 - acc: 0.863 - ETA: 1:17 - loss: 0.3603 - acc: 0.863 - ETA: 1:16 - loss: 0.3603 - acc: 0.863 - ETA: 1:15 - loss: 0.3605 - acc: 0.863 - ETA: 1:14 - loss: 0.3600 - acc: 0.862 - ETA: 1:13 - loss: 0.3605 - acc: 0.862 - ETA: 1:12 - loss: 0.3606 - acc: 0.862 - ETA: 1:11 - loss: 0.3602 - acc: 0.862 - ETA: 1:10 - loss: 0.3605 - acc: 0.861 - ETA: 1:09 - loss: 0.3618 - acc: 0.861 - ETA: 1:09 - loss: 0.3611 - acc: 0.861 - ETA: 1:08 - loss: 0.3611 - acc: 0.860 - ETA: 1:07 - loss: 0.3609 - acc: 0.860 - ETA: 1:06 - loss: 0.3618 - acc: 0.860 - ETA: 1:05 - loss: 0.3609 - acc: 0.860 - ETA: 1:05 - loss: 0.3611 - acc: 0.860 - ETA: 1:04 - loss: 0.3606 - acc: 0.860 - ETA: 1:03 - loss: 0.3613 - acc: 0.860 - ETA: 1:02 - loss: 0.3613 - acc: 0.860 - ETA: 1:01 - loss: 0.3617 - acc: 0.860 - ETA: 1:00 - loss: 0.3618 - acc: 0.859 - ETA: 59s - loss: 0.3608 - acc: 0.860 - ETA: 59s - loss: 0.3615 - acc: 0.85 - ETA: 58s - loss: 0.3640 - acc: 0.85 - ETA: 57s - loss: 0.3632 - acc: 0.85 - ETA: 56s - loss: 0.3628 - acc: 0.85 - ETA: 55s - loss: 0.3623 - acc: 0.85 - ETA: 54s - loss: 0.3652 - acc: 0.85 - ETA: 53s - loss: 0.3663 - acc: 0.85 - ETA: 52s - loss: 0.3671 - acc: 0.85 - ETA: 51s - loss: 0.3677 - acc: 0.85 - ETA: 50s - loss: 0.3668 - acc: 0.85 - ETA: 50s - loss: 0.3667 - acc: 0.85 - ETA: 49s - loss: 0.3676 - acc: 0.85 - ETA: 48s - loss: 0.3675 - acc: 0.85 - ETA: 47s - loss: 0.3673 - acc: 0.85 - ETA: 46s - loss: 0.3678 - acc: 0.85 - ETA: 45s - loss: 0.3688 - acc: 0.85 - ETA: 44s - loss: 0.3704 - acc: 0.85 - ETA: 44s - loss: 0.3716 - acc: 0.85 - ETA: 43s - loss: 0.3723 - acc: 0.85 - ETA: 42s - loss: 0.3731 - acc: 0.85 - ETA: 41s - loss: 0.3733 - acc: 0.85 - ETA: 40s - loss: 0.3728 - acc: 0.85 - ETA: 39s - loss: 0.3738 - acc: 0.85 - ETA: 38s - loss: 0.3744 - acc: 0.85 - ETA: 38s - loss: 0.3761 - acc: 0.85 - ETA: 37s - loss: 0.3758 - acc: 0.85 - ETA: 36s - loss: 0.3756 - acc: 0.85 - ETA: 35s - loss: 0.3757 - acc: 0.85 - ETA: 34s - loss: 0.3752 - acc: 0.85 - ETA: 33s - loss: 0.3756 - acc: 0.85 - ETA: 32s - loss: 0.3764 - acc: 0.85 - ETA: 32s - loss: 0.3758 - acc: 0.85 - ETA: 31s - loss: 0.3751 - acc: 0.85 - ETA: 30s - loss: 0.3749 - acc: 0.85 - ETA: 29s - loss: 0.3739 - acc: 0.85 - ETA: 28s - loss: 0.3735 - acc: 0.85 - ETA: 27s - loss: 0.3723 - acc: 0.85 - ETA: 27s - loss: 0.3718 - acc: 0.85 - ETA: 26s - loss: 0.3725 - acc: 0.85 - ETA: 25s - loss: 0.3730 - acc: 0.85 - ETA: 24s - loss: 0.3734 - acc: 0.85 - ETA: 23s - loss: 0.3729 - acc: 0.85 - ETA: 22s - loss: 0.3723 - acc: 0.85 - ETA: 22s - loss: 0.3725 - acc: 0.85 - ETA: 21s - loss: 0.3731 - acc: 0.85 - ETA: 20s - loss: 0.3722 - acc: 0.85 - ETA: 19s - loss: 0.3714 - acc: 0.85 - ETA: 18s - loss: 0.3714 - acc: 0.85 - ETA: 17s - loss: 0.3711 - acc: 0.85 - ETA: 17s - loss: 0.3725 - acc: 0.85 - ETA: 16s - loss: 0.3723 - acc: 0.85 - ETA: 15s - loss: 0.3730 - acc: 0.85 - ETA: 14s - loss: 0.3731 - acc: 0.85 - ETA: 13s - loss: 0.3741 - acc: 0.85 - ETA: 12s - loss: 0.3755 - acc: 0.85 - ETA: 11s - loss: 0.3766 - acc: 0.85 - ETA: 11s - loss: 0.3770 - acc: 0.85 - ETA: 10s - loss: 0.3769 - acc: 0.85 - ETA: 9s - loss: 0.3772 - acc: 0.8528 - ETA: 8s - loss: 0.3778 - acc: 0.852 - ETA: 7s - loss: 0.3790 - acc: 0.851 - ETA: 6s - loss: 0.3787 - acc: 0.851 - ETA: 6s - loss: 0.3786 - acc: 0.851 - ETA: 5s - loss: 0.3785 - acc: 0.852 - ETA: 4s - loss: 0.3787 - acc: 0.851 - ETA: 3s - loss: 0.3792 - acc: 0.851 - ETA: 2s - loss: 0.3810 - acc: 0.850 - ETA: 1s - loss: 0.3818 - acc: 0.850 - ETA: 1s - loss: 0.3823 - acc: 0.849 - ETA: 0s - loss: 0.3823 - acc: 0.849 - 176s 29ms/step - loss: 0.3821 - acc: 0.8493 - val_loss: 1.5040 - val_acc: 0.4842\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.00784\n",
      "Epoch 5/5\n",
      "5993/5993 [==============================] - ETA: 2:17 - loss: 0.2071 - acc: 0.937 - ETA: 2:16 - loss: 0.2365 - acc: 0.937 - ETA: 2:15 - loss: 0.2448 - acc: 0.916 - ETA: 2:15 - loss: 0.2149 - acc: 0.929 - ETA: 2:14 - loss: 0.2059 - acc: 0.937 - ETA: 2:13 - loss: 0.2266 - acc: 0.937 - ETA: 2:13 - loss: 0.2279 - acc: 0.942 - ETA: 2:12 - loss: 0.2303 - acc: 0.937 - ETA: 2:13 - loss: 0.2238 - acc: 0.941 - ETA: 2:13 - loss: 0.2301 - acc: 0.931 - ETA: 2:13 - loss: 0.2309 - acc: 0.931 - ETA: 2:12 - loss: 0.2321 - acc: 0.932 - ETA: 2:12 - loss: 0.2274 - acc: 0.932 - ETA: 2:12 - loss: 0.2286 - acc: 0.935 - ETA: 2:11 - loss: 0.2343 - acc: 0.931 - ETA: 2:11 - loss: 0.2394 - acc: 0.927 - ETA: 2:10 - loss: 0.2371 - acc: 0.926 - ETA: 2:09 - loss: 0.2390 - acc: 0.923 - ETA: 2:09 - loss: 0.2322 - acc: 0.927 - ETA: 2:08 - loss: 0.2295 - acc: 0.925 - ETA: 2:07 - loss: 0.2216 - acc: 0.928 - ETA: 2:06 - loss: 0.2321 - acc: 0.920 - ETA: 2:05 - loss: 0.2354 - acc: 0.918 - ETA: 2:04 - loss: 0.2325 - acc: 0.918 - ETA: 2:04 - loss: 0.2313 - acc: 0.917 - ETA: 2:03 - loss: 0.2358 - acc: 0.914 - ETA: 2:02 - loss: 0.2309 - acc: 0.916 - ETA: 2:01 - loss: 0.2345 - acc: 0.915 - ETA: 2:01 - loss: 0.2310 - acc: 0.917 - ETA: 2:00 - loss: 0.2255 - acc: 0.918 - ETA: 2:00 - loss: 0.2263 - acc: 0.919 - ETA: 2:00 - loss: 0.2308 - acc: 0.918 - ETA: 1:59 - loss: 0.2268 - acc: 0.921 - ETA: 1:59 - loss: 0.2302 - acc: 0.920 - ETA: 1:59 - loss: 0.2285 - acc: 0.920 - ETA: 1:58 - loss: 0.2300 - acc: 0.920 - ETA: 1:57 - loss: 0.2308 - acc: 0.917 - ETA: 1:57 - loss: 0.2312 - acc: 0.916 - ETA: 1:56 - loss: 0.2318 - acc: 0.915 - ETA: 1:55 - loss: 0.2299 - acc: 0.916 - ETA: 1:54 - loss: 0.2320 - acc: 0.915 - ETA: 1:54 - loss: 0.2327 - acc: 0.915 - ETA: 1:53 - loss: 0.2316 - acc: 0.915 - ETA: 1:52 - loss: 0.2317 - acc: 0.915 - ETA: 1:51 - loss: 0.2317 - acc: 0.915 - ETA: 1:50 - loss: 0.2308 - acc: 0.914 - ETA: 1:50 - loss: 0.2337 - acc: 0.913 - ETA: 1:49 - loss: 0.2319 - acc: 0.914 - ETA: 1:48 - loss: 0.2314 - acc: 0.913 - ETA: 1:47 - loss: 0.2359 - acc: 0.911 - ETA: 1:46 - loss: 0.2359 - acc: 0.909 - ETA: 1:45 - loss: 0.2352 - acc: 0.910 - ETA: 1:45 - loss: 0.2369 - acc: 0.908 - ETA: 1:44 - loss: 0.2417 - acc: 0.906 - ETA: 1:43 - loss: 0.2424 - acc: 0.905 - ETA: 1:42 - loss: 0.2451 - acc: 0.903 - ETA: 1:41 - loss: 0.2467 - acc: 0.902 - ETA: 1:41 - loss: 0.2455 - acc: 0.903 - ETA: 1:40 - loss: 0.2466 - acc: 0.903 - ETA: 1:39 - loss: 0.2464 - acc: 0.903 - ETA: 1:38 - loss: 0.2441 - acc: 0.904 - ETA: 1:38 - loss: 0.2440 - acc: 0.903 - ETA: 1:37 - loss: 0.2468 - acc: 0.902 - ETA: 1:36 - loss: 0.2500 - acc: 0.899 - ETA: 1:36 - loss: 0.2488 - acc: 0.901 - ETA: 1:35 - loss: 0.2505 - acc: 0.900 - ETA: 1:34 - loss: 0.2490 - acc: 0.901 - ETA: 1:33 - loss: 0.2510 - acc: 0.900 - ETA: 1:32 - loss: 0.2534 - acc: 0.899 - ETA: 1:32 - loss: 0.2536 - acc: 0.898 - ETA: 1:31 - loss: 0.2512 - acc: 0.899 - ETA: 1:30 - loss: 0.2518 - acc: 0.900 - ETA: 1:29 - loss: 0.2534 - acc: 0.899 - ETA: 1:28 - loss: 0.2519 - acc: 0.899 - ETA: 1:28 - loss: 0.2515 - acc: 0.899 - ETA: 1:27 - loss: 0.2535 - acc: 0.898 - ETA: 1:26 - loss: 0.2579 - acc: 0.896 - ETA: 1:25 - loss: 0.2579 - acc: 0.896 - ETA: 1:25 - loss: 0.2574 - acc: 0.896 - ETA: 1:24 - loss: 0.2573 - acc: 0.896 - ETA: 1:23 - loss: 0.2581 - acc: 0.896 - ETA: 1:22 - loss: 0.2603 - acc: 0.895 - ETA: 1:21 - loss: 0.2604 - acc: 0.895 - ETA: 1:21 - loss: 0.2599 - acc: 0.895 - ETA: 1:20 - loss: 0.2592 - acc: 0.896 - ETA: 1:19 - loss: 0.2586 - acc: 0.895 - ETA: 1:18 - loss: 0.2602 - acc: 0.894 - ETA: 1:17 - loss: 0.2608 - acc: 0.894 - ETA: 1:17 - loss: 0.2590 - acc: 0.895 - ETA: 1:16 - loss: 0.2587 - acc: 0.895 - ETA: 1:15 - loss: 0.2581 - acc: 0.896 - ETA: 1:14 - loss: 0.2561 - acc: 0.897 - ETA: 1:13 - loss: 0.2569 - acc: 0.897 - ETA: 1:13 - loss: 0.2553 - acc: 0.897 - ETA: 1:12 - loss: 0.2570 - acc: 0.897 - ETA: 1:11 - loss: 0.2589 - acc: 0.896 - ETA: 1:10 - loss: 0.2591 - acc: 0.896 - ETA: 1:09 - loss: 0.2574 - acc: 0.898 - ETA: 1:09 - loss: 0.2570 - acc: 0.898 - ETA: 1:08 - loss: 0.2566 - acc: 0.898 - ETA: 1:07 - loss: 0.2570 - acc: 0.897 - ETA: 1:06 - loss: 0.2602 - acc: 0.896 - ETA: 1:05 - loss: 0.2603 - acc: 0.896 - ETA: 1:05 - loss: 0.2620 - acc: 0.895 - ETA: 1:04 - loss: 0.2626 - acc: 0.895 - ETA: 1:03 - loss: 0.2639 - acc: 0.894 - ETA: 1:02 - loss: 0.2633 - acc: 0.894 - ETA: 1:02 - loss: 0.2642 - acc: 0.894 - ETA: 1:01 - loss: 0.2652 - acc: 0.893 - ETA: 1:00 - loss: 0.2639 - acc: 0.894 - ETA: 59s - loss: 0.2641 - acc: 0.895 - ETA: 58s - loss: 0.2628 - acc: 0.89 - ETA: 58s - loss: 0.2627 - acc: 0.89 - ETA: 57s - loss: 0.2627 - acc: 0.89 - ETA: 56s - loss: 0.2643 - acc: 0.89 - ETA: 55s - loss: 0.2658 - acc: 0.89 - ETA: 55s - loss: 0.2662 - acc: 0.89 - ETA: 54s - loss: 0.2665 - acc: 0.89 - ETA: 53s - loss: 0.2663 - acc: 0.89 - ETA: 52s - loss: 0.2665 - acc: 0.89 - ETA: 51s - loss: 0.2684 - acc: 0.89 - ETA: 51s - loss: 0.2685 - acc: 0.89 - ETA: 50s - loss: 0.2714 - acc: 0.89 - ETA: 49s - loss: 0.2718 - acc: 0.89 - ETA: 48s - loss: 0.2707 - acc: 0.89 - ETA: 48s - loss: 0.2727 - acc: 0.89 - ETA: 47s - loss: 0.2728 - acc: 0.89 - ETA: 46s - loss: 0.2733 - acc: 0.89 - ETA: 45s - loss: 0.2744 - acc: 0.89 - ETA: 44s - loss: 0.2741 - acc: 0.89 - ETA: 44s - loss: 0.2751 - acc: 0.88 - ETA: 43s - loss: 0.2744 - acc: 0.88 - ETA: 42s - loss: 0.2743 - acc: 0.88 - ETA: 41s - loss: 0.2758 - acc: 0.88 - ETA: 41s - loss: 0.2767 - acc: 0.88 - ETA: 40s - loss: 0.2764 - acc: 0.88 - ETA: 39s - loss: 0.2768 - acc: 0.88 - ETA: 38s - loss: 0.2779 - acc: 0.88 - ETA: 37s - loss: 0.2775 - acc: 0.88 - ETA: 37s - loss: 0.2778 - acc: 0.88 - ETA: 36s - loss: 0.2780 - acc: 0.88 - ETA: 35s - loss: 0.2798 - acc: 0.88 - ETA: 34s - loss: 0.2790 - acc: 0.88 - ETA: 33s - loss: 0.2795 - acc: 0.88 - ETA: 33s - loss: 0.2794 - acc: 0.88 - ETA: 32s - loss: 0.2804 - acc: 0.88 - ETA: 31s - loss: 0.2795 - acc: 0.88 - ETA: 30s - loss: 0.2792 - acc: 0.88 - ETA: 30s - loss: 0.2794 - acc: 0.88 - ETA: 29s - loss: 0.2796 - acc: 0.88 - ETA: 28s - loss: 0.2801 - acc: 0.88 - ETA: 27s - loss: 0.2795 - acc: 0.88 - ETA: 26s - loss: 0.2796 - acc: 0.88 - ETA: 26s - loss: 0.2797 - acc: 0.88 - ETA: 25s - loss: 0.2802 - acc: 0.88 - ETA: 24s - loss: 0.2813 - acc: 0.88 - ETA: 23s - loss: 0.2821 - acc: 0.88 - ETA: 23s - loss: 0.2821 - acc: 0.88 - ETA: 22s - loss: 0.2830 - acc: 0.88 - ETA: 21s - loss: 0.2820 - acc: 0.88 - ETA: 20s - loss: 0.2817 - acc: 0.88 - ETA: 19s - loss: 0.2808 - acc: 0.88 - ETA: 19s - loss: 0.2807 - acc: 0.88 - ETA: 18s - loss: 0.2802 - acc: 0.88 - ETA: 17s - loss: 0.2801 - acc: 0.88 - ETA: 16s - loss: 0.2799 - acc: 0.88 - ETA: 16s - loss: 0.2800 - acc: 0.88 - ETA: 15s - loss: 0.2797 - acc: 0.88 - ETA: 14s - loss: 0.2788 - acc: 0.88 - ETA: 13s - loss: 0.2788 - acc: 0.88 - ETA: 12s - loss: 0.2792 - acc: 0.88 - ETA: 12s - loss: 0.2783 - acc: 0.88 - ETA: 11s - loss: 0.2782 - acc: 0.88 - ETA: 10s - loss: 0.2781 - acc: 0.88 - ETA: 9s - loss: 0.2787 - acc: 0.8859 - ETA: 8s - loss: 0.2789 - acc: 0.886 - ETA: 8s - loss: 0.2788 - acc: 0.886 - ETA: 7s - loss: 0.2788 - acc: 0.886 - ETA: 6s - loss: 0.2785 - acc: 0.886 - ETA: 5s - loss: 0.2783 - acc: 0.886 - ETA: 4s - loss: 0.2777 - acc: 0.886 - ETA: 4s - loss: 0.2777 - acc: 0.886 - ETA: 3s - loss: 0.2777 - acc: 0.886 - ETA: 2s - loss: 0.2779 - acc: 0.886 - ETA: 1s - loss: 0.2785 - acc: 0.886 - ETA: 1s - loss: 0.2780 - acc: 0.886 - ETA: 0s - loss: 0.2771 - acc: 0.886 - 168s 28ms/step - loss: 0.2772 - acc: 0.8867 - val_loss: 1.9140 - val_acc: 0.4837\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.00784\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x235f8312518>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_checkpts = ModelCheckpoint(filepath=os.path.join(os.getcwd() + '/saved_models/text/sentiment/cnn.weights.best.hdf5'), \n",
    "                               verbose=1, save_best_only=True)\n",
    "sen_cnn = build_CNN(num_polarities)\n",
    "sen_cnn.fit(x_train_reshaped, z_train, validation_split=0.4, epochs=5, callbacks=[cnn_checkpts], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 1339, 0: 751, 2: 520})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_pred_cnn = sen_cnn.predict_classes(x_test_reshaped)\n",
    "Counter(z_pred_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 48.5824%\n"
     ]
    }
   ],
   "source": [
    "cnn_accuracy = 100*np.sum(z_pred_cnn==z_transf)/len(z_transf)\n",
    "print('Test accuracy: %.4f%%' % cnn_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "219px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
